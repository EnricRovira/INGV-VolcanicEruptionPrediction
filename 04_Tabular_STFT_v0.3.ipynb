{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "#############################################################\n",
    "# 1. Libraries\n",
    "\n",
    "import os\n",
    "import datetime\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.signal\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "pd.options.display.max_columns = None    # disp all columns\n",
    "\n",
    "from sklearn.model_selection import KFold, GroupKFold, StratifiedKFold\n",
    "\n",
    "import gc\n",
    "import pickle\n",
    "\n",
    "import lightgbm as lgb\n",
    "from pytorch_tabnet.tab_model import TabNetRegressor\n",
    "import torch\n",
    "from pytorch_tabnet.metrics import Metric\n",
    "\n",
    "#############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "#############################################################\n",
    "# 2. Paths & Global Variables\n",
    "\n",
    "## 2.1 Paths\n",
    "\n",
    "path = '../../01_Data/'\n",
    "path_sequences = path + '01_GeneratedSequences/'\n",
    "path_spectograms = path + '04_GeneratedSpectogramsSTFT/'\n",
    "\n",
    "\n",
    "df_train = pd.read_csv(path + 'train.csv')\n",
    "df_sample_submission = pd.read_csv(path + 'sample_submission.csv') \n",
    "\n",
    "## 2.2 Global Variables\n",
    "\n",
    "unique_segments_id_train = set(df_train['segment_id'])\n",
    "unique_segments_id_test = set(df_sample_submission['segment_id'])\n",
    "\n",
    "SEQ_LENGTH = 60_001\n",
    "\n",
    "#############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################\n",
    "# 3. Preprocess\n",
    "\n",
    "dict_segments_paths_train = {\n",
    "    segment : path + 'train/' + str(segment) + '.csv' for segment in unique_segments_id_train\n",
    "}\n",
    "\n",
    "dict_segments_paths_test = {\n",
    "    segment : path + 'test/' + str(segment) + '.csv' for segment in unique_segments_id_test\n",
    "}\n",
    "\n",
    "###\n",
    "\n",
    "dict_segments_sequences_paths_train = {\n",
    "    segment : path_sequences + 'train/' + str(segment) + '.npy' for segment in unique_segments_id_train\n",
    "}\n",
    "\n",
    "dict_segments_sequences_paths_test = {\n",
    "    segment : path_sequences + 'test/' + str(segment) + '.npy' for segment in unique_segments_id_test\n",
    "}\n",
    "\n",
    "\n",
    "###\n",
    "\n",
    "df_train['time_to_eruption'] = df_train['time_to_eruption']/(10**6)\n",
    "\n",
    "dict_labels = {\n",
    "    segment : df_train['time_to_eruption'][df_train['segment_id']==segment].values.flatten()\n",
    "    \n",
    "    for segment in unique_segments_id_train\n",
    "}\n",
    "\n",
    "\n",
    "#############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efd8afa75cbb4736a5abedcd1ff9a0c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=4431.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#############################################################\n",
    "# 5. Build Dataset\n",
    "\n",
    "fs = 100                # sampling frequency \n",
    "n = 256                 # FFT segment size\n",
    "max_f = 20              # ï½ž20Hz\n",
    "\n",
    "delta_f = fs / n        # 0.39Hz\n",
    "delta_t = n / fs / 2    # 1.28s\n",
    "\n",
    "def generateFeaturesTimeDomain(dict_paths):\n",
    "    feature_set = []\n",
    "    for segment_id in tqdm(dict_paths, total=len(dict_paths), position=0):\n",
    "        data = np.load(dict_paths[segment_id])\n",
    "        segment = [segment_id]\n",
    "        \n",
    "        # mean\n",
    "        segment += data.mean(axis=0).tolist()\n",
    "        # std\n",
    "        segment += data.std(axis=0).tolist()\n",
    "        # min\n",
    "        segment += data.min(axis=0).tolist()\n",
    "        # max\n",
    "        segment += data.max(axis=0).tolist()\n",
    "        # 5 percentile\n",
    "        segment += np.quantile(data, 0.05, axis=0).tolist()\n",
    "        # 10 percentile\n",
    "        segment += np.quantile(data, 0.1, axis=0).tolist()\n",
    "        # 20 percentile\n",
    "        segment += np.quantile(data, 0.2, axis=0).tolist()\n",
    "        # 40 percentile\n",
    "        segment += np.quantile(data, 0.4, axis=0).tolist()\n",
    "        # 50 percentile\n",
    "        segment += np.quantile(data, 0.5, axis=0).tolist()\n",
    "        # 60 percentile\n",
    "        segment += np.quantile(data, 0.6, axis=0).tolist()\n",
    "        # 80 percentile\n",
    "        segment += np.quantile(data, 0.8, axis=0).tolist()\n",
    "        # 90 percentile\n",
    "        segment += np.quantile(data, 0.9, axis=0).tolist()\n",
    "        \n",
    "        # shift\n",
    "        d = pd.DataFrame(data)\n",
    "        d.columns = [f'sensor_{i+1}' for i in range(10)]\n",
    "        for col in d:\n",
    "            d[col+'_5000'] = d[col].shift(5000).fillna(0)\n",
    "            d[col+'_10000'] = d[col].shift(10000).fillna(0)\n",
    "            d[col+'_20000'] = d[col].shift(20000).fillna(0)\n",
    "            d[col+'_30000'] = d[col].shift(30000).fillna(0)\n",
    "\n",
    "        # +5000 / +10000 / +20000 / +30000 self-corr\n",
    "        for col in d.columns[:10]:\n",
    "            col1 = col+'_5000'\n",
    "            col2 = col+'_10000'\n",
    "            col3 = col+'_20000'\n",
    "            col4 = col+'_30000'\n",
    "            tmp1 = d.loc[:, [col, col1]].dropna().fillna(0)\n",
    "            tmp2 = d.loc[:, [col, col2]].dropna().fillna(0)\n",
    "            tmp3 = d.loc[:, [col, col3]].dropna().fillna(0)\n",
    "            tmp4 = d.loc[:, [col, col4]].dropna().fillna(0)\n",
    "            segment += [tmp1[col].corr(tmp1[col1]), \n",
    "                        tmp2[col].corr(tmp2[col2]), \n",
    "                        tmp3[col].corr(tmp3[col3]),\n",
    "                        tmp4[col].corr(tmp4[col4])]\n",
    "\n",
    "        feature_set.append(segment)\n",
    "        \n",
    "    base_colname = ['sensor_'+str(i) for i in range(1, 11)]\n",
    "    fea_colname = ['segment_id'] + [j + '_mean' for j in base_colname] + [j + '_std' for j in base_colname] + \\\n",
    "                    [j + '_min' for j in base_colname] + [j + '_max' for j in base_colname] + \\\n",
    "                        [j + '_5_quant' for j in base_colname] + [j + '_10_quant' for j in base_colname] + \\\n",
    "                            [j + '_20_quant' for j in base_colname] + [j + '_40_quant' for j in base_colname] + \\\n",
    "                            [j + '_50_quant' for j in base_colname] + [j + '_60_quant' for j in base_colname] + \\\n",
    "                            [j + '_80_quant' for j in base_colname] + [j + '_90_quant' for j in base_colname] + \\\n",
    "                        [j + i for j in base_colname for i in ['_5000_self_corr', '_10000_self_corr', \n",
    "                                                               '_20000_self_corr', '_30000_self_corr']]    \n",
    "    feature_df = pd.DataFrame(feature_set, columns=fea_colname)\n",
    "    feature_df['segment_id'] = feature_df['segment_id'].astype('int')\n",
    "    \n",
    "    return feature_df\n",
    "\n",
    "\n",
    "def generateFeaturesFreqDomain(dict_paths):\n",
    "    feature_set = []\n",
    "    for segment_id in tqdm(dict_paths, total=len(dict_paths), position=0):\n",
    "        data = np.load(dict_paths[segment_id])\n",
    "        segment = [segment_id]\n",
    "        for sensor in range(10):\n",
    "            x = data[:, sensor]\n",
    "            f, t, Z = scipy.signal.stft(x, fs = fs, window = 'hann', nperseg = n)\n",
    "            f = f[:round(max_f/delta_f)+1]\n",
    "            \n",
    "            # Time domain\n",
    "            Z_half = np.abs(Z[:round(Z.shape[0]//2)+1]).T\n",
    "            min_ = Z_half.min(axis=0).mean()\n",
    "            max_ = Z_half.max(axis=0).mean()\n",
    "            std_ = Z_half.std(axis=0).mean()\n",
    "            mean_ = Z_half.mean(axis=0).mean()\n",
    "            p25 = np.quantile(Z_half, 0.25, axis=0).mean()\n",
    "            p50 = np.quantile(Z_half, 0.5, axis=0).mean()\n",
    "            p75 = np.quantile(Z_half, 0.75, axis=0).mean()\n",
    "            p90 = np.quantile(Z_half, 0.9, axis=0).mean()\n",
    "            p95 = np.quantile(Z_half, 0.95, axis=0).mean()\n",
    "            segment += [min_, max_, std_, mean_, p25, p50, p75, p90, p95]\n",
    "            \n",
    "            # Freq domain\n",
    "            Z = np.abs(Z[:round(max_f/delta_f)+1]).T\n",
    "            th = Z.mean() * 1 \n",
    "            Z_pow = Z.copy()\n",
    "            Z_pow[Z < th] = 0\n",
    "            Z_num = Z_pow.copy()\n",
    "            Z_num[Z >= th] = 1\n",
    "\n",
    "            Z_pow_sum = Z_pow.sum(axis = 0)\n",
    "            Z_num_sum = Z_num.sum(axis = 0)\n",
    "\n",
    "            A_pow = Z_pow_sum[round(10/delta_f):].sum()\n",
    "            A_num = Z_num_sum[round(10/delta_f):].sum()\n",
    "            BH_pow = Z_pow_sum[round(5/delta_f):round(8/delta_f)].sum()\n",
    "            BH_num = Z_num_sum[round(5/delta_f):round(8/delta_f)].sum()\n",
    "            BL_pow = Z_pow_sum[round(1.5/delta_f):round(2.5/delta_f)].sum()\n",
    "            BL_num = Z_num_sum[round(1.5/delta_f):round(2.5/delta_f)].sum()\n",
    "            C_pow = Z_pow_sum[round(0.6/delta_f):round(1.2/delta_f)].sum()\n",
    "            C_num = Z_num_sum[round(0.6/delta_f):round(1.2/delta_f)].sum()\n",
    "            D_pow = Z_pow_sum[round(2/delta_f):round(4/delta_f)].sum()\n",
    "            D_num = Z_num_sum[round(2/delta_f):round(4/delta_f)].sum()\n",
    "            segment += [A_pow, A_num, BH_pow, BH_num, BL_pow, BL_num, C_pow, C_num, D_pow, D_num]\n",
    "\n",
    "        feature_set.append(segment)\n",
    "\n",
    "    #Cols Names\n",
    "    cols = ['segment_id']\n",
    "    for i in range(10):\n",
    "        for j in ['min', 'max', 'std', 'mean', 'p25', 'p50', 'p75', 'p90', 'p95']:\n",
    "            cols += [f's{i+1}_{j}']\n",
    "        for j in ['A_pow', 'A_num','BH_pow', 'BH_num','BL_pow', 'BL_num','C_pow', 'C_num','D_pow', 'D_num']:\n",
    "            cols += [f's{i+1}_{j}']\n",
    "    feature_df = pd.DataFrame(feature_set, columns = cols)\n",
    "    feature_df['segment_id'] = feature_df['segment_id'].astype('int')\n",
    "    \n",
    "    return feature_df\n",
    "\n",
    "\n",
    "def buildDataset(dict_paths):\n",
    "    #df_time = generateFeaturesTimeDomain(dict_paths)\n",
    "    df = generateFeaturesFreqDomain(dict_paths)\n",
    "    \n",
    "    #df = pd.merge(df_time, df_freq, how='inner', on='segment_id')\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "# 5.2 Build Dataframes - 4mins\n",
    "\n",
    "# df_time_X_train = generateFeaturesTimedomain(dict_segments_sequences_paths_train)\n",
    "# df_freq_X_train = generateFeaturesFreqDomain(dict_segments_sequences_paths_train)\n",
    "\n",
    "\n",
    "df_X_train = buildDataset(dict_segments_sequences_paths_train)\n",
    "\n",
    "df_X_train = df_X_train.merge(df_train[['segment_id', 'time_to_eruption']], how='inner')\n",
    "features = [col for col in df_X_train.columns.tolist() if col not in ['segment_id', 'time_to_eruption']]\n",
    "    \n",
    "#############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################\n",
    "# 6. Models\n",
    "\n",
    "def buildLGBModel(X_train, y_train, X_val, y_val, features, verbose=10, early_stopping_rounds=200):\n",
    "    cat_features = {}\n",
    "    params = {'objective': 'rmse',\n",
    "              'metric': 'rmse',\n",
    "              'max_depth':14,\n",
    "              'min_data_in_leaf':5,         # = min_child_samples\n",
    "              'num_leaves': 2**7 - 1,\n",
    "              'learning_rate': 0.05,\n",
    "              'feature_fraction': 0.7,      # = colsample_bytree\n",
    "              'bagging_fraction': 0.5,      # = subsample\n",
    "              'bagging_freq': 5,\n",
    "              'lambda_l1':80,               # = reg_alpha\n",
    "              'num_iterations': 10000,      # = n_estimators\n",
    "              'seed': 42,\n",
    "              'verbose': -1\n",
    "             }\n",
    "\n",
    "    lgb_train = lgb.Dataset(X_train, y_train)\n",
    "    lgb_eval = lgb.Dataset(X_val, y_val, reference=lgb_train)\n",
    "\n",
    "    evals_result = {}\n",
    "    \n",
    "    model = lgb.train(\n",
    "        params,\n",
    "        lgb_train,\n",
    "        valid_sets = (lgb_train, lgb_eval),\n",
    "        feature_name = features,\n",
    "        categorical_feature = cat_features,\n",
    "        verbose_eval = 100,\n",
    "        evals_result = evals_result,\n",
    "        early_stopping_rounds = 200\n",
    "    )\n",
    "\n",
    "#     model = lgb.LGBMRegressor(random_state = 12,\n",
    "#                                 max_depth = 8,\n",
    "#                                 num_leaves=28,\n",
    "#                                 n_estimators = 250,\n",
    "#                                 reg_lambda=1.5,\n",
    "#                                 learning_rate = 0.05)\n",
    "    \n",
    "#     model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "    \n",
    "#############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class TabnetMAE(Metric):\n",
    "    def __init__(self):\n",
    "        self._name = \"mae\"\n",
    "        self._maximize = False\n",
    "\n",
    "    def __call__(self, y_true, y_score):\n",
    "        mae = mean_absolute_error(y_true, y_score[:, 1])\n",
    "        return mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Fold: 1\n",
      "Train segments: 3544 Val segments: 887\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 22.56065| val_0_mae: 24.54005|  0:00:01s\n",
      "epoch 1  | loss: 21.41019| val_0_mae: 16.58556|  0:00:01s\n",
      "epoch 2  | loss: 20.09935| val_0_mae: 19.31124|  0:00:01s\n",
      "epoch 3  | loss: 18.98425| val_0_mae: 23.43033|  0:00:02s\n",
      "epoch 4  | loss: 17.70642| val_0_mae: 17.69521|  0:00:02s\n",
      "epoch 5  | loss: 15.83465| val_0_mae: 17.10458|  0:00:02s\n",
      "epoch 6  | loss: 14.20443| val_0_mae: 17.94293|  0:00:02s\n",
      "epoch 7  | loss: 12.60815| val_0_mae: 17.958  |  0:00:02s\n",
      "epoch 8  | loss: 11.6459 | val_0_mae: 15.88384|  0:00:03s\n",
      "epoch 9  | loss: 11.17378| val_0_mae: 14.49778|  0:00:03s\n",
      "epoch 10 | loss: 10.72015| val_0_mae: 16.93676|  0:00:03s\n",
      "epoch 11 | loss: 10.00044| val_0_mae: 21.2035 |  0:00:03s\n",
      "epoch 12 | loss: 9.76214 | val_0_mae: 21.09859|  0:00:03s\n",
      "epoch 13 | loss: 9.56314 | val_0_mae: 27.42346|  0:00:04s\n",
      "epoch 14 | loss: 9.50574 | val_0_mae: 23.05602|  0:00:04s\n",
      "epoch 15 | loss: 9.32078 | val_0_mae: 19.14741|  0:00:04s\n",
      "epoch 16 | loss: 9.41905 | val_0_mae: 15.19547|  0:00:04s\n",
      "epoch 17 | loss: 8.97946 | val_0_mae: 15.53605|  0:00:04s\n",
      "epoch 18 | loss: 8.79691 | val_0_mae: 14.9783 |  0:00:05s\n",
      "epoch 19 | loss: 8.31139 | val_0_mae: 18.12397|  0:00:05s\n",
      "epoch 20 | loss: 8.36496 | val_0_mae: 16.85696|  0:00:05s\n",
      "epoch 21 | loss: 8.01422 | val_0_mae: 16.14258|  0:00:05s\n",
      "epoch 22 | loss: 7.65553 | val_0_mae: 14.36913|  0:00:05s\n",
      "epoch 23 | loss: 7.51329 | val_0_mae: 13.43154|  0:00:06s\n",
      "epoch 24 | loss: 7.39677 | val_0_mae: 13.70944|  0:00:06s\n",
      "epoch 25 | loss: 7.06206 | val_0_mae: 13.98492|  0:00:06s\n",
      "epoch 26 | loss: 6.92821 | val_0_mae: 13.39658|  0:00:06s\n",
      "epoch 27 | loss: 7.05522 | val_0_mae: 12.48893|  0:00:06s\n",
      "epoch 28 | loss: 6.98129 | val_0_mae: 13.00651|  0:00:07s\n",
      "epoch 29 | loss: 6.85815 | val_0_mae: 14.87549|  0:00:07s\n",
      "epoch 30 | loss: 6.77665 | val_0_mae: 12.72206|  0:00:07s\n",
      "epoch 31 | loss: 6.59895 | val_0_mae: 12.57855|  0:00:07s\n",
      "epoch 32 | loss: 6.27001 | val_0_mae: 11.71135|  0:00:07s\n",
      "epoch 33 | loss: 6.32892 | val_0_mae: 11.5306 |  0:00:08s\n",
      "epoch 34 | loss: 6.19895 | val_0_mae: 10.79113|  0:00:08s\n",
      "epoch 35 | loss: 6.27273 | val_0_mae: 10.41491|  0:00:08s\n",
      "epoch 36 | loss: 5.99373 | val_0_mae: 10.72333|  0:00:08s\n",
      "epoch 37 | loss: 6.12089 | val_0_mae: 10.36165|  0:00:08s\n",
      "epoch 38 | loss: 6.01222 | val_0_mae: 10.20529|  0:00:09s\n",
      "epoch 39 | loss: 5.91572 | val_0_mae: 9.81847 |  0:00:09s\n",
      "epoch 40 | loss: 5.8185  | val_0_mae: 9.46163 |  0:00:09s\n",
      "epoch 41 | loss: 5.90635 | val_0_mae: 9.64095 |  0:00:09s\n",
      "epoch 42 | loss: 6.04499 | val_0_mae: 9.16367 |  0:00:09s\n",
      "epoch 43 | loss: 5.82861 | val_0_mae: 8.93422 |  0:00:10s\n",
      "epoch 44 | loss: 5.90454 | val_0_mae: 8.83764 |  0:00:10s\n",
      "epoch 45 | loss: 5.72439 | val_0_mae: 9.00521 |  0:00:10s\n",
      "epoch 46 | loss: 5.6035  | val_0_mae: 8.71081 |  0:00:10s\n",
      "epoch 47 | loss: 5.56347 | val_0_mae: 9.15283 |  0:00:11s\n",
      "epoch 48 | loss: 5.59393 | val_0_mae: 9.07014 |  0:00:11s\n",
      "epoch 49 | loss: 5.59016 | val_0_mae: 7.93907 |  0:00:11s\n",
      "epoch 50 | loss: 5.3469  | val_0_mae: 7.61903 |  0:00:11s\n",
      "epoch 51 | loss: 5.30745 | val_0_mae: 7.48647 |  0:00:11s\n",
      "epoch 52 | loss: 5.20875 | val_0_mae: 7.39901 |  0:00:12s\n",
      "epoch 53 | loss: 4.95737 | val_0_mae: 7.58593 |  0:00:12s\n",
      "epoch 54 | loss: 4.9308  | val_0_mae: 7.15296 |  0:00:12s\n",
      "epoch 55 | loss: 4.99578 | val_0_mae: 6.90652 |  0:00:12s\n",
      "epoch 56 | loss: 4.91166 | val_0_mae: 7.30465 |  0:00:12s\n",
      "epoch 57 | loss: 4.9267  | val_0_mae: 6.96169 |  0:00:13s\n",
      "epoch 58 | loss: 4.87981 | val_0_mae: 6.47799 |  0:00:13s\n",
      "epoch 59 | loss: 4.86397 | val_0_mae: 6.56961 |  0:00:13s\n",
      "epoch 60 | loss: 4.73217 | val_0_mae: 6.51098 |  0:00:13s\n",
      "epoch 61 | loss: 4.61397 | val_0_mae: 6.42708 |  0:00:13s\n",
      "epoch 62 | loss: 4.59303 | val_0_mae: 6.07895 |  0:00:14s\n",
      "epoch 63 | loss: 4.63697 | val_0_mae: 6.31847 |  0:00:14s\n",
      "epoch 64 | loss: 4.61239 | val_0_mae: 6.41524 |  0:00:14s\n",
      "epoch 65 | loss: 4.71034 | val_0_mae: 6.51348 |  0:00:14s\n",
      "epoch 66 | loss: 4.6622  | val_0_mae: 5.74531 |  0:00:14s\n",
      "epoch 67 | loss: 4.45135 | val_0_mae: 5.85818 |  0:00:15s\n",
      "epoch 68 | loss: 4.48128 | val_0_mae: 5.6482  |  0:00:15s\n",
      "epoch 69 | loss: 4.36124 | val_0_mae: 5.81891 |  0:00:15s\n",
      "epoch 70 | loss: 4.38067 | val_0_mae: 5.85445 |  0:00:15s\n",
      "epoch 71 | loss: 4.41053 | val_0_mae: 5.57521 |  0:00:15s\n",
      "epoch 72 | loss: 4.59201 | val_0_mae: 5.65427 |  0:00:16s\n",
      "epoch 73 | loss: 4.40797 | val_0_mae: 5.61539 |  0:00:16s\n",
      "epoch 74 | loss: 4.31337 | val_0_mae: 5.15724 |  0:00:16s\n",
      "epoch 75 | loss: 4.40654 | val_0_mae: 5.30695 |  0:00:16s\n",
      "epoch 76 | loss: 4.38271 | val_0_mae: 5.21612 |  0:00:16s\n",
      "epoch 77 | loss: 4.17403 | val_0_mae: 5.28655 |  0:00:17s\n",
      "epoch 78 | loss: 4.29464 | val_0_mae: 5.15416 |  0:00:17s\n",
      "epoch 79 | loss: 4.15101 | val_0_mae: 5.1539  |  0:00:17s\n",
      "epoch 80 | loss: 3.94675 | val_0_mae: 5.06222 |  0:00:17s\n",
      "epoch 81 | loss: 4.20296 | val_0_mae: 4.89098 |  0:00:17s\n",
      "epoch 82 | loss: 4.1325  | val_0_mae: 4.60432 |  0:00:18s\n",
      "epoch 83 | loss: 4.04779 | val_0_mae: 4.41382 |  0:00:18s\n",
      "epoch 84 | loss: 3.88935 | val_0_mae: 4.60795 |  0:00:18s\n",
      "epoch 85 | loss: 3.94779 | val_0_mae: 4.36038 |  0:00:18s\n",
      "epoch 86 | loss: 4.05134 | val_0_mae: 4.28533 |  0:00:18s\n",
      "epoch 87 | loss: 3.96535 | val_0_mae: 4.33516 |  0:00:19s\n",
      "epoch 88 | loss: 3.95827 | val_0_mae: 4.26054 |  0:00:19s\n",
      "epoch 89 | loss: 3.93639 | val_0_mae: 4.4148  |  0:00:19s\n",
      "epoch 90 | loss: 3.85388 | val_0_mae: 4.36473 |  0:00:19s\n",
      "epoch 91 | loss: 3.84344 | val_0_mae: 4.0764  |  0:00:19s\n",
      "epoch 92 | loss: 3.73102 | val_0_mae: 3.9969  |  0:00:20s\n",
      "epoch 93 | loss: 3.77715 | val_0_mae: 4.09116 |  0:00:20s\n",
      "epoch 94 | loss: 3.83237 | val_0_mae: 3.91703 |  0:00:20s\n",
      "epoch 95 | loss: 3.7398  | val_0_mae: 3.70185 |  0:00:20s\n",
      "epoch 96 | loss: 3.68373 | val_0_mae: 3.93441 |  0:00:20s\n",
      "epoch 97 | loss: 3.71968 | val_0_mae: 4.17218 |  0:00:21s\n",
      "epoch 98 | loss: 3.64958 | val_0_mae: 4.14795 |  0:00:21s\n",
      "epoch 99 | loss: 3.68189 | val_0_mae: 3.89214 |  0:00:21s\n",
      "epoch 100| loss: 3.66029 | val_0_mae: 3.85084 |  0:00:21s\n",
      "epoch 101| loss: 3.64655 | val_0_mae: 3.79487 |  0:00:22s\n",
      "epoch 102| loss: 3.59362 | val_0_mae: 3.89571 |  0:00:22s\n",
      "epoch 103| loss: 3.44851 | val_0_mae: 3.66137 |  0:00:22s\n",
      "epoch 104| loss: 3.55775 | val_0_mae: 3.60405 |  0:00:22s\n",
      "epoch 105| loss: 3.5868  | val_0_mae: 3.58933 |  0:00:22s\n",
      "epoch 106| loss: 3.47125 | val_0_mae: 3.72095 |  0:00:23s\n",
      "epoch 107| loss: 3.42674 | val_0_mae: 3.75657 |  0:00:23s\n",
      "epoch 108| loss: 3.44498 | val_0_mae: 3.78301 |  0:00:23s\n",
      "epoch 109| loss: 3.3877  | val_0_mae: 3.49514 |  0:00:23s\n",
      "epoch 110| loss: 3.4239  | val_0_mae: 3.66193 |  0:00:23s\n",
      "epoch 111| loss: 3.5999  | val_0_mae: 3.71783 |  0:00:24s\n",
      "epoch 112| loss: 3.59911 | val_0_mae: 3.81041 |  0:00:24s\n",
      "epoch 113| loss: 3.49794 | val_0_mae: 3.76931 |  0:00:24s\n",
      "epoch 114| loss: 3.37071 | val_0_mae: 3.82473 |  0:00:24s\n",
      "epoch 115| loss: 3.34768 | val_0_mae: 3.64217 |  0:00:24s\n",
      "epoch 116| loss: 3.33991 | val_0_mae: 3.46021 |  0:00:25s\n",
      "epoch 117| loss: 3.38457 | val_0_mae: 3.4757  |  0:00:25s\n",
      "epoch 118| loss: 3.24698 | val_0_mae: 3.56054 |  0:00:25s\n",
      "epoch 119| loss: 3.22885 | val_0_mae: 3.48994 |  0:00:25s\n",
      "epoch 120| loss: 3.34187 | val_0_mae: 3.33387 |  0:00:25s\n",
      "epoch 121| loss: 3.31418 | val_0_mae: 3.3053  |  0:00:26s\n",
      "epoch 122| loss: 3.35573 | val_0_mae: 3.46103 |  0:00:26s\n",
      "epoch 123| loss: 3.34305 | val_0_mae: 3.36698 |  0:00:26s\n",
      "epoch 124| loss: 3.25    | val_0_mae: 3.2727  |  0:00:26s\n",
      "epoch 125| loss: 3.3145  | val_0_mae: 3.27359 |  0:00:26s\n",
      "epoch 126| loss: 3.21064 | val_0_mae: 3.40067 |  0:00:27s\n",
      "epoch 127| loss: 3.28328 | val_0_mae: 3.24957 |  0:00:27s\n",
      "epoch 128| loss: 3.18621 | val_0_mae: 3.34866 |  0:00:27s\n",
      "epoch 129| loss: 3.38702 | val_0_mae: 3.32158 |  0:00:27s\n",
      "epoch 130| loss: 3.1946  | val_0_mae: 3.36959 |  0:00:27s\n",
      "epoch 131| loss: 3.11315 | val_0_mae: 3.25928 |  0:00:28s\n",
      "epoch 132| loss: 3.20743 | val_0_mae: 3.35218 |  0:00:28s\n",
      "epoch 133| loss: 3.17234 | val_0_mae: 3.83606 |  0:00:28s\n",
      "epoch 134| loss: 3.19557 | val_0_mae: 3.46558 |  0:00:28s\n",
      "epoch 135| loss: 3.23212 | val_0_mae: 3.34707 |  0:00:28s\n",
      "epoch 136| loss: 3.22899 | val_0_mae: 3.35849 |  0:00:29s\n",
      "epoch 137| loss: 3.34173 | val_0_mae: 3.20347 |  0:00:29s\n",
      "epoch 138| loss: 3.04525 | val_0_mae: 3.03912 |  0:00:29s\n",
      "epoch 139| loss: 3.09753 | val_0_mae: 3.22524 |  0:00:29s\n",
      "epoch 140| loss: 3.21728 | val_0_mae: 3.67024 |  0:00:29s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 141| loss: 3.14675 | val_0_mae: 3.11168 |  0:00:30s\n",
      "epoch 142| loss: 3.01358 | val_0_mae: 3.34154 |  0:00:30s\n",
      "epoch 143| loss: 2.99612 | val_0_mae: 3.11405 |  0:00:30s\n",
      "epoch 144| loss: 3.06688 | val_0_mae: 3.18058 |  0:00:30s\n",
      "epoch 145| loss: 2.98266 | val_0_mae: 3.13389 |  0:00:30s\n",
      "epoch 146| loss: 3.13368 | val_0_mae: 3.18809 |  0:00:31s\n",
      "epoch 147| loss: 3.08331 | val_0_mae: 3.1195  |  0:00:31s\n",
      "epoch 148| loss: 3.05242 | val_0_mae: 3.06779 |  0:00:31s\n",
      "epoch 149| loss: 3.05825 | val_0_mae: 3.1345  |  0:00:31s\n",
      "epoch 150| loss: 3.18234 | val_0_mae: 3.22607 |  0:00:31s\n",
      "epoch 151| loss: 3.1031  | val_0_mae: 3.02819 |  0:00:32s\n",
      "epoch 152| loss: 3.05459 | val_0_mae: 3.17012 |  0:00:32s\n",
      "epoch 153| loss: 2.99837 | val_0_mae: 3.21181 |  0:00:32s\n",
      "epoch 154| loss: 3.13558 | val_0_mae: 2.98464 |  0:00:32s\n",
      "epoch 155| loss: 3.05971 | val_0_mae: 3.03645 |  0:00:32s\n",
      "epoch 156| loss: 2.98554 | val_0_mae: 3.08833 |  0:00:33s\n",
      "epoch 157| loss: 2.96808 | val_0_mae: 3.04589 |  0:00:33s\n",
      "epoch 158| loss: 3.02207 | val_0_mae: 2.98132 |  0:00:33s\n",
      "epoch 159| loss: 2.93604 | val_0_mae: 2.94322 |  0:00:33s\n",
      "epoch 160| loss: 3.00578 | val_0_mae: 3.03827 |  0:00:33s\n",
      "epoch 161| loss: 2.89541 | val_0_mae: 3.14601 |  0:00:34s\n",
      "epoch 162| loss: 2.83194 | val_0_mae: 3.11032 |  0:00:34s\n",
      "epoch 163| loss: 2.84806 | val_0_mae: 3.25785 |  0:00:34s\n",
      "epoch 164| loss: 2.93182 | val_0_mae: 3.06622 |  0:00:34s\n",
      "epoch 165| loss: 2.80416 | val_0_mae: 3.01125 |  0:00:35s\n",
      "epoch 166| loss: 2.82433 | val_0_mae: 2.97731 |  0:00:35s\n",
      "epoch 167| loss: 2.90512 | val_0_mae: 2.9806  |  0:00:35s\n",
      "epoch 168| loss: 2.98814 | val_0_mae: 2.95974 |  0:00:35s\n",
      "epoch 169| loss: 2.8207  | val_0_mae: 2.93439 |  0:00:35s\n",
      "epoch 170| loss: 2.98223 | val_0_mae: 2.95655 |  0:00:36s\n",
      "epoch 171| loss: 2.7757  | val_0_mae: 2.91778 |  0:00:36s\n",
      "epoch 172| loss: 2.82832 | val_0_mae: 2.94528 |  0:00:36s\n",
      "epoch 173| loss: 2.94562 | val_0_mae: 2.87468 |  0:00:36s\n",
      "epoch 174| loss: 2.88656 | val_0_mae: 3.00794 |  0:00:36s\n",
      "epoch 175| loss: 2.93142 | val_0_mae: 3.01749 |  0:00:37s\n",
      "epoch 176| loss: 2.78447 | val_0_mae: 2.93894 |  0:00:37s\n",
      "epoch 177| loss: 2.78781 | val_0_mae: 2.71949 |  0:00:37s\n",
      "epoch 178| loss: 2.74198 | val_0_mae: 2.71375 |  0:00:37s\n",
      "epoch 179| loss: 2.82375 | val_0_mae: 2.8632  |  0:00:37s\n",
      "epoch 180| loss: 2.63645 | val_0_mae: 2.72658 |  0:00:38s\n",
      "epoch 181| loss: 2.71738 | val_0_mae: 2.76834 |  0:00:38s\n",
      "epoch 182| loss: 2.79265 | val_0_mae: 2.741   |  0:00:38s\n",
      "epoch 183| loss: 2.6998  | val_0_mae: 2.87034 |  0:00:38s\n",
      "epoch 184| loss: 2.70603 | val_0_mae: 2.95167 |  0:00:38s\n",
      "epoch 185| loss: 2.7424  | val_0_mae: 3.0266  |  0:00:39s\n",
      "epoch 186| loss: 2.72086 | val_0_mae: 2.82239 |  0:00:39s\n",
      "epoch 187| loss: 2.65116 | val_0_mae: 2.66017 |  0:00:39s\n",
      "epoch 188| loss: 2.51608 | val_0_mae: 2.68182 |  0:00:39s\n",
      "epoch 189| loss: 2.61165 | val_0_mae: 2.83179 |  0:00:39s\n",
      "epoch 190| loss: 2.61701 | val_0_mae: 2.80037 |  0:00:40s\n",
      "epoch 191| loss: 2.73746 | val_0_mae: 2.71677 |  0:00:40s\n",
      "epoch 192| loss: 2.63825 | val_0_mae: 2.7381  |  0:00:40s\n",
      "epoch 193| loss: 2.60261 | val_0_mae: 2.74812 |  0:00:40s\n",
      "epoch 194| loss: 2.6197  | val_0_mae: 2.84313 |  0:00:40s\n",
      "epoch 195| loss: 2.59443 | val_0_mae: 2.94581 |  0:00:41s\n",
      "epoch 196| loss: 2.61395 | val_0_mae: 2.88739 |  0:00:41s\n",
      "epoch 197| loss: 2.54996 | val_0_mae: 2.8293  |  0:00:41s\n",
      "epoch 198| loss: 2.70061 | val_0_mae: 2.95275 |  0:00:41s\n",
      "epoch 199| loss: 2.59797 | val_0_mae: 2.92637 |  0:00:42s\n",
      "epoch 200| loss: 2.55306 | val_0_mae: 2.96753 |  0:00:42s\n",
      "epoch 201| loss: 2.52785 | val_0_mae: 2.72199 |  0:00:42s\n",
      "epoch 202| loss: 2.51432 | val_0_mae: 2.72238 |  0:00:42s\n",
      "epoch 203| loss: 2.46333 | val_0_mae: 2.5238  |  0:00:42s\n",
      "epoch 204| loss: 2.5063  | val_0_mae: 2.58724 |  0:00:43s\n",
      "epoch 205| loss: 2.48237 | val_0_mae: 2.6959  |  0:00:43s\n",
      "epoch 206| loss: 2.57498 | val_0_mae: 2.7381  |  0:00:43s\n",
      "epoch 207| loss: 2.50142 | val_0_mae: 2.7363  |  0:00:43s\n",
      "epoch 208| loss: 2.66038 | val_0_mae: 2.71821 |  0:00:43s\n",
      "epoch 209| loss: 2.62695 | val_0_mae: 2.56982 |  0:00:44s\n",
      "epoch 210| loss: 2.50342 | val_0_mae: 2.61977 |  0:00:44s\n",
      "epoch 211| loss: 2.45393 | val_0_mae: 2.60821 |  0:00:44s\n",
      "epoch 212| loss: 2.40992 | val_0_mae: 2.83687 |  0:00:44s\n",
      "epoch 213| loss: 2.5102  | val_0_mae: 2.7461  |  0:00:44s\n",
      "epoch 214| loss: 2.37614 | val_0_mae: 2.67257 |  0:00:44s\n",
      "epoch 215| loss: 2.40332 | val_0_mae: 2.63516 |  0:00:45s\n",
      "epoch 216| loss: 2.46084 | val_0_mae: 2.58043 |  0:00:45s\n",
      "epoch 217| loss: 2.40332 | val_0_mae: 2.55911 |  0:00:45s\n",
      "epoch 218| loss: 2.34352 | val_0_mae: 2.63381 |  0:00:45s\n",
      "epoch 219| loss: 2.43632 | val_0_mae: 2.54955 |  0:00:45s\n",
      "epoch 220| loss: 2.46205 | val_0_mae: 2.74714 |  0:00:46s\n",
      "epoch 221| loss: 2.46699 | val_0_mae: 2.61658 |  0:00:46s\n",
      "epoch 222| loss: 2.51821 | val_0_mae: 2.61999 |  0:00:46s\n",
      "epoch 223| loss: 2.51685 | val_0_mae: 2.60902 |  0:00:46s\n",
      "epoch 224| loss: 2.60737 | val_0_mae: 2.55737 |  0:00:47s\n",
      "epoch 225| loss: 2.47674 | val_0_mae: 2.57571 |  0:00:47s\n",
      "epoch 226| loss: 2.52701 | val_0_mae: 2.63605 |  0:00:47s\n",
      "epoch 227| loss: 2.42536 | val_0_mae: 2.51473 |  0:00:47s\n",
      "epoch 228| loss: 2.5143  | val_0_mae: 2.55232 |  0:00:47s\n",
      "epoch 229| loss: 2.4438  | val_0_mae: 2.57363 |  0:00:48s\n",
      "epoch 230| loss: 2.40035 | val_0_mae: 2.62431 |  0:00:48s\n",
      "epoch 231| loss: 2.39022 | val_0_mae: 2.51928 |  0:00:48s\n",
      "epoch 232| loss: 2.33599 | val_0_mae: 2.43333 |  0:00:48s\n",
      "epoch 233| loss: 2.40715 | val_0_mae: 2.55963 |  0:00:48s\n",
      "epoch 234| loss: 2.37224 | val_0_mae: 2.5307  |  0:00:49s\n",
      "epoch 235| loss: 2.25191 | val_0_mae: 2.51179 |  0:00:49s\n",
      "epoch 236| loss: 2.35772 | val_0_mae: 2.48855 |  0:00:49s\n",
      "epoch 237| loss: 2.35101 | val_0_mae: 2.59265 |  0:00:49s\n",
      "epoch 238| loss: 2.31054 | val_0_mae: 2.38218 |  0:00:49s\n",
      "epoch 239| loss: 2.16296 | val_0_mae: 2.44799 |  0:00:50s\n",
      "epoch 240| loss: 2.29553 | val_0_mae: 2.39801 |  0:00:50s\n",
      "epoch 241| loss: 2.38034 | val_0_mae: 2.53263 |  0:00:50s\n",
      "epoch 242| loss: 2.25777 | val_0_mae: 2.62347 |  0:00:50s\n",
      "epoch 243| loss: 2.48908 | val_0_mae: 2.75918 |  0:00:50s\n",
      "epoch 244| loss: 2.44844 | val_0_mae: 2.80015 |  0:00:51s\n",
      "epoch 245| loss: 2.56506 | val_0_mae: 2.78405 |  0:00:51s\n",
      "epoch 246| loss: 2.49448 | val_0_mae: 2.76179 |  0:00:51s\n",
      "epoch 247| loss: 2.45008 | val_0_mae: 2.66589 |  0:00:51s\n",
      "epoch 248| loss: 2.45974 | val_0_mae: 2.63254 |  0:00:51s\n",
      "epoch 249| loss: 2.50064 | val_0_mae: 2.72915 |  0:00:52s\n",
      "epoch 250| loss: 2.55664 | val_0_mae: 2.63909 |  0:00:52s\n",
      "epoch 251| loss: 2.48211 | val_0_mae: 2.86469 |  0:00:52s\n",
      "epoch 252| loss: 2.51685 | val_0_mae: 2.78754 |  0:00:52s\n",
      "epoch 253| loss: 2.43924 | val_0_mae: 2.5694  |  0:00:52s\n",
      "epoch 254| loss: 2.35806 | val_0_mae: 2.58534 |  0:00:53s\n",
      "epoch 255| loss: 2.41661 | val_0_mae: 2.59918 |  0:00:53s\n",
      "epoch 256| loss: 2.31326 | val_0_mae: 2.58742 |  0:00:53s\n",
      "epoch 257| loss: 2.25567 | val_0_mae: 2.61129 |  0:00:53s\n",
      "epoch 258| loss: 2.36339 | val_0_mae: 2.59939 |  0:00:54s\n",
      "epoch 259| loss: 2.33899 | val_0_mae: 2.63984 |  0:00:54s\n",
      "epoch 260| loss: 2.39821 | val_0_mae: 2.63683 |  0:00:54s\n",
      "epoch 261| loss: 2.29376 | val_0_mae: 2.46886 |  0:00:54s\n",
      "epoch 262| loss: 2.36257 | val_0_mae: 2.57282 |  0:00:54s\n",
      "epoch 263| loss: 2.32347 | val_0_mae: 2.496   |  0:00:55s\n",
      "epoch 264| loss: 2.45483 | val_0_mae: 2.48514 |  0:00:55s\n",
      "epoch 265| loss: 2.32478 | val_0_mae: 2.55984 |  0:00:55s\n",
      "epoch 266| loss: 2.25333 | val_0_mae: 2.4527  |  0:00:55s\n",
      "epoch 267| loss: 2.34059 | val_0_mae: 2.38414 |  0:00:55s\n",
      "epoch 268| loss: 2.30048 | val_0_mae: 2.54478 |  0:00:56s\n",
      "epoch 269| loss: 2.2827  | val_0_mae: 2.54129 |  0:00:56s\n",
      "epoch 270| loss: 2.34782 | val_0_mae: 2.41588 |  0:00:56s\n",
      "epoch 271| loss: 2.33802 | val_0_mae: 2.35637 |  0:00:56s\n",
      "epoch 272| loss: 2.42577 | val_0_mae: 2.38761 |  0:00:56s\n",
      "epoch 273| loss: 2.29783 | val_0_mae: 2.44523 |  0:00:57s\n",
      "epoch 274| loss: 2.27219 | val_0_mae: 2.415   |  0:00:57s\n",
      "epoch 275| loss: 2.15046 | val_0_mae: 2.34565 |  0:00:57s\n",
      "epoch 276| loss: 2.23267 | val_0_mae: 2.48027 |  0:00:57s\n",
      "epoch 277| loss: 2.22717 | val_0_mae: 2.33141 |  0:00:57s\n",
      "epoch 278| loss: 2.3979  | val_0_mae: 2.522   |  0:00:58s\n",
      "epoch 279| loss: 2.31124 | val_0_mae: 2.42147 |  0:00:58s\n",
      "epoch 280| loss: 2.29929 | val_0_mae: 2.42244 |  0:00:58s\n",
      "epoch 281| loss: 2.27302 | val_0_mae: 2.37386 |  0:00:58s\n",
      "epoch 282| loss: 2.25267 | val_0_mae: 2.36696 |  0:00:58s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 283| loss: 2.32002 | val_0_mae: 2.47993 |  0:00:59s\n",
      "epoch 284| loss: 2.2377  | val_0_mae: 2.27407 |  0:00:59s\n",
      "epoch 285| loss: 2.21499 | val_0_mae: 2.52463 |  0:00:59s\n",
      "epoch 286| loss: 2.18671 | val_0_mae: 2.45175 |  0:00:59s\n",
      "epoch 287| loss: 2.23122 | val_0_mae: 2.42717 |  0:00:59s\n",
      "epoch 288| loss: 2.3124  | val_0_mae: 2.49553 |  0:01:00s\n",
      "epoch 289| loss: 2.29697 | val_0_mae: 2.38011 |  0:01:00s\n",
      "epoch 290| loss: 2.34708 | val_0_mae: 2.48589 |  0:01:00s\n",
      "epoch 291| loss: 2.28587 | val_0_mae: 2.53793 |  0:01:00s\n",
      "epoch 292| loss: 2.19697 | val_0_mae: 2.46179 |  0:01:00s\n",
      "epoch 293| loss: 2.19084 | val_0_mae: 2.38852 |  0:01:01s\n",
      "epoch 294| loss: 2.24508 | val_0_mae: 2.38202 |  0:01:01s\n",
      "epoch 295| loss: 2.15357 | val_0_mae: 2.43556 |  0:01:01s\n",
      "epoch 296| loss: 2.15945 | val_0_mae: 2.52988 |  0:01:01s\n",
      "epoch 297| loss: 2.27082 | val_0_mae: 2.37289 |  0:01:01s\n",
      "epoch 298| loss: 2.12971 | val_0_mae: 2.37265 |  0:01:02s\n",
      "epoch 299| loss: 2.18263 | val_0_mae: 2.37608 |  0:01:02s\n",
      "epoch 300| loss: 2.22536 | val_0_mae: 2.5093  |  0:01:02s\n",
      "epoch 301| loss: 2.18726 | val_0_mae: 2.50121 |  0:01:02s\n",
      "epoch 302| loss: 2.2041  | val_0_mae: 2.4431  |  0:01:02s\n",
      "epoch 303| loss: 2.18756 | val_0_mae: 2.35948 |  0:01:03s\n",
      "epoch 304| loss: 2.16386 | val_0_mae: 2.39002 |  0:01:03s\n",
      "epoch 305| loss: 2.10953 | val_0_mae: 2.47098 |  0:01:03s\n",
      "epoch 306| loss: 2.08536 | val_0_mae: 2.29173 |  0:01:03s\n",
      "epoch 307| loss: 2.13487 | val_0_mae: 2.38597 |  0:01:03s\n",
      "epoch 308| loss: 2.16747 | val_0_mae: 2.31764 |  0:01:04s\n",
      "epoch 309| loss: 2.13475 | val_0_mae: 2.4021  |  0:01:04s\n",
      "epoch 310| loss: 2.14302 | val_0_mae: 2.43326 |  0:01:04s\n",
      "epoch 311| loss: 2.07651 | val_0_mae: 2.28799 |  0:01:04s\n",
      "epoch 312| loss: 1.98235 | val_0_mae: 2.35895 |  0:01:04s\n",
      "epoch 313| loss: 2.15084 | val_0_mae: 2.3169  |  0:01:05s\n",
      "epoch 314| loss: 2.18982 | val_0_mae: 2.3561  |  0:01:05s\n",
      "epoch 315| loss: 2.05152 | val_0_mae: 2.34353 |  0:01:05s\n",
      "epoch 316| loss: 2.00035 | val_0_mae: 2.35237 |  0:01:05s\n",
      "epoch 317| loss: 2.01846 | val_0_mae: 2.2196  |  0:01:05s\n",
      "epoch 318| loss: 2.09994 | val_0_mae: 2.24755 |  0:01:06s\n",
      "epoch 319| loss: 2.04583 | val_0_mae: 2.32645 |  0:01:06s\n",
      "epoch 320| loss: 2.12989 | val_0_mae: 2.33411 |  0:01:06s\n",
      "epoch 321| loss: 2.03711 | val_0_mae: 2.22487 |  0:01:06s\n",
      "epoch 322| loss: 2.04284 | val_0_mae: 2.21659 |  0:01:06s\n",
      "epoch 323| loss: 2.13373 | val_0_mae: 2.23369 |  0:01:07s\n",
      "epoch 324| loss: 2.15024 | val_0_mae: 2.48885 |  0:01:07s\n",
      "epoch 325| loss: 2.19131 | val_0_mae: 2.6485  |  0:01:07s\n",
      "epoch 326| loss: 2.11123 | val_0_mae: 2.54812 |  0:01:07s\n",
      "epoch 327| loss: 2.1527  | val_0_mae: 2.48188 |  0:01:07s\n",
      "epoch 328| loss: 2.3202  | val_0_mae: 2.35285 |  0:01:08s\n",
      "epoch 329| loss: 2.27864 | val_0_mae: 2.36984 |  0:01:08s\n",
      "epoch 330| loss: 2.07438 | val_0_mae: 2.427   |  0:01:08s\n",
      "epoch 331| loss: 2.24458 | val_0_mae: 2.42222 |  0:01:08s\n",
      "epoch 332| loss: 2.20327 | val_0_mae: 2.39048 |  0:01:09s\n",
      "epoch 333| loss: 2.08834 | val_0_mae: 2.48339 |  0:01:09s\n",
      "epoch 334| loss: 2.14789 | val_0_mae: 2.35663 |  0:01:09s\n",
      "epoch 335| loss: 2.08108 | val_0_mae: 2.3979  |  0:01:09s\n",
      "epoch 336| loss: 2.04141 | val_0_mae: 2.45675 |  0:01:09s\n",
      "epoch 337| loss: 2.03125 | val_0_mae: 2.41241 |  0:01:10s\n",
      "epoch 338| loss: 2.12199 | val_0_mae: 2.38307 |  0:01:10s\n",
      "epoch 339| loss: 2.07237 | val_0_mae: 2.36437 |  0:01:10s\n",
      "epoch 340| loss: 2.06968 | val_0_mae: 2.24948 |  0:01:10s\n",
      "epoch 341| loss: 2.13825 | val_0_mae: 2.67561 |  0:01:10s\n",
      "epoch 342| loss: 2.22127 | val_0_mae: 2.46445 |  0:01:11s\n",
      "epoch 343| loss: 2.13843 | val_0_mae: 2.38064 |  0:01:11s\n",
      "epoch 344| loss: 2.10411 | val_0_mae: 2.47097 |  0:01:11s\n",
      "epoch 345| loss: 2.1206  | val_0_mae: 2.47034 |  0:01:11s\n",
      "epoch 346| loss: 2.19897 | val_0_mae: 2.60324 |  0:01:11s\n",
      "epoch 347| loss: 2.45005 | val_0_mae: 2.58317 |  0:01:12s\n",
      "epoch 348| loss: 2.38184 | val_0_mae: 2.57992 |  0:01:12s\n",
      "epoch 349| loss: 2.26803 | val_0_mae: 2.60576 |  0:01:12s\n",
      "epoch 350| loss: 2.09242 | val_0_mae: 2.41148 |  0:01:12s\n",
      "epoch 351| loss: 2.16779 | val_0_mae: 2.47147 |  0:01:12s\n",
      "epoch 352| loss: 2.05875 | val_0_mae: 2.69412 |  0:01:13s\n",
      "epoch 353| loss: 2.0507  | val_0_mae: 2.49975 |  0:01:13s\n",
      "epoch 354| loss: 2.15194 | val_0_mae: 2.3915  |  0:01:13s\n",
      "epoch 355| loss: 1.983   | val_0_mae: 2.35381 |  0:01:13s\n",
      "epoch 356| loss: 2.09822 | val_0_mae: 2.27914 |  0:01:13s\n",
      "epoch 357| loss: 2.00187 | val_0_mae: 2.27369 |  0:01:14s\n",
      "epoch 358| loss: 2.00702 | val_0_mae: 2.237   |  0:01:14s\n",
      "epoch 359| loss: 2.02205 | val_0_mae: 2.23853 |  0:01:14s\n",
      "epoch 360| loss: 1.99963 | val_0_mae: 2.27952 |  0:01:14s\n",
      "epoch 361| loss: 1.91395 | val_0_mae: 2.33167 |  0:01:14s\n",
      "epoch 362| loss: 2.0632  | val_0_mae: 2.30301 |  0:01:15s\n",
      "epoch 363| loss: 2.04887 | val_0_mae: 2.38047 |  0:01:15s\n",
      "epoch 364| loss: 2.0695  | val_0_mae: 2.21926 |  0:01:15s\n",
      "epoch 365| loss: 2.04592 | val_0_mae: 2.23315 |  0:01:15s\n",
      "epoch 366| loss: 2.02314 | val_0_mae: 2.18217 |  0:01:15s\n",
      "epoch 367| loss: 2.00038 | val_0_mae: 2.19054 |  0:01:16s\n",
      "epoch 368| loss: 1.96595 | val_0_mae: 2.12831 |  0:01:16s\n",
      "epoch 369| loss: 1.94736 | val_0_mae: 2.13983 |  0:01:16s\n",
      "epoch 370| loss: 1.88504 | val_0_mae: 2.15811 |  0:01:16s\n",
      "epoch 371| loss: 1.98406 | val_0_mae: 2.13566 |  0:01:16s\n",
      "epoch 372| loss: 1.91582 | val_0_mae: 2.19762 |  0:01:17s\n",
      "epoch 373| loss: 1.95853 | val_0_mae: 2.06641 |  0:01:17s\n",
      "epoch 374| loss: 1.94111 | val_0_mae: 2.28125 |  0:01:17s\n",
      "epoch 375| loss: 1.99916 | val_0_mae: 2.60317 |  0:01:17s\n",
      "epoch 376| loss: 1.92044 | val_0_mae: 2.22574 |  0:01:17s\n",
      "epoch 377| loss: 2.00159 | val_0_mae: 2.15017 |  0:01:18s\n",
      "epoch 378| loss: 1.97692 | val_0_mae: 2.22277 |  0:01:18s\n",
      "epoch 379| loss: 2.0494  | val_0_mae: 2.17067 |  0:01:18s\n",
      "epoch 380| loss: 1.92148 | val_0_mae: 2.14728 |  0:01:18s\n",
      "epoch 381| loss: 1.98926 | val_0_mae: 2.11026 |  0:01:18s\n",
      "epoch 382| loss: 1.95217 | val_0_mae: 2.24679 |  0:01:19s\n",
      "epoch 383| loss: 1.98064 | val_0_mae: 2.33801 |  0:01:19s\n",
      "epoch 384| loss: 1.96881 | val_0_mae: 2.34247 |  0:01:19s\n",
      "epoch 385| loss: 1.90877 | val_0_mae: 2.19619 |  0:01:19s\n",
      "epoch 386| loss: 1.93911 | val_0_mae: 2.11446 |  0:01:19s\n",
      "epoch 387| loss: 1.95615 | val_0_mae: 2.14051 |  0:01:20s\n",
      "epoch 388| loss: 2.11691 | val_0_mae: 2.19599 |  0:01:20s\n",
      "epoch 389| loss: 1.99514 | val_0_mae: 2.31886 |  0:01:20s\n",
      "epoch 390| loss: 1.98353 | val_0_mae: 2.24423 |  0:01:20s\n",
      "epoch 391| loss: 2.1124  | val_0_mae: 2.27206 |  0:01:20s\n",
      "epoch 392| loss: 1.98776 | val_0_mae: 2.21992 |  0:01:21s\n",
      "epoch 393| loss: 1.95308 | val_0_mae: 2.19274 |  0:01:21s\n",
      "epoch 394| loss: 1.91366 | val_0_mae: 2.17195 |  0:01:21s\n",
      "epoch 395| loss: 1.92498 | val_0_mae: 2.15745 |  0:01:21s\n",
      "epoch 396| loss: 1.88269 | val_0_mae: 2.11817 |  0:01:21s\n",
      "epoch 397| loss: 1.86877 | val_0_mae: 2.23504 |  0:01:22s\n",
      "epoch 398| loss: 1.97187 | val_0_mae: 2.29212 |  0:01:22s\n",
      "epoch 399| loss: 1.96978 | val_0_mae: 2.32523 |  0:01:22s\n",
      "epoch 400| loss: 1.88117 | val_0_mae: 2.17289 |  0:01:22s\n",
      "epoch 401| loss: 1.93117 | val_0_mae: 2.25529 |  0:01:22s\n",
      "epoch 402| loss: 1.86299 | val_0_mae: 2.18955 |  0:01:23s\n",
      "epoch 403| loss: 1.88839 | val_0_mae: 2.14301 |  0:01:23s\n",
      "epoch 404| loss: 1.85291 | val_0_mae: 2.19134 |  0:01:23s\n",
      "epoch 405| loss: 1.87442 | val_0_mae: 2.20485 |  0:01:23s\n",
      "epoch 406| loss: 1.88673 | val_0_mae: 2.06866 |  0:01:23s\n",
      "epoch 407| loss: 1.77232 | val_0_mae: 2.08263 |  0:01:24s\n",
      "epoch 408| loss: 1.80976 | val_0_mae: 2.10544 |  0:01:24s\n",
      "epoch 409| loss: 1.8283  | val_0_mae: 2.10448 |  0:01:24s\n",
      "epoch 410| loss: 1.79538 | val_0_mae: 2.18142 |  0:01:24s\n",
      "epoch 411| loss: 1.88173 | val_0_mae: 2.21385 |  0:01:24s\n",
      "epoch 412| loss: 1.91256 | val_0_mae: 2.18577 |  0:01:25s\n",
      "epoch 413| loss: 1.85144 | val_0_mae: 2.14749 |  0:01:25s\n",
      "epoch 414| loss: 1.89901 | val_0_mae: 2.16429 |  0:01:25s\n",
      "epoch 415| loss: 1.83993 | val_0_mae: 2.17801 |  0:01:25s\n",
      "epoch 416| loss: 1.84158 | val_0_mae: 2.2487  |  0:01:25s\n",
      "epoch 417| loss: 1.89826 | val_0_mae: 2.07805 |  0:01:26s\n",
      "epoch 418| loss: 1.84131 | val_0_mae: 2.12988 |  0:01:26s\n",
      "epoch 419| loss: 1.88298 | val_0_mae: 2.13364 |  0:01:26s\n",
      "epoch 420| loss: 1.79957 | val_0_mae: 2.14367 |  0:01:26s\n",
      "epoch 421| loss: 1.89061 | val_0_mae: 2.12529 |  0:01:26s\n",
      "epoch 422| loss: 1.9105  | val_0_mae: 2.24043 |  0:01:27s\n",
      "epoch 423| loss: 1.92666 | val_0_mae: 2.26937 |  0:01:27s\n",
      "\n",
      "Early stopping occured at epoch 423 with best_epoch = 373 and best_val_0_mae = 2.06641\n",
      "Best weights from best epoch are automatically used!\n",
      "************************************************************\n",
      "Prediction MAE: 2.066409698524868\n",
      "************************************************************\n",
      "Num Fold: 2\n",
      "Train segments: 3545 Val segments: 886\n",
      "Device used : cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 22.77497| val_0_mae: 20.98271|  0:00:00s\n",
      "epoch 1  | loss: 21.76208| val_0_mae: 19.42258|  0:00:00s\n",
      "epoch 2  | loss: 20.6102 | val_0_mae: 17.81593|  0:00:00s\n",
      "epoch 3  | loss: 19.44037| val_0_mae: 16.37098|  0:00:00s\n",
      "epoch 4  | loss: 18.11905| val_0_mae: 17.93274|  0:00:01s\n",
      "epoch 5  | loss: 16.67839| val_0_mae: 14.8733 |  0:00:01s\n",
      "epoch 6  | loss: 14.75837| val_0_mae: 20.23816|  0:00:01s\n",
      "epoch 7  | loss: 12.96708| val_0_mae: 33.80388|  0:00:01s\n",
      "epoch 8  | loss: 11.59465| val_0_mae: 23.79183|  0:00:01s\n",
      "epoch 9  | loss: 10.79066| val_0_mae: 39.15563|  0:00:02s\n",
      "epoch 10 | loss: 10.74422| val_0_mae: 20.06341|  0:00:02s\n",
      "epoch 11 | loss: 10.49788| val_0_mae: 17.47858|  0:00:02s\n",
      "epoch 12 | loss: 10.00242| val_0_mae: 15.60929|  0:00:02s\n",
      "epoch 13 | loss: 9.87989 | val_0_mae: 17.17432|  0:00:02s\n",
      "epoch 14 | loss: 9.3721  | val_0_mae: 19.36864|  0:00:03s\n",
      "epoch 15 | loss: 9.13405 | val_0_mae: 19.83064|  0:00:03s\n",
      "epoch 16 | loss: 8.72662 | val_0_mae: 22.67545|  0:00:03s\n",
      "epoch 17 | loss: 8.37908 | val_0_mae: 24.23407|  0:00:03s\n",
      "epoch 18 | loss: 8.2642  | val_0_mae: 19.27005|  0:00:03s\n",
      "epoch 19 | loss: 7.9611  | val_0_mae: 14.89033|  0:00:04s\n",
      "epoch 20 | loss: 7.82262 | val_0_mae: 15.19035|  0:00:04s\n",
      "epoch 21 | loss: 7.8925  | val_0_mae: 15.82487|  0:00:04s\n",
      "epoch 22 | loss: 7.64986 | val_0_mae: 13.40684|  0:00:04s\n",
      "epoch 23 | loss: 7.32561 | val_0_mae: 12.38787|  0:00:04s\n",
      "epoch 24 | loss: 7.27678 | val_0_mae: 12.06708|  0:00:05s\n",
      "epoch 25 | loss: 7.20151 | val_0_mae: 10.2267 |  0:00:05s\n",
      "epoch 26 | loss: 7.17706 | val_0_mae: 10.27497|  0:00:05s\n",
      "epoch 27 | loss: 7.06285 | val_0_mae: 11.37004|  0:00:05s\n",
      "epoch 28 | loss: 6.82536 | val_0_mae: 11.96477|  0:00:05s\n",
      "epoch 29 | loss: 6.79832 | val_0_mae: 11.64977|  0:00:06s\n",
      "epoch 30 | loss: 6.61264 | val_0_mae: 10.68115|  0:00:06s\n",
      "epoch 31 | loss: 6.61174 | val_0_mae: 9.95896 |  0:00:06s\n",
      "epoch 32 | loss: 6.46028 | val_0_mae: 9.92882 |  0:00:06s\n",
      "epoch 33 | loss: 6.26685 | val_0_mae: 9.81063 |  0:00:07s\n",
      "epoch 34 | loss: 6.48579 | val_0_mae: 9.55178 |  0:00:07s\n",
      "epoch 35 | loss: 6.13064 | val_0_mae: 9.51346 |  0:00:07s\n",
      "epoch 36 | loss: 6.24169 | val_0_mae: 9.48135 |  0:00:07s\n",
      "epoch 37 | loss: 6.0547  | val_0_mae: 9.49507 |  0:00:08s\n",
      "epoch 38 | loss: 6.09525 | val_0_mae: 9.3821  |  0:00:08s\n",
      "epoch 39 | loss: 5.73626 | val_0_mae: 9.46277 |  0:00:08s\n",
      "epoch 40 | loss: 5.73162 | val_0_mae: 9.33515 |  0:00:08s\n",
      "epoch 41 | loss: 5.67087 | val_0_mae: 9.27816 |  0:00:08s\n",
      "epoch 42 | loss: 5.68504 | val_0_mae: 8.88489 |  0:00:09s\n",
      "epoch 43 | loss: 5.68754 | val_0_mae: 8.74992 |  0:00:09s\n",
      "epoch 44 | loss: 5.36351 | val_0_mae: 9.20147 |  0:00:09s\n",
      "epoch 45 | loss: 5.42951 | val_0_mae: 10.01273|  0:00:09s\n",
      "epoch 46 | loss: 5.37993 | val_0_mae: 9.66167 |  0:00:09s\n",
      "epoch 47 | loss: 5.22066 | val_0_mae: 9.27506 |  0:00:10s\n",
      "epoch 48 | loss: 5.33759 | val_0_mae: 9.41591 |  0:00:10s\n",
      "epoch 49 | loss: 5.34563 | val_0_mae: 10.08947|  0:00:10s\n",
      "epoch 50 | loss: 5.09211 | val_0_mae: 9.44012 |  0:00:10s\n",
      "epoch 51 | loss: 5.16708 | val_0_mae: 9.17666 |  0:00:10s\n",
      "epoch 52 | loss: 5.2775  | val_0_mae: 8.87358 |  0:00:11s\n",
      "epoch 53 | loss: 5.25504 | val_0_mae: 9.40654 |  0:00:11s\n",
      "epoch 54 | loss: 5.20494 | val_0_mae: 9.21896 |  0:00:11s\n",
      "epoch 55 | loss: 4.93534 | val_0_mae: 8.80621 |  0:00:11s\n",
      "epoch 56 | loss: 4.92024 | val_0_mae: 8.57043 |  0:00:11s\n",
      "epoch 57 | loss: 4.84522 | val_0_mae: 8.26404 |  0:00:12s\n",
      "epoch 58 | loss: 4.62653 | val_0_mae: 8.66387 |  0:00:12s\n",
      "epoch 59 | loss: 4.74514 | val_0_mae: 8.56805 |  0:00:12s\n",
      "epoch 60 | loss: 4.62431 | val_0_mae: 7.9938  |  0:00:12s\n",
      "epoch 61 | loss: 4.40435 | val_0_mae: 8.12854 |  0:00:12s\n",
      "epoch 62 | loss: 4.54347 | val_0_mae: 8.16283 |  0:00:13s\n",
      "epoch 63 | loss: 4.50311 | val_0_mae: 7.48915 |  0:00:13s\n",
      "epoch 64 | loss: 4.4692  | val_0_mae: 6.84338 |  0:00:13s\n",
      "epoch 65 | loss: 4.30957 | val_0_mae: 6.96422 |  0:00:13s\n",
      "epoch 66 | loss: 4.26611 | val_0_mae: 7.20284 |  0:00:13s\n",
      "epoch 67 | loss: 4.29362 | val_0_mae: 6.84038 |  0:00:14s\n",
      "epoch 68 | loss: 4.27176 | val_0_mae: 6.58333 |  0:00:14s\n",
      "epoch 69 | loss: 4.20883 | val_0_mae: 6.34663 |  0:00:14s\n",
      "epoch 70 | loss: 4.19199 | val_0_mae: 6.62219 |  0:00:14s\n",
      "epoch 71 | loss: 4.02819 | val_0_mae: 6.527   |  0:00:14s\n",
      "epoch 72 | loss: 3.99946 | val_0_mae: 6.07029 |  0:00:15s\n",
      "epoch 73 | loss: 4.01759 | val_0_mae: 5.35485 |  0:00:15s\n",
      "epoch 74 | loss: 4.20228 | val_0_mae: 5.45941 |  0:00:15s\n",
      "epoch 75 | loss: 3.99903 | val_0_mae: 5.36855 |  0:00:15s\n",
      "epoch 76 | loss: 3.96633 | val_0_mae: 5.69476 |  0:00:15s\n",
      "epoch 77 | loss: 4.01371 | val_0_mae: 5.33222 |  0:00:16s\n",
      "epoch 78 | loss: 4.04964 | val_0_mae: 4.98964 |  0:00:16s\n",
      "epoch 79 | loss: 3.8719  | val_0_mae: 5.23342 |  0:00:16s\n",
      "epoch 80 | loss: 3.88694 | val_0_mae: 4.79977 |  0:00:16s\n",
      "epoch 81 | loss: 3.93117 | val_0_mae: 5.22956 |  0:00:17s\n",
      "epoch 82 | loss: 3.8192  | val_0_mae: 5.09901 |  0:00:17s\n",
      "epoch 83 | loss: 3.66693 | val_0_mae: 5.00623 |  0:00:17s\n",
      "epoch 84 | loss: 3.66478 | val_0_mae: 4.61417 |  0:00:17s\n",
      "epoch 85 | loss: 3.65162 | val_0_mae: 4.75587 |  0:00:17s\n",
      "epoch 86 | loss: 3.76091 | val_0_mae: 4.69379 |  0:00:18s\n",
      "epoch 87 | loss: 3.70673 | val_0_mae: 4.47599 |  0:00:18s\n",
      "epoch 88 | loss: 3.68201 | val_0_mae: 4.44226 |  0:00:18s\n",
      "epoch 89 | loss: 3.61816 | val_0_mae: 4.28979 |  0:00:18s\n",
      "epoch 90 | loss: 3.65088 | val_0_mae: 4.16692 |  0:00:18s\n",
      "epoch 91 | loss: 3.76327 | val_0_mae: 4.2737  |  0:00:19s\n",
      "epoch 92 | loss: 3.67123 | val_0_mae: 4.14044 |  0:00:19s\n",
      "epoch 93 | loss: 3.51986 | val_0_mae: 4.0832  |  0:00:19s\n",
      "epoch 94 | loss: 3.51976 | val_0_mae: 4.07562 |  0:00:19s\n",
      "epoch 95 | loss: 3.51046 | val_0_mae: 3.81336 |  0:00:19s\n",
      "epoch 96 | loss: 3.4929  | val_0_mae: 3.92787 |  0:00:20s\n",
      "epoch 97 | loss: 3.49175 | val_0_mae: 3.99433 |  0:00:20s\n",
      "epoch 98 | loss: 3.63522 | val_0_mae: 3.91357 |  0:00:20s\n",
      "epoch 99 | loss: 3.5339  | val_0_mae: 4.07008 |  0:00:20s\n",
      "epoch 100| loss: 3.47163 | val_0_mae: 3.91219 |  0:00:20s\n",
      "epoch 101| loss: 3.49956 | val_0_mae: 3.86886 |  0:00:21s\n",
      "epoch 102| loss: 3.47124 | val_0_mae: 4.1271  |  0:00:21s\n",
      "epoch 103| loss: 3.58271 | val_0_mae: 4.05674 |  0:00:21s\n",
      "epoch 104| loss: 3.45638 | val_0_mae: 3.76509 |  0:00:21s\n",
      "epoch 105| loss: 3.48857 | val_0_mae: 3.84369 |  0:00:21s\n",
      "epoch 106| loss: 3.27582 | val_0_mae: 3.69446 |  0:00:22s\n",
      "epoch 107| loss: 3.34008 | val_0_mae: 3.64489 |  0:00:22s\n",
      "epoch 108| loss: 3.23452 | val_0_mae: 3.68628 |  0:00:22s\n",
      "epoch 109| loss: 3.29046 | val_0_mae: 3.58694 |  0:00:22s\n",
      "epoch 110| loss: 3.33501 | val_0_mae: 3.67635 |  0:00:22s\n",
      "epoch 111| loss: 3.32605 | val_0_mae: 3.72267 |  0:00:23s\n",
      "epoch 112| loss: 3.3425  | val_0_mae: 3.60833 |  0:00:23s\n",
      "epoch 113| loss: 3.13959 | val_0_mae: 3.49537 |  0:00:23s\n",
      "epoch 114| loss: 3.23281 | val_0_mae: 3.60188 |  0:00:23s\n",
      "epoch 115| loss: 3.30797 | val_0_mae: 3.63935 |  0:00:24s\n",
      "epoch 116| loss: 3.30162 | val_0_mae: 3.58871 |  0:00:24s\n",
      "epoch 117| loss: 3.28118 | val_0_mae: 3.40077 |  0:00:24s\n",
      "epoch 118| loss: 3.27281 | val_0_mae: 3.30828 |  0:00:24s\n",
      "epoch 119| loss: 3.19118 | val_0_mae: 3.29337 |  0:00:24s\n",
      "epoch 120| loss: 3.20542 | val_0_mae: 3.3707  |  0:00:25s\n",
      "epoch 121| loss: 3.228   | val_0_mae: 3.35047 |  0:00:25s\n",
      "epoch 122| loss: 3.15847 | val_0_mae: 3.3726  |  0:00:25s\n",
      "epoch 123| loss: 3.13895 | val_0_mae: 3.3013  |  0:00:25s\n",
      "epoch 124| loss: 3.17509 | val_0_mae: 3.26235 |  0:00:25s\n",
      "epoch 125| loss: 3.10803 | val_0_mae: 3.22406 |  0:00:26s\n",
      "epoch 126| loss: 3.09541 | val_0_mae: 3.39195 |  0:00:26s\n",
      "epoch 127| loss: 3.20294 | val_0_mae: 3.5161  |  0:00:26s\n",
      "epoch 128| loss: 3.13701 | val_0_mae: 3.37116 |  0:00:26s\n",
      "epoch 129| loss: 3.05043 | val_0_mae: 3.27729 |  0:00:26s\n",
      "epoch 130| loss: 3.124   | val_0_mae: 3.21821 |  0:00:27s\n",
      "epoch 131| loss: 3.00527 | val_0_mae: 3.19536 |  0:00:27s\n",
      "epoch 132| loss: 3.1791  | val_0_mae: 3.14832 |  0:00:27s\n",
      "epoch 133| loss: 3.0738  | val_0_mae: 3.21506 |  0:00:27s\n",
      "epoch 134| loss: 2.97859 | val_0_mae: 3.25932 |  0:00:27s\n",
      "epoch 135| loss: 3.00116 | val_0_mae: 3.21037 |  0:00:28s\n",
      "epoch 136| loss: 2.90136 | val_0_mae: 3.2437  |  0:00:28s\n",
      "epoch 137| loss: 2.99887 | val_0_mae: 3.16903 |  0:00:28s\n",
      "epoch 138| loss: 2.91666 | val_0_mae: 3.3384  |  0:00:28s\n",
      "epoch 139| loss: 2.90711 | val_0_mae: 3.09744 |  0:00:28s\n",
      "epoch 140| loss: 2.94023 | val_0_mae: 3.08051 |  0:00:29s\n",
      "epoch 141| loss: 2.93484 | val_0_mae: 3.21564 |  0:00:29s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 142| loss: 2.91484 | val_0_mae: 3.19997 |  0:00:29s\n",
      "epoch 143| loss: 2.85075 | val_0_mae: 3.19608 |  0:00:29s\n",
      "epoch 144| loss: 2.92827 | val_0_mae: 3.11277 |  0:00:29s\n",
      "epoch 145| loss: 2.99761 | val_0_mae: 3.04572 |  0:00:30s\n",
      "epoch 146| loss: 2.86994 | val_0_mae: 3.0807  |  0:00:30s\n",
      "epoch 147| loss: 2.83859 | val_0_mae: 3.27905 |  0:00:30s\n",
      "epoch 148| loss: 2.85878 | val_0_mae: 3.16903 |  0:00:30s\n",
      "epoch 149| loss: 2.81806 | val_0_mae: 3.03324 |  0:00:30s\n",
      "epoch 150| loss: 2.78023 | val_0_mae: 3.03059 |  0:00:31s\n",
      "epoch 151| loss: 2.79092 | val_0_mae: 3.01903 |  0:00:31s\n",
      "epoch 152| loss: 2.82515 | val_0_mae: 2.98498 |  0:00:31s\n",
      "epoch 153| loss: 2.77635 | val_0_mae: 3.09189 |  0:00:31s\n",
      "epoch 154| loss: 2.82973 | val_0_mae: 3.07922 |  0:00:31s\n",
      "epoch 155| loss: 2.78578 | val_0_mae: 3.12648 |  0:00:32s\n",
      "epoch 156| loss: 2.83798 | val_0_mae: 3.03888 |  0:00:32s\n",
      "epoch 157| loss: 2.80688 | val_0_mae: 3.01796 |  0:00:32s\n",
      "epoch 158| loss: 2.7275  | val_0_mae: 2.97352 |  0:00:32s\n",
      "epoch 159| loss: 2.67067 | val_0_mae: 3.05559 |  0:00:33s\n",
      "epoch 160| loss: 2.92944 | val_0_mae: 3.02047 |  0:00:33s\n",
      "epoch 161| loss: 2.88592 | val_0_mae: 3.09616 |  0:00:33s\n",
      "epoch 162| loss: 2.87356 | val_0_mae: 3.1085  |  0:00:33s\n",
      "epoch 163| loss: 2.83588 | val_0_mae: 2.94599 |  0:00:33s\n",
      "epoch 164| loss: 2.77397 | val_0_mae: 2.96031 |  0:00:34s\n",
      "epoch 165| loss: 2.75373 | val_0_mae: 2.97091 |  0:00:34s\n",
      "epoch 166| loss: 2.76522 | val_0_mae: 3.02769 |  0:00:34s\n",
      "epoch 167| loss: 2.64494 | val_0_mae: 2.92695 |  0:00:34s\n",
      "epoch 168| loss: 2.61079 | val_0_mae: 2.79278 |  0:00:34s\n",
      "epoch 169| loss: 2.6038  | val_0_mae: 2.79953 |  0:00:35s\n",
      "epoch 170| loss: 2.54227 | val_0_mae: 2.99604 |  0:00:35s\n",
      "epoch 171| loss: 2.58345 | val_0_mae: 2.90255 |  0:00:35s\n",
      "epoch 172| loss: 2.63776 | val_0_mae: 2.73743 |  0:00:35s\n",
      "epoch 173| loss: 2.57854 | val_0_mae: 2.7857  |  0:00:35s\n",
      "epoch 174| loss: 2.58418 | val_0_mae: 2.68186 |  0:00:36s\n",
      "epoch 175| loss: 2.58524 | val_0_mae: 2.76992 |  0:00:36s\n",
      "epoch 176| loss: 2.49304 | val_0_mae: 2.74478 |  0:00:36s\n",
      "epoch 177| loss: 2.52196 | val_0_mae: 2.79358 |  0:00:36s\n",
      "epoch 178| loss: 2.53626 | val_0_mae: 2.82898 |  0:00:36s\n",
      "epoch 179| loss: 2.60145 | val_0_mae: 2.74646 |  0:00:37s\n",
      "epoch 180| loss: 2.61171 | val_0_mae: 2.79561 |  0:00:37s\n",
      "epoch 181| loss: 2.46004 | val_0_mae: 2.76921 |  0:00:37s\n",
      "epoch 182| loss: 2.54639 | val_0_mae: 2.7902  |  0:00:37s\n",
      "epoch 183| loss: 2.45673 | val_0_mae: 2.75482 |  0:00:37s\n",
      "epoch 184| loss: 2.48652 | val_0_mae: 2.71682 |  0:00:38s\n",
      "epoch 185| loss: 2.41815 | val_0_mae: 2.66893 |  0:00:38s\n",
      "epoch 186| loss: 2.3674  | val_0_mae: 2.86491 |  0:00:38s\n",
      "epoch 187| loss: 2.44832 | val_0_mae: 2.57102 |  0:00:38s\n",
      "epoch 188| loss: 2.40132 | val_0_mae: 2.81152 |  0:00:39s\n",
      "epoch 189| loss: 2.53523 | val_0_mae: 2.67908 |  0:00:39s\n",
      "epoch 190| loss: 2.56922 | val_0_mae: 2.81683 |  0:00:39s\n",
      "epoch 191| loss: 2.38511 | val_0_mae: 2.75449 |  0:00:39s\n",
      "epoch 192| loss: 2.48972 | val_0_mae: 2.6075  |  0:00:39s\n",
      "epoch 193| loss: 2.39873 | val_0_mae: 2.709   |  0:00:40s\n",
      "epoch 194| loss: 2.44789 | val_0_mae: 2.6425  |  0:00:40s\n",
      "epoch 195| loss: 2.43185 | val_0_mae: 2.77507 |  0:00:40s\n",
      "epoch 196| loss: 2.54821 | val_0_mae: 2.6241  |  0:00:40s\n",
      "epoch 197| loss: 2.44531 | val_0_mae: 2.49405 |  0:00:40s\n",
      "epoch 198| loss: 2.31138 | val_0_mae: 2.50124 |  0:00:41s\n",
      "epoch 199| loss: 2.34525 | val_0_mae: 2.52789 |  0:00:41s\n",
      "epoch 200| loss: 2.2881  | val_0_mae: 2.59261 |  0:00:41s\n",
      "epoch 201| loss: 2.35275 | val_0_mae: 2.72541 |  0:00:41s\n",
      "epoch 202| loss: 2.35475 | val_0_mae: 2.63338 |  0:00:41s\n",
      "epoch 203| loss: 2.34353 | val_0_mae: 2.5504  |  0:00:42s\n",
      "epoch 204| loss: 2.37288 | val_0_mae: 2.54287 |  0:00:42s\n",
      "epoch 205| loss: 2.31681 | val_0_mae: 2.46775 |  0:00:42s\n",
      "epoch 206| loss: 2.38506 | val_0_mae: 2.53699 |  0:00:42s\n",
      "epoch 207| loss: 2.29593 | val_0_mae: 2.60428 |  0:00:42s\n",
      "epoch 208| loss: 2.28596 | val_0_mae: 2.59682 |  0:00:43s\n",
      "epoch 209| loss: 2.32238 | val_0_mae: 2.52305 |  0:00:43s\n",
      "epoch 210| loss: 2.25032 | val_0_mae: 2.39061 |  0:00:43s\n",
      "epoch 211| loss: 2.21646 | val_0_mae: 2.46589 |  0:00:43s\n",
      "epoch 212| loss: 2.35134 | val_0_mae: 2.38118 |  0:00:44s\n",
      "epoch 213| loss: 2.33531 | val_0_mae: 2.45519 |  0:00:44s\n",
      "epoch 214| loss: 2.3353  | val_0_mae: 2.46663 |  0:00:44s\n",
      "epoch 215| loss: 2.26879 | val_0_mae: 2.51281 |  0:00:44s\n",
      "epoch 216| loss: 2.16143 | val_0_mae: 2.44952 |  0:00:44s\n",
      "epoch 217| loss: 2.26352 | val_0_mae: 2.37757 |  0:00:45s\n",
      "epoch 218| loss: 2.24517 | val_0_mae: 2.32712 |  0:00:45s\n",
      "epoch 219| loss: 2.20152 | val_0_mae: 2.49913 |  0:00:45s\n",
      "epoch 220| loss: 2.22203 | val_0_mae: 2.29277 |  0:00:45s\n",
      "epoch 221| loss: 2.19272 | val_0_mae: 2.2895  |  0:00:45s\n",
      "epoch 222| loss: 2.26083 | val_0_mae: 2.45263 |  0:00:46s\n",
      "epoch 223| loss: 2.26667 | val_0_mae: 2.48695 |  0:00:46s\n",
      "epoch 224| loss: 2.22013 | val_0_mae: 2.42162 |  0:00:46s\n",
      "epoch 225| loss: 2.41496 | val_0_mae: 2.25288 |  0:00:46s\n",
      "epoch 226| loss: 2.23705 | val_0_mae: 2.37377 |  0:00:46s\n",
      "epoch 227| loss: 2.24333 | val_0_mae: 2.30115 |  0:00:47s\n",
      "epoch 228| loss: 2.28159 | val_0_mae: 2.44008 |  0:00:47s\n",
      "epoch 229| loss: 2.20177 | val_0_mae: 2.41087 |  0:00:47s\n",
      "epoch 230| loss: 2.13425 | val_0_mae: 2.40087 |  0:00:47s\n",
      "epoch 231| loss: 2.1824  | val_0_mae: 2.27562 |  0:00:47s\n",
      "epoch 232| loss: 2.19605 | val_0_mae: 2.42453 |  0:00:48s\n",
      "epoch 233| loss: 2.19708 | val_0_mae: 2.43713 |  0:00:48s\n",
      "epoch 234| loss: 2.19706 | val_0_mae: 2.46477 |  0:00:48s\n",
      "epoch 235| loss: 2.15975 | val_0_mae: 2.43602 |  0:00:48s\n",
      "epoch 236| loss: 2.11607 | val_0_mae: 2.32516 |  0:00:48s\n",
      "epoch 237| loss: 2.07325 | val_0_mae: 2.35163 |  0:00:49s\n",
      "epoch 238| loss: 2.06472 | val_0_mae: 2.31088 |  0:00:49s\n",
      "epoch 239| loss: 2.15924 | val_0_mae: 2.31678 |  0:00:49s\n",
      "epoch 240| loss: 2.09113 | val_0_mae: 2.39497 |  0:00:49s\n",
      "epoch 241| loss: 2.11417 | val_0_mae: 2.40031 |  0:00:49s\n",
      "epoch 242| loss: 2.08357 | val_0_mae: 2.34702 |  0:00:50s\n",
      "epoch 243| loss: 2.1475  | val_0_mae: 2.3019  |  0:00:50s\n",
      "epoch 244| loss: 2.13128 | val_0_mae: 2.30199 |  0:00:50s\n",
      "epoch 245| loss: 2.14054 | val_0_mae: 2.31249 |  0:00:50s\n",
      "epoch 246| loss: 2.15646 | val_0_mae: 2.16839 |  0:00:50s\n",
      "epoch 247| loss: 2.03608 | val_0_mae: 2.27644 |  0:00:51s\n",
      "epoch 248| loss: 2.14541 | val_0_mae: 2.47133 |  0:00:51s\n",
      "epoch 249| loss: 2.22932 | val_0_mae: 2.40685 |  0:00:51s\n",
      "epoch 250| loss: 2.20274 | val_0_mae: 2.39454 |  0:00:51s\n",
      "epoch 251| loss: 2.28676 | val_0_mae: 2.65386 |  0:00:51s\n",
      "epoch 252| loss: 2.21054 | val_0_mae: 2.36079 |  0:00:52s\n",
      "epoch 253| loss: 2.13432 | val_0_mae: 2.27375 |  0:00:52s\n",
      "epoch 254| loss: 2.14521 | val_0_mae: 2.24369 |  0:00:52s\n",
      "epoch 255| loss: 2.10677 | val_0_mae: 2.25327 |  0:00:52s\n",
      "epoch 256| loss: 2.13743 | val_0_mae: 2.2372  |  0:00:52s\n",
      "epoch 257| loss: 2.07875 | val_0_mae: 2.12017 |  0:00:53s\n",
      "epoch 258| loss: 1.97711 | val_0_mae: 2.193   |  0:00:53s\n",
      "epoch 259| loss: 2.09389 | val_0_mae: 2.17538 |  0:00:53s\n",
      "epoch 260| loss: 2.03393 | val_0_mae: 2.24605 |  0:00:53s\n",
      "epoch 261| loss: 2.08569 | val_0_mae: 2.32646 |  0:00:54s\n",
      "epoch 262| loss: 2.08461 | val_0_mae: 2.27465 |  0:00:54s\n",
      "epoch 263| loss: 2.09146 | val_0_mae: 2.37793 |  0:00:54s\n",
      "epoch 264| loss: 2.1867  | val_0_mae: 2.31946 |  0:00:54s\n",
      "epoch 265| loss: 2.14248 | val_0_mae: 2.30302 |  0:00:54s\n",
      "epoch 266| loss: 2.14002 | val_0_mae: 2.38306 |  0:00:55s\n",
      "epoch 267| loss: 2.07606 | val_0_mae: 2.35564 |  0:00:55s\n",
      "epoch 268| loss: 2.13291 | val_0_mae: 2.45661 |  0:00:55s\n",
      "epoch 269| loss: 2.06862 | val_0_mae: 2.36831 |  0:00:55s\n",
      "epoch 270| loss: 2.04011 | val_0_mae: 2.22029 |  0:00:55s\n",
      "epoch 271| loss: 2.00836 | val_0_mae: 2.24779 |  0:00:56s\n",
      "epoch 272| loss: 2.00567 | val_0_mae: 2.34262 |  0:00:56s\n",
      "epoch 273| loss: 2.03003 | val_0_mae: 2.21147 |  0:00:56s\n",
      "epoch 274| loss: 2.0883  | val_0_mae: 2.31833 |  0:00:56s\n",
      "epoch 275| loss: 2.03523 | val_0_mae: 2.24929 |  0:00:56s\n",
      "epoch 276| loss: 2.05552 | val_0_mae: 2.36004 |  0:00:57s\n",
      "epoch 277| loss: 2.09979 | val_0_mae: 2.2623  |  0:00:57s\n",
      "epoch 278| loss: 2.04306 | val_0_mae: 2.24884 |  0:00:57s\n",
      "epoch 279| loss: 2.03144 | val_0_mae: 2.20435 |  0:00:57s\n",
      "epoch 280| loss: 1.98446 | val_0_mae: 2.33706 |  0:00:57s\n",
      "epoch 281| loss: 2.11778 | val_0_mae: 2.29557 |  0:00:58s\n",
      "epoch 282| loss: 1.96024 | val_0_mae: 2.26072 |  0:00:58s\n",
      "epoch 283| loss: 1.97988 | val_0_mae: 2.19668 |  0:00:58s\n",
      "epoch 284| loss: 2.06177 | val_0_mae: 2.26576 |  0:00:58s\n",
      "epoch 285| loss: 1.958   | val_0_mae: 2.26931 |  0:00:58s\n",
      "epoch 286| loss: 2.03461 | val_0_mae: 2.24078 |  0:00:59s\n",
      "epoch 287| loss: 2.02516 | val_0_mae: 2.40849 |  0:00:59s\n",
      "epoch 288| loss: 2.00212 | val_0_mae: 2.24925 |  0:00:59s\n",
      "epoch 289| loss: 1.9983  | val_0_mae: 2.19069 |  0:00:59s\n",
      "epoch 290| loss: 2.03661 | val_0_mae: 2.15801 |  0:01:00s\n",
      "epoch 291| loss: 2.07677 | val_0_mae: 2.21957 |  0:01:00s\n",
      "epoch 292| loss: 1.98012 | val_0_mae: 2.19818 |  0:01:00s\n",
      "epoch 293| loss: 2.01658 | val_0_mae: 2.23752 |  0:01:00s\n",
      "epoch 294| loss: 1.88643 | val_0_mae: 2.28936 |  0:01:00s\n",
      "epoch 295| loss: 1.93936 | val_0_mae: 2.28858 |  0:01:01s\n",
      "epoch 296| loss: 1.94316 | val_0_mae: 2.22057 |  0:01:01s\n",
      "epoch 297| loss: 2.01593 | val_0_mae: 2.34241 |  0:01:01s\n",
      "epoch 298| loss: 2.04067 | val_0_mae: 2.18312 |  0:01:01s\n",
      "epoch 299| loss: 1.93766 | val_0_mae: 2.10878 |  0:01:01s\n",
      "epoch 300| loss: 1.96857 | val_0_mae: 2.23914 |  0:01:02s\n",
      "epoch 301| loss: 2.03852 | val_0_mae: 2.28527 |  0:01:02s\n",
      "epoch 302| loss: 2.04593 | val_0_mae: 2.15039 |  0:01:02s\n",
      "epoch 303| loss: 1.88257 | val_0_mae: 2.27156 |  0:01:02s\n",
      "epoch 304| loss: 1.96289 | val_0_mae: 2.24178 |  0:01:02s\n",
      "epoch 305| loss: 1.91663 | val_0_mae: 2.22241 |  0:01:03s\n",
      "epoch 306| loss: 2.09723 | val_0_mae: 2.17726 |  0:01:03s\n",
      "epoch 307| loss: 2.02929 | val_0_mae: 2.14771 |  0:01:03s\n",
      "epoch 308| loss: 2.04444 | val_0_mae: 2.23118 |  0:01:03s\n",
      "epoch 309| loss: 1.9291  | val_0_mae: 2.11776 |  0:01:04s\n",
      "epoch 310| loss: 1.93929 | val_0_mae: 2.04337 |  0:01:04s\n",
      "epoch 311| loss: 1.83557 | val_0_mae: 2.1063  |  0:01:04s\n",
      "epoch 312| loss: 1.84797 | val_0_mae: 2.1271  |  0:01:04s\n",
      "epoch 313| loss: 1.92748 | val_0_mae: 2.14921 |  0:01:04s\n",
      "epoch 314| loss: 1.8527  | val_0_mae: 2.09186 |  0:01:05s\n",
      "epoch 315| loss: 1.85191 | val_0_mae: 1.96993 |  0:01:05s\n",
      "epoch 316| loss: 1.92912 | val_0_mae: 2.01557 |  0:01:05s\n",
      "epoch 317| loss: 1.85665 | val_0_mae: 2.03377 |  0:01:05s\n",
      "epoch 318| loss: 1.88279 | val_0_mae: 2.12988 |  0:01:05s\n",
      "epoch 319| loss: 1.85125 | val_0_mae: 2.15672 |  0:01:06s\n",
      "epoch 320| loss: 1.90147 | val_0_mae: 2.23457 |  0:01:06s\n",
      "epoch 321| loss: 1.94847 | val_0_mae: 2.17125 |  0:01:06s\n",
      "epoch 322| loss: 1.96903 | val_0_mae: 2.17996 |  0:01:06s\n",
      "epoch 323| loss: 1.92268 | val_0_mae: 2.14903 |  0:01:06s\n",
      "epoch 324| loss: 1.8837  | val_0_mae: 2.08997 |  0:01:07s\n",
      "epoch 325| loss: 1.93158 | val_0_mae: 2.06354 |  0:01:07s\n",
      "epoch 326| loss: 1.82676 | val_0_mae: 2.16475 |  0:01:07s\n",
      "epoch 327| loss: 1.84134 | val_0_mae: 2.18559 |  0:01:07s\n",
      "epoch 328| loss: 1.87616 | val_0_mae: 2.11745 |  0:01:07s\n",
      "epoch 329| loss: 1.92814 | val_0_mae: 2.30393 |  0:01:08s\n",
      "epoch 330| loss: 1.89353 | val_0_mae: 2.0588  |  0:01:08s\n",
      "epoch 331| loss: 1.80494 | val_0_mae: 2.16327 |  0:01:08s\n",
      "epoch 332| loss: 1.89939 | val_0_mae: 2.04201 |  0:01:08s\n",
      "epoch 333| loss: 1.79061 | val_0_mae: 2.10465 |  0:01:08s\n",
      "epoch 334| loss: 1.81008 | val_0_mae: 2.0468  |  0:01:09s\n",
      "epoch 335| loss: 1.88347 | val_0_mae: 2.06867 |  0:01:09s\n",
      "epoch 336| loss: 1.84075 | val_0_mae: 2.02218 |  0:01:09s\n",
      "epoch 337| loss: 1.76658 | val_0_mae: 2.14527 |  0:01:09s\n",
      "epoch 338| loss: 1.82248 | val_0_mae: 2.11199 |  0:01:09s\n",
      "epoch 339| loss: 1.85817 | val_0_mae: 2.10564 |  0:01:10s\n",
      "epoch 340| loss: 1.80343 | val_0_mae: 2.09838 |  0:01:10s\n",
      "epoch 341| loss: 1.8276  | val_0_mae: 2.15046 |  0:01:10s\n",
      "epoch 342| loss: 1.92569 | val_0_mae: 2.06129 |  0:01:10s\n",
      "epoch 343| loss: 1.81915 | val_0_mae: 2.10014 |  0:01:11s\n",
      "epoch 344| loss: 1.8159  | val_0_mae: 2.11456 |  0:01:11s\n",
      "epoch 345| loss: 1.83321 | val_0_mae: 2.05959 |  0:01:11s\n",
      "epoch 346| loss: 1.82058 | val_0_mae: 2.00232 |  0:01:11s\n",
      "epoch 347| loss: 1.80425 | val_0_mae: 2.06783 |  0:01:11s\n",
      "epoch 348| loss: 1.7994  | val_0_mae: 2.07078 |  0:01:12s\n",
      "epoch 349| loss: 1.77973 | val_0_mae: 2.21435 |  0:01:12s\n",
      "epoch 350| loss: 1.85409 | val_0_mae: 2.06729 |  0:01:12s\n",
      "epoch 351| loss: 1.79766 | val_0_mae: 1.94543 |  0:01:12s\n",
      "epoch 352| loss: 1.78986 | val_0_mae: 2.09355 |  0:01:12s\n",
      "epoch 353| loss: 1.77033 | val_0_mae: 2.0443  |  0:01:13s\n",
      "epoch 354| loss: 1.75906 | val_0_mae: 2.03015 |  0:01:13s\n",
      "epoch 355| loss: 1.75118 | val_0_mae: 2.12691 |  0:01:13s\n",
      "epoch 356| loss: 1.74084 | val_0_mae: 2.11473 |  0:01:13s\n",
      "epoch 357| loss: 1.83495 | val_0_mae: 2.128   |  0:01:13s\n",
      "epoch 358| loss: 1.79552 | val_0_mae: 2.16361 |  0:01:14s\n",
      "epoch 359| loss: 1.83592 | val_0_mae: 2.04419 |  0:01:14s\n",
      "epoch 360| loss: 1.81151 | val_0_mae: 2.05233 |  0:01:14s\n",
      "epoch 361| loss: 1.71797 | val_0_mae: 2.12715 |  0:01:14s\n",
      "epoch 362| loss: 1.78472 | val_0_mae: 2.18582 |  0:01:14s\n",
      "epoch 363| loss: 1.75852 | val_0_mae: 2.09743 |  0:01:15s\n",
      "epoch 364| loss: 1.78261 | val_0_mae: 2.07556 |  0:01:15s\n",
      "epoch 365| loss: 1.74675 | val_0_mae: 2.10947 |  0:01:15s\n",
      "epoch 366| loss: 1.8159  | val_0_mae: 2.15553 |  0:01:15s\n",
      "epoch 367| loss: 1.76474 | val_0_mae: 2.15741 |  0:01:15s\n",
      "epoch 368| loss: 1.79631 | val_0_mae: 2.14573 |  0:01:16s\n",
      "epoch 369| loss: 1.79095 | val_0_mae: 2.1065  |  0:01:16s\n",
      "epoch 370| loss: 1.80133 | val_0_mae: 2.08196 |  0:01:16s\n",
      "epoch 371| loss: 1.74227 | val_0_mae: 2.06478 |  0:01:16s\n",
      "epoch 372| loss: 1.73439 | val_0_mae: 2.03296 |  0:01:16s\n",
      "epoch 373| loss: 1.746   | val_0_mae: 2.00934 |  0:01:17s\n",
      "epoch 374| loss: 1.69274 | val_0_mae: 2.1284  |  0:01:17s\n",
      "epoch 375| loss: 1.76858 | val_0_mae: 2.08746 |  0:01:17s\n",
      "epoch 376| loss: 1.6682  | val_0_mae: 2.04707 |  0:01:17s\n",
      "epoch 377| loss: 1.79828 | val_0_mae: 1.96432 |  0:01:17s\n",
      "epoch 378| loss: 1.74295 | val_0_mae: 2.00143 |  0:01:18s\n",
      "epoch 379| loss: 1.78324 | val_0_mae: 2.06033 |  0:01:18s\n",
      "epoch 380| loss: 1.83286 | val_0_mae: 2.04599 |  0:01:18s\n",
      "epoch 381| loss: 1.81791 | val_0_mae: 2.02209 |  0:01:18s\n",
      "epoch 382| loss: 1.85685 | val_0_mae: 1.97901 |  0:01:18s\n",
      "epoch 383| loss: 1.65701 | val_0_mae: 2.07251 |  0:01:19s\n",
      "epoch 384| loss: 1.81517 | val_0_mae: 1.88787 |  0:01:19s\n",
      "epoch 385| loss: 1.72576 | val_0_mae: 1.90946 |  0:01:19s\n",
      "epoch 386| loss: 1.6792  | val_0_mae: 1.96191 |  0:01:19s\n",
      "epoch 387| loss: 1.69693 | val_0_mae: 1.93663 |  0:01:19s\n",
      "epoch 388| loss: 1.70333 | val_0_mae: 1.92768 |  0:01:20s\n",
      "epoch 389| loss: 1.59976 | val_0_mae: 1.92897 |  0:01:20s\n",
      "epoch 390| loss: 1.64647 | val_0_mae: 1.9291  |  0:01:20s\n",
      "epoch 391| loss: 1.62181 | val_0_mae: 1.99458 |  0:01:20s\n",
      "epoch 392| loss: 1.66965 | val_0_mae: 2.10664 |  0:01:20s\n",
      "epoch 393| loss: 1.73041 | val_0_mae: 1.95911 |  0:01:21s\n",
      "epoch 394| loss: 1.69345 | val_0_mae: 1.93786 |  0:01:21s\n",
      "epoch 395| loss: 1.81658 | val_0_mae: 1.96152 |  0:01:21s\n",
      "epoch 396| loss: 1.73028 | val_0_mae: 1.9708  |  0:01:21s\n",
      "epoch 397| loss: 1.76011 | val_0_mae: 2.03624 |  0:01:21s\n",
      "epoch 398| loss: 1.77748 | val_0_mae: 2.01424 |  0:01:22s\n",
      "epoch 399| loss: 1.7508  | val_0_mae: 1.99025 |  0:01:22s\n",
      "epoch 400| loss: 1.73442 | val_0_mae: 1.89842 |  0:01:22s\n",
      "epoch 401| loss: 1.71365 | val_0_mae: 2.09742 |  0:01:22s\n",
      "epoch 402| loss: 1.70042 | val_0_mae: 2.03676 |  0:01:22s\n",
      "epoch 403| loss: 1.72235 | val_0_mae: 1.92387 |  0:01:23s\n",
      "epoch 404| loss: 1.75729 | val_0_mae: 2.02472 |  0:01:23s\n",
      "epoch 405| loss: 1.70172 | val_0_mae: 2.02897 |  0:01:23s\n",
      "epoch 406| loss: 1.82971 | val_0_mae: 2.00485 |  0:01:23s\n",
      "epoch 407| loss: 1.84851 | val_0_mae: 1.98991 |  0:01:23s\n",
      "epoch 408| loss: 1.92754 | val_0_mae: 2.03259 |  0:01:24s\n",
      "epoch 409| loss: 1.90603 | val_0_mae: 2.14825 |  0:01:24s\n",
      "epoch 410| loss: 1.85755 | val_0_mae: 1.97875 |  0:01:24s\n",
      "epoch 411| loss: 1.8026  | val_0_mae: 2.00868 |  0:01:24s\n",
      "epoch 412| loss: 1.72081 | val_0_mae: 2.02911 |  0:01:24s\n",
      "epoch 413| loss: 1.74223 | val_0_mae: 1.98934 |  0:01:25s\n",
      "epoch 414| loss: 1.74377 | val_0_mae: 1.95035 |  0:01:25s\n",
      "epoch 415| loss: 1.80734 | val_0_mae: 1.93948 |  0:01:25s\n",
      "epoch 416| loss: 1.75288 | val_0_mae: 1.94714 |  0:01:25s\n",
      "epoch 417| loss: 1.75597 | val_0_mae: 2.00901 |  0:01:26s\n",
      "epoch 418| loss: 1.9094  | val_0_mae: 1.96667 |  0:01:26s\n",
      "epoch 419| loss: 1.79832 | val_0_mae: 1.9001  |  0:01:26s\n",
      "epoch 420| loss: 1.76906 | val_0_mae: 1.95617 |  0:01:26s\n",
      "epoch 421| loss: 1.88849 | val_0_mae: 1.98504 |  0:01:26s\n",
      "epoch 422| loss: 1.80733 | val_0_mae: 1.95037 |  0:01:26s\n",
      "epoch 423| loss: 1.71292 | val_0_mae: 1.89923 |  0:01:27s\n",
      "epoch 424| loss: 1.65346 | val_0_mae: 1.99867 |  0:01:27s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 425| loss: 1.72246 | val_0_mae: 2.01231 |  0:01:27s\n",
      "epoch 426| loss: 1.82657 | val_0_mae: 2.16003 |  0:01:27s\n",
      "epoch 427| loss: 1.80361 | val_0_mae: 2.11396 |  0:01:27s\n",
      "epoch 428| loss: 1.75058 | val_0_mae: 2.09966 |  0:01:28s\n",
      "epoch 429| loss: 1.70495 | val_0_mae: 2.04808 |  0:01:28s\n",
      "epoch 430| loss: 1.7619  | val_0_mae: 1.93585 |  0:01:28s\n",
      "epoch 431| loss: 1.6853  | val_0_mae: 1.86025 |  0:01:28s\n",
      "epoch 432| loss: 1.72008 | val_0_mae: 2.02025 |  0:01:29s\n",
      "epoch 433| loss: 1.68399 | val_0_mae: 1.98021 |  0:01:29s\n",
      "epoch 434| loss: 1.71572 | val_0_mae: 1.89275 |  0:01:29s\n",
      "epoch 435| loss: 1.67268 | val_0_mae: 1.81226 |  0:01:29s\n",
      "epoch 436| loss: 1.68629 | val_0_mae: 1.88545 |  0:01:29s\n",
      "epoch 437| loss: 1.61695 | val_0_mae: 1.90285 |  0:01:30s\n",
      "epoch 438| loss: 1.69476 | val_0_mae: 1.97009 |  0:01:30s\n",
      "epoch 439| loss: 1.74199 | val_0_mae: 1.97797 |  0:01:30s\n",
      "epoch 440| loss: 1.66568 | val_0_mae: 1.97393 |  0:01:30s\n",
      "epoch 441| loss: 1.6976  | val_0_mae: 1.96474 |  0:01:30s\n",
      "epoch 442| loss: 1.74383 | val_0_mae: 1.91442 |  0:01:31s\n",
      "epoch 443| loss: 1.7058  | val_0_mae: 1.92052 |  0:01:31s\n",
      "epoch 444| loss: 1.6616  | val_0_mae: 1.97047 |  0:01:31s\n",
      "epoch 445| loss: 1.6025  | val_0_mae: 1.96358 |  0:01:31s\n",
      "epoch 446| loss: 1.70309 | val_0_mae: 1.84417 |  0:01:31s\n",
      "epoch 447| loss: 1.64699 | val_0_mae: 1.95009 |  0:01:32s\n",
      "epoch 448| loss: 1.71112 | val_0_mae: 1.94614 |  0:01:32s\n",
      "epoch 449| loss: 1.65041 | val_0_mae: 2.0519  |  0:01:32s\n",
      "epoch 450| loss: 1.7526  | val_0_mae: 2.04311 |  0:01:32s\n",
      "epoch 451| loss: 1.70176 | val_0_mae: 1.9191  |  0:01:32s\n",
      "epoch 452| loss: 1.65821 | val_0_mae: 1.86177 |  0:01:33s\n",
      "epoch 453| loss: 1.67709 | val_0_mae: 1.93591 |  0:01:33s\n",
      "epoch 454| loss: 1.70038 | val_0_mae: 2.06279 |  0:01:33s\n",
      "epoch 455| loss: 1.72871 | val_0_mae: 1.99497 |  0:01:33s\n",
      "epoch 456| loss: 1.70136 | val_0_mae: 1.89786 |  0:01:33s\n",
      "epoch 457| loss: 1.75295 | val_0_mae: 1.89938 |  0:01:34s\n",
      "epoch 458| loss: 1.77179 | val_0_mae: 1.92103 |  0:01:34s\n",
      "epoch 459| loss: 1.78968 | val_0_mae: 1.88744 |  0:01:34s\n",
      "epoch 460| loss: 1.67565 | val_0_mae: 2.01908 |  0:01:34s\n",
      "epoch 461| loss: 1.69948 | val_0_mae: 2.01797 |  0:01:35s\n",
      "epoch 462| loss: 1.66837 | val_0_mae: 1.91745 |  0:01:35s\n",
      "epoch 463| loss: 1.8024  | val_0_mae: 1.97534 |  0:01:35s\n",
      "epoch 464| loss: 1.72425 | val_0_mae: 1.89811 |  0:01:35s\n",
      "epoch 465| loss: 1.72882 | val_0_mae: 1.91717 |  0:01:35s\n",
      "epoch 466| loss: 1.74255 | val_0_mae: 1.85995 |  0:01:36s\n",
      "epoch 467| loss: 1.70543 | val_0_mae: 1.92635 |  0:01:36s\n",
      "epoch 468| loss: 1.66193 | val_0_mae: 1.93994 |  0:01:36s\n",
      "epoch 469| loss: 1.66736 | val_0_mae: 1.8985  |  0:01:36s\n",
      "epoch 470| loss: 1.68804 | val_0_mae: 1.98498 |  0:01:36s\n",
      "epoch 471| loss: 1.73778 | val_0_mae: 1.93022 |  0:01:37s\n",
      "epoch 472| loss: 1.60386 | val_0_mae: 1.87942 |  0:01:37s\n",
      "epoch 473| loss: 1.60827 | val_0_mae: 1.8889  |  0:01:37s\n",
      "epoch 474| loss: 1.60997 | val_0_mae: 1.84445 |  0:01:37s\n",
      "epoch 475| loss: 1.59568 | val_0_mae: 1.84627 |  0:01:38s\n",
      "epoch 476| loss: 1.58265 | val_0_mae: 1.83585 |  0:01:38s\n",
      "epoch 477| loss: 1.58398 | val_0_mae: 1.83698 |  0:01:38s\n",
      "epoch 478| loss: 1.55487 | val_0_mae: 1.92957 |  0:01:38s\n",
      "epoch 479| loss: 1.58964 | val_0_mae: 1.82801 |  0:01:38s\n",
      "epoch 480| loss: 1.54963 | val_0_mae: 1.86116 |  0:01:39s\n",
      "epoch 481| loss: 1.55925 | val_0_mae: 1.91668 |  0:01:39s\n",
      "epoch 482| loss: 1.59924 | val_0_mae: 1.8767  |  0:01:39s\n",
      "epoch 483| loss: 1.61413 | val_0_mae: 1.89706 |  0:01:39s\n",
      "epoch 484| loss: 1.65138 | val_0_mae: 2.04094 |  0:01:39s\n",
      "epoch 485| loss: 1.67272 | val_0_mae: 1.95567 |  0:01:40s\n",
      "\n",
      "Early stopping occured at epoch 485 with best_epoch = 435 and best_val_0_mae = 1.81226\n",
      "Best weights from best epoch are automatically used!\n",
      "************************************************************\n",
      "Prediction MAE: 1.812262806266992\n",
      "************************************************************\n",
      "Num Fold: 3\n",
      "Train segments: 3545 Val segments: 886\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 22.5973 | val_0_mae: 23.37454|  0:00:00s\n",
      "epoch 1  | loss: 21.52877| val_0_mae: 25.0175 |  0:00:00s\n",
      "epoch 2  | loss: 20.57394| val_0_mae: 21.80472|  0:00:00s\n",
      "epoch 3  | loss: 19.43173| val_0_mae: 18.02723|  0:00:00s\n",
      "epoch 4  | loss: 18.11871| val_0_mae: 15.56533|  0:00:01s\n",
      "epoch 5  | loss: 16.61334| val_0_mae: 19.34751|  0:00:01s\n",
      "epoch 6  | loss: 14.867  | val_0_mae: 27.81437|  0:00:01s\n",
      "epoch 7  | loss: 12.98744| val_0_mae: 16.14296|  0:00:01s\n",
      "epoch 8  | loss: 11.29656| val_0_mae: 16.80756|  0:00:01s\n",
      "epoch 9  | loss: 10.11605| val_0_mae: 14.97127|  0:00:02s\n",
      "epoch 10 | loss: 9.53383 | val_0_mae: 12.75309|  0:00:02s\n",
      "epoch 11 | loss: 9.2684  | val_0_mae: 12.4276 |  0:00:02s\n",
      "epoch 12 | loss: 8.88355 | val_0_mae: 13.08994|  0:00:02s\n",
      "epoch 13 | loss: 9.09874 | val_0_mae: 13.41072|  0:00:02s\n",
      "epoch 14 | loss: 8.81673 | val_0_mae: 13.56227|  0:00:03s\n",
      "epoch 15 | loss: 8.44939 | val_0_mae: 14.7543 |  0:00:03s\n",
      "epoch 16 | loss: 8.14033 | val_0_mae: 14.51243|  0:00:03s\n",
      "epoch 17 | loss: 7.89871 | val_0_mae: 14.26631|  0:00:03s\n",
      "epoch 18 | loss: 7.57825 | val_0_mae: 15.13911|  0:00:03s\n",
      "epoch 19 | loss: 7.34582 | val_0_mae: 14.97713|  0:00:04s\n",
      "epoch 20 | loss: 7.07161 | val_0_mae: 13.92402|  0:00:04s\n",
      "epoch 21 | loss: 6.93899 | val_0_mae: 14.05439|  0:00:04s\n",
      "epoch 22 | loss: 6.95391 | val_0_mae: 13.29875|  0:00:04s\n",
      "epoch 23 | loss: 6.67803 | val_0_mae: 13.03428|  0:00:04s\n",
      "epoch 24 | loss: 6.85081 | val_0_mae: 12.83594|  0:00:05s\n",
      "epoch 25 | loss: 6.8149  | val_0_mae: 12.2404 |  0:00:05s\n",
      "epoch 26 | loss: 6.41635 | val_0_mae: 12.42684|  0:00:05s\n",
      "epoch 27 | loss: 6.11986 | val_0_mae: 12.396  |  0:00:05s\n",
      "epoch 28 | loss: 5.98178 | val_0_mae: 13.04951|  0:00:05s\n",
      "epoch 29 | loss: 5.94869 | val_0_mae: 12.33571|  0:00:06s\n",
      "epoch 30 | loss: 6.04438 | val_0_mae: 12.68241|  0:00:06s\n",
      "epoch 31 | loss: 5.82368 | val_0_mae: 12.17509|  0:00:06s\n",
      "epoch 32 | loss: 5.91264 | val_0_mae: 13.13652|  0:00:06s\n",
      "epoch 33 | loss: 5.90291 | val_0_mae: 11.42871|  0:00:07s\n",
      "epoch 34 | loss: 5.71779 | val_0_mae: 12.40105|  0:00:07s\n",
      "epoch 35 | loss: 5.58518 | val_0_mae: 13.6448 |  0:00:07s\n",
      "epoch 36 | loss: 5.56438 | val_0_mae: 11.69864|  0:00:07s\n",
      "epoch 37 | loss: 5.41993 | val_0_mae: 10.52256|  0:00:07s\n",
      "epoch 38 | loss: 5.59054 | val_0_mae: 10.90475|  0:00:08s\n",
      "epoch 39 | loss: 5.40969 | val_0_mae: 10.71471|  0:00:08s\n",
      "epoch 40 | loss: 5.13839 | val_0_mae: 9.89733 |  0:00:08s\n",
      "epoch 41 | loss: 5.03291 | val_0_mae: 9.66517 |  0:00:08s\n",
      "epoch 42 | loss: 4.94685 | val_0_mae: 9.60465 |  0:00:08s\n",
      "epoch 43 | loss: 5.06456 | val_0_mae: 9.89036 |  0:00:09s\n",
      "epoch 44 | loss: 5.02276 | val_0_mae: 10.03043|  0:00:09s\n",
      "epoch 45 | loss: 5.24692 | val_0_mae: 10.0737 |  0:00:09s\n",
      "epoch 46 | loss: 4.99018 | val_0_mae: 9.39826 |  0:00:09s\n",
      "epoch 47 | loss: 5.13619 | val_0_mae: 9.1412  |  0:00:09s\n",
      "epoch 48 | loss: 4.99904 | val_0_mae: 9.30716 |  0:00:10s\n",
      "epoch 49 | loss: 4.80151 | val_0_mae: 8.59285 |  0:00:10s\n",
      "epoch 50 | loss: 4.69325 | val_0_mae: 8.80648 |  0:00:10s\n",
      "epoch 51 | loss: 4.71109 | val_0_mae: 8.99209 |  0:00:10s\n",
      "epoch 52 | loss: 4.53909 | val_0_mae: 8.85984 |  0:00:10s\n",
      "epoch 53 | loss: 4.4249  | val_0_mae: 8.89547 |  0:00:11s\n",
      "epoch 54 | loss: 4.41442 | val_0_mae: 8.24081 |  0:00:11s\n",
      "epoch 55 | loss: 4.31371 | val_0_mae: 8.30093 |  0:00:11s\n",
      "epoch 56 | loss: 4.324   | val_0_mae: 8.24506 |  0:00:11s\n",
      "epoch 57 | loss: 4.53272 | val_0_mae: 8.72687 |  0:00:11s\n",
      "epoch 58 | loss: 4.36482 | val_0_mae: 8.30731 |  0:00:12s\n",
      "epoch 59 | loss: 4.37473 | val_0_mae: 7.42805 |  0:00:12s\n",
      "epoch 60 | loss: 4.40053 | val_0_mae: 7.18266 |  0:00:12s\n",
      "epoch 61 | loss: 4.33577 | val_0_mae: 7.87455 |  0:00:12s\n",
      "epoch 62 | loss: 4.18611 | val_0_mae: 8.08448 |  0:00:12s\n",
      "epoch 63 | loss: 4.35275 | val_0_mae: 8.00744 |  0:00:13s\n",
      "epoch 64 | loss: 4.15648 | val_0_mae: 7.58129 |  0:00:13s\n",
      "epoch 65 | loss: 4.0593  | val_0_mae: 7.8148  |  0:00:13s\n",
      "epoch 66 | loss: 4.07559 | val_0_mae: 6.99206 |  0:00:13s\n",
      "epoch 67 | loss: 3.96209 | val_0_mae: 6.53899 |  0:00:13s\n",
      "epoch 68 | loss: 4.14038 | val_0_mae: 6.80737 |  0:00:14s\n",
      "epoch 69 | loss: 3.92192 | val_0_mae: 6.73112 |  0:00:14s\n",
      "epoch 70 | loss: 3.90004 | val_0_mae: 6.28644 |  0:00:14s\n",
      "epoch 71 | loss: 4.18312 | val_0_mae: 6.62586 |  0:00:14s\n",
      "epoch 72 | loss: 4.08961 | val_0_mae: 6.11645 |  0:00:14s\n",
      "epoch 73 | loss: 3.85953 | val_0_mae: 4.95811 |  0:00:15s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 74 | loss: 3.90167 | val_0_mae: 4.83929 |  0:00:15s\n",
      "epoch 75 | loss: 3.87164 | val_0_mae: 4.70772 |  0:00:15s\n",
      "epoch 76 | loss: 3.89715 | val_0_mae: 4.59451 |  0:00:15s\n",
      "epoch 77 | loss: 3.80078 | val_0_mae: 4.41228 |  0:00:15s\n",
      "epoch 78 | loss: 3.79327 | val_0_mae: 4.89145 |  0:00:16s\n",
      "epoch 79 | loss: 3.81153 | val_0_mae: 4.32774 |  0:00:16s\n",
      "epoch 80 | loss: 3.88968 | val_0_mae: 4.21167 |  0:00:16s\n",
      "epoch 81 | loss: 3.77981 | val_0_mae: 4.39359 |  0:00:16s\n",
      "epoch 82 | loss: 3.87955 | val_0_mae: 4.71159 |  0:00:16s\n",
      "epoch 83 | loss: 3.79659 | val_0_mae: 4.41697 |  0:00:17s\n",
      "epoch 84 | loss: 3.69343 | val_0_mae: 4.35362 |  0:00:17s\n",
      "epoch 85 | loss: 3.67261 | val_0_mae: 4.40769 |  0:00:17s\n",
      "epoch 86 | loss: 3.90541 | val_0_mae: 3.89535 |  0:00:17s\n",
      "epoch 87 | loss: 3.63427 | val_0_mae: 3.69098 |  0:00:17s\n",
      "epoch 88 | loss: 3.65268 | val_0_mae: 4.28106 |  0:00:18s\n",
      "epoch 89 | loss: 3.66897 | val_0_mae: 3.9792  |  0:00:18s\n",
      "epoch 90 | loss: 3.68345 | val_0_mae: 3.6851  |  0:00:18s\n",
      "epoch 91 | loss: 3.60377 | val_0_mae: 3.94695 |  0:00:18s\n",
      "epoch 92 | loss: 3.64902 | val_0_mae: 3.85188 |  0:00:18s\n",
      "epoch 93 | loss: 3.66335 | val_0_mae: 3.58428 |  0:00:19s\n",
      "epoch 94 | loss: 3.78887 | val_0_mae: 3.85368 |  0:00:19s\n",
      "epoch 95 | loss: 3.62005 | val_0_mae: 3.81543 |  0:00:19s\n",
      "epoch 96 | loss: 3.56768 | val_0_mae: 3.68676 |  0:00:19s\n",
      "epoch 97 | loss: 3.52833 | val_0_mae: 4.01234 |  0:00:20s\n",
      "epoch 98 | loss: 3.45131 | val_0_mae: 3.91394 |  0:00:20s\n",
      "epoch 99 | loss: 3.39611 | val_0_mae: 3.71979 |  0:00:20s\n",
      "epoch 100| loss: 3.3522  | val_0_mae: 3.62485 |  0:00:20s\n",
      "epoch 101| loss: 3.30805 | val_0_mae: 3.43959 |  0:00:20s\n",
      "epoch 102| loss: 3.32382 | val_0_mae: 3.57549 |  0:00:21s\n",
      "epoch 103| loss: 3.3932  | val_0_mae: 3.44158 |  0:00:21s\n",
      "epoch 104| loss: 3.48037 | val_0_mae: 3.55781 |  0:00:21s\n",
      "epoch 105| loss: 3.40154 | val_0_mae: 3.37998 |  0:00:21s\n",
      "epoch 106| loss: 3.39637 | val_0_mae: 3.37937 |  0:00:21s\n",
      "epoch 107| loss: 3.4136  | val_0_mae: 3.34445 |  0:00:22s\n",
      "epoch 108| loss: 3.3245  | val_0_mae: 3.29388 |  0:00:22s\n",
      "epoch 109| loss: 3.35825 | val_0_mae: 3.35746 |  0:00:22s\n",
      "epoch 110| loss: 3.35164 | val_0_mae: 3.50459 |  0:00:22s\n",
      "epoch 111| loss: 3.37915 | val_0_mae: 3.32626 |  0:00:22s\n",
      "epoch 112| loss: 3.32087 | val_0_mae: 3.30451 |  0:00:23s\n",
      "epoch 113| loss: 3.3221  | val_0_mae: 3.09384 |  0:00:23s\n",
      "epoch 114| loss: 3.11186 | val_0_mae: 3.32626 |  0:00:23s\n",
      "epoch 115| loss: 3.19441 | val_0_mae: 3.33373 |  0:00:23s\n",
      "epoch 116| loss: 3.13954 | val_0_mae: 3.31103 |  0:00:23s\n",
      "epoch 117| loss: 3.28255 | val_0_mae: 3.26109 |  0:00:24s\n",
      "epoch 118| loss: 3.17548 | val_0_mae: 3.12852 |  0:00:24s\n",
      "epoch 119| loss: 3.08552 | val_0_mae: 3.09423 |  0:00:24s\n",
      "epoch 120| loss: 3.23877 | val_0_mae: 3.19816 |  0:00:24s\n",
      "epoch 121| loss: 3.1252  | val_0_mae: 2.92039 |  0:00:24s\n",
      "epoch 122| loss: 3.08867 | val_0_mae: 2.91955 |  0:00:25s\n",
      "epoch 123| loss: 2.95813 | val_0_mae: 3.0109  |  0:00:25s\n",
      "epoch 124| loss: 3.01096 | val_0_mae: 2.84218 |  0:00:25s\n",
      "epoch 125| loss: 2.96983 | val_0_mae: 2.86136 |  0:00:25s\n",
      "epoch 126| loss: 3.04297 | val_0_mae: 2.85259 |  0:00:25s\n",
      "epoch 127| loss: 3.05863 | val_0_mae: 2.87586 |  0:00:26s\n",
      "epoch 128| loss: 2.97206 | val_0_mae: 2.91333 |  0:00:26s\n",
      "epoch 129| loss: 3.03874 | val_0_mae: 2.97724 |  0:00:26s\n",
      "epoch 130| loss: 3.02011 | val_0_mae: 2.84359 |  0:00:26s\n",
      "epoch 131| loss: 2.9553  | val_0_mae: 3.1101  |  0:00:26s\n",
      "epoch 132| loss: 2.99419 | val_0_mae: 2.97883 |  0:00:27s\n",
      "epoch 133| loss: 2.87976 | val_0_mae: 2.97892 |  0:00:27s\n",
      "epoch 134| loss: 2.91368 | val_0_mae: 2.95906 |  0:00:27s\n",
      "epoch 135| loss: 2.8775  | val_0_mae: 3.03315 |  0:00:27s\n",
      "epoch 136| loss: 2.92019 | val_0_mae: 2.98053 |  0:00:27s\n",
      "epoch 137| loss: 2.87315 | val_0_mae: 3.00667 |  0:00:28s\n",
      "epoch 138| loss: 2.93066 | val_0_mae: 2.96517 |  0:00:28s\n",
      "epoch 139| loss: 2.83975 | val_0_mae: 2.95899 |  0:00:28s\n",
      "epoch 140| loss: 2.98103 | val_0_mae: 2.7899  |  0:00:28s\n",
      "epoch 141| loss: 2.77592 | val_0_mae: 2.77104 |  0:00:28s\n",
      "epoch 142| loss: 2.98151 | val_0_mae: 2.94262 |  0:00:29s\n",
      "epoch 143| loss: 2.90105 | val_0_mae: 2.96687 |  0:00:29s\n",
      "epoch 144| loss: 2.82454 | val_0_mae: 3.10892 |  0:00:29s\n",
      "epoch 145| loss: 2.98039 | val_0_mae: 2.90267 |  0:00:29s\n",
      "epoch 146| loss: 2.83496 | val_0_mae: 2.91032 |  0:00:29s\n",
      "epoch 147| loss: 2.79082 | val_0_mae: 2.8309  |  0:00:30s\n",
      "epoch 148| loss: 2.71159 | val_0_mae: 2.81375 |  0:00:30s\n",
      "epoch 149| loss: 2.73284 | val_0_mae: 2.74915 |  0:00:30s\n",
      "epoch 150| loss: 2.70624 | val_0_mae: 2.75091 |  0:00:30s\n",
      "epoch 151| loss: 2.69258 | val_0_mae: 2.70091 |  0:00:31s\n",
      "epoch 152| loss: 2.87063 | val_0_mae: 2.8261  |  0:00:31s\n",
      "epoch 153| loss: 2.82521 | val_0_mae: 2.87149 |  0:00:31s\n",
      "epoch 154| loss: 2.85443 | val_0_mae: 2.79921 |  0:00:31s\n",
      "epoch 155| loss: 2.74396 | val_0_mae: 2.69324 |  0:00:31s\n",
      "epoch 156| loss: 2.71595 | val_0_mae: 2.80208 |  0:00:32s\n",
      "epoch 157| loss: 2.75963 | val_0_mae: 2.86819 |  0:00:32s\n",
      "epoch 158| loss: 2.81127 | val_0_mae: 2.83689 |  0:00:32s\n",
      "epoch 159| loss: 2.8714  | val_0_mae: 2.85268 |  0:00:32s\n",
      "epoch 160| loss: 2.91168 | val_0_mae: 2.73144 |  0:00:32s\n",
      "epoch 161| loss: 2.88879 | val_0_mae: 2.76674 |  0:00:33s\n",
      "epoch 162| loss: 2.75703 | val_0_mae: 2.8051  |  0:00:33s\n",
      "epoch 163| loss: 2.744   | val_0_mae: 2.73452 |  0:00:33s\n",
      "epoch 164| loss: 2.7302  | val_0_mae: 2.69876 |  0:00:33s\n",
      "epoch 165| loss: 2.70965 | val_0_mae: 2.76645 |  0:00:33s\n",
      "epoch 166| loss: 2.73932 | val_0_mae: 2.88643 |  0:00:34s\n",
      "epoch 167| loss: 2.73552 | val_0_mae: 2.7314  |  0:00:34s\n",
      "epoch 168| loss: 2.73225 | val_0_mae: 2.77709 |  0:00:34s\n",
      "epoch 169| loss: 2.7375  | val_0_mae: 2.8193  |  0:00:34s\n",
      "epoch 170| loss: 2.6332  | val_0_mae: 2.79196 |  0:00:34s\n",
      "epoch 171| loss: 2.72478 | val_0_mae: 2.77576 |  0:00:35s\n",
      "epoch 172| loss: 2.68902 | val_0_mae: 2.70847 |  0:00:35s\n",
      "epoch 173| loss: 2.72001 | val_0_mae: 2.70466 |  0:00:35s\n",
      "epoch 174| loss: 2.66757 | val_0_mae: 2.75902 |  0:00:35s\n",
      "epoch 175| loss: 2.65742 | val_0_mae: 2.76848 |  0:00:35s\n",
      "epoch 176| loss: 2.56573 | val_0_mae: 2.68405 |  0:00:36s\n",
      "epoch 177| loss: 2.62299 | val_0_mae: 2.78251 |  0:00:36s\n",
      "epoch 178| loss: 2.83467 | val_0_mae: 2.6429  |  0:00:36s\n",
      "epoch 179| loss: 2.61261 | val_0_mae: 2.74286 |  0:00:36s\n",
      "epoch 180| loss: 2.63035 | val_0_mae: 2.78222 |  0:00:36s\n",
      "epoch 181| loss: 2.55779 | val_0_mae: 2.68659 |  0:00:37s\n",
      "epoch 182| loss: 2.63499 | val_0_mae: 2.7883  |  0:00:37s\n",
      "epoch 183| loss: 2.6441  | val_0_mae: 2.61041 |  0:00:37s\n",
      "epoch 184| loss: 2.67854 | val_0_mae: 2.62127 |  0:00:37s\n",
      "epoch 185| loss: 2.53473 | val_0_mae: 2.68203 |  0:00:38s\n",
      "epoch 186| loss: 2.63445 | val_0_mae: 2.77792 |  0:00:38s\n",
      "epoch 187| loss: 2.60917 | val_0_mae: 2.77873 |  0:00:38s\n",
      "epoch 188| loss: 2.57687 | val_0_mae: 2.7906  |  0:00:38s\n",
      "epoch 189| loss: 2.55173 | val_0_mae: 2.64466 |  0:00:38s\n",
      "epoch 190| loss: 2.65637 | val_0_mae: 2.66523 |  0:00:38s\n",
      "epoch 191| loss: 2.64103 | val_0_mae: 2.6665  |  0:00:39s\n",
      "epoch 192| loss: 2.6396  | val_0_mae: 2.59561 |  0:00:39s\n",
      "epoch 193| loss: 2.50421 | val_0_mae: 2.57515 |  0:00:39s\n",
      "epoch 194| loss: 2.56538 | val_0_mae: 2.60345 |  0:00:39s\n",
      "epoch 195| loss: 2.54159 | val_0_mae: 2.62044 |  0:00:40s\n",
      "epoch 196| loss: 2.58575 | val_0_mae: 2.50188 |  0:00:40s\n",
      "epoch 197| loss: 2.58805 | val_0_mae: 2.47342 |  0:00:40s\n",
      "epoch 198| loss: 2.53223 | val_0_mae: 2.59176 |  0:00:40s\n",
      "epoch 199| loss: 2.42891 | val_0_mae: 2.48293 |  0:00:40s\n",
      "epoch 200| loss: 2.51586 | val_0_mae: 2.50168 |  0:00:41s\n",
      "epoch 201| loss: 2.47546 | val_0_mae: 2.54267 |  0:00:41s\n",
      "epoch 202| loss: 2.50312 | val_0_mae: 2.80099 |  0:00:41s\n",
      "epoch 203| loss: 2.49971 | val_0_mae: 2.67505 |  0:00:41s\n",
      "epoch 204| loss: 2.56856 | val_0_mae: 2.58682 |  0:00:41s\n",
      "epoch 205| loss: 2.50427 | val_0_mae: 2.61716 |  0:00:42s\n",
      "epoch 206| loss: 2.37858 | val_0_mae: 2.66046 |  0:00:42s\n",
      "epoch 207| loss: 2.46734 | val_0_mae: 2.63235 |  0:00:42s\n",
      "epoch 208| loss: 2.33407 | val_0_mae: 2.60121 |  0:00:42s\n",
      "epoch 209| loss: 2.47864 | val_0_mae: 2.75421 |  0:00:42s\n",
      "epoch 210| loss: 2.52384 | val_0_mae: 2.77568 |  0:00:43s\n",
      "epoch 211| loss: 2.50444 | val_0_mae: 2.61518 |  0:00:43s\n",
      "epoch 212| loss: 2.61928 | val_0_mae: 2.59797 |  0:00:43s\n",
      "epoch 213| loss: 2.35783 | val_0_mae: 2.75167 |  0:00:43s\n",
      "epoch 214| loss: 2.49663 | val_0_mae: 2.68248 |  0:00:43s\n",
      "epoch 215| loss: 2.46289 | val_0_mae: 2.70524 |  0:00:44s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 216| loss: 2.50238 | val_0_mae: 2.51662 |  0:00:44s\n",
      "epoch 217| loss: 2.32082 | val_0_mae: 2.57196 |  0:00:44s\n",
      "epoch 218| loss: 2.40058 | val_0_mae: 2.54107 |  0:00:44s\n",
      "epoch 219| loss: 2.36319 | val_0_mae: 2.55166 |  0:00:44s\n",
      "epoch 220| loss: 2.38322 | val_0_mae: 2.51402 |  0:00:45s\n",
      "epoch 221| loss: 2.45438 | val_0_mae: 2.61987 |  0:00:45s\n",
      "epoch 222| loss: 2.36559 | val_0_mae: 2.55152 |  0:00:45s\n",
      "epoch 223| loss: 2.33813 | val_0_mae: 2.54487 |  0:00:45s\n",
      "epoch 224| loss: 2.30297 | val_0_mae: 2.46283 |  0:00:45s\n",
      "epoch 225| loss: 2.31989 | val_0_mae: 2.58274 |  0:00:46s\n",
      "epoch 226| loss: 2.38366 | val_0_mae: 2.44873 |  0:00:46s\n",
      "epoch 227| loss: 2.22987 | val_0_mae: 2.59604 |  0:00:46s\n",
      "epoch 228| loss: 2.36564 | val_0_mae: 2.51976 |  0:00:46s\n",
      "epoch 229| loss: 2.36582 | val_0_mae: 2.39713 |  0:00:46s\n",
      "epoch 230| loss: 2.32853 | val_0_mae: 2.48962 |  0:00:47s\n",
      "epoch 231| loss: 2.21035 | val_0_mae: 2.4633  |  0:00:47s\n",
      "epoch 232| loss: 2.32631 | val_0_mae: 2.3997  |  0:00:47s\n",
      "epoch 233| loss: 2.39859 | val_0_mae: 2.41271 |  0:00:47s\n",
      "epoch 234| loss: 2.34027 | val_0_mae: 2.3818  |  0:00:47s\n",
      "epoch 235| loss: 2.2723  | val_0_mae: 2.52733 |  0:00:48s\n",
      "epoch 236| loss: 2.35913 | val_0_mae: 2.3856  |  0:00:48s\n",
      "epoch 237| loss: 2.28341 | val_0_mae: 2.42091 |  0:00:48s\n",
      "epoch 238| loss: 2.22313 | val_0_mae: 2.32531 |  0:00:48s\n",
      "epoch 239| loss: 2.09327 | val_0_mae: 2.44307 |  0:00:48s\n",
      "epoch 240| loss: 2.1875  | val_0_mae: 2.44964 |  0:00:49s\n",
      "epoch 241| loss: 2.16482 | val_0_mae: 2.4059  |  0:00:49s\n",
      "epoch 242| loss: 2.31434 | val_0_mae: 2.48353 |  0:00:49s\n",
      "epoch 243| loss: 2.24067 | val_0_mae: 2.35642 |  0:00:49s\n",
      "epoch 244| loss: 2.26413 | val_0_mae: 2.37073 |  0:00:49s\n",
      "epoch 245| loss: 2.33676 | val_0_mae: 2.48985 |  0:00:50s\n",
      "epoch 246| loss: 2.26142 | val_0_mae: 2.48472 |  0:00:50s\n",
      "epoch 247| loss: 2.28748 | val_0_mae: 2.51522 |  0:00:50s\n",
      "epoch 248| loss: 2.22793 | val_0_mae: 2.43288 |  0:00:50s\n",
      "epoch 249| loss: 2.29932 | val_0_mae: 2.47471 |  0:00:50s\n",
      "epoch 250| loss: 2.28166 | val_0_mae: 2.40352 |  0:00:51s\n",
      "epoch 251| loss: 2.20619 | val_0_mae: 2.42104 |  0:00:51s\n",
      "epoch 252| loss: 2.19923 | val_0_mae: 2.44999 |  0:00:51s\n",
      "epoch 253| loss: 2.2453  | val_0_mae: 2.49879 |  0:00:51s\n",
      "epoch 254| loss: 2.24033 | val_0_mae: 2.49871 |  0:00:51s\n",
      "epoch 255| loss: 2.28039 | val_0_mae: 2.48499 |  0:00:52s\n",
      "epoch 256| loss: 2.4074  | val_0_mae: 2.50476 |  0:00:52s\n",
      "epoch 257| loss: 2.33256 | val_0_mae: 2.56444 |  0:00:52s\n",
      "epoch 258| loss: 2.33358 | val_0_mae: 2.5831  |  0:00:52s\n",
      "epoch 259| loss: 2.38329 | val_0_mae: 2.4993  |  0:00:52s\n",
      "epoch 260| loss: 2.30269 | val_0_mae: 2.54829 |  0:00:53s\n",
      "epoch 261| loss: 2.31101 | val_0_mae: 2.4689  |  0:00:53s\n",
      "epoch 262| loss: 2.20476 | val_0_mae: 2.34854 |  0:00:53s\n",
      "epoch 263| loss: 2.13059 | val_0_mae: 2.38804 |  0:00:53s\n",
      "epoch 264| loss: 2.19317 | val_0_mae: 2.60133 |  0:00:53s\n",
      "epoch 265| loss: 2.19976 | val_0_mae: 2.57612 |  0:00:54s\n",
      "epoch 266| loss: 2.13012 | val_0_mae: 2.53838 |  0:00:54s\n",
      "epoch 267| loss: 2.20018 | val_0_mae: 2.46266 |  0:00:54s\n",
      "epoch 268| loss: 2.21904 | val_0_mae: 2.47174 |  0:00:54s\n",
      "epoch 269| loss: 2.26955 | val_0_mae: 2.5012  |  0:00:54s\n",
      "epoch 270| loss: 2.33932 | val_0_mae: 2.55216 |  0:00:55s\n",
      "epoch 271| loss: 2.19992 | val_0_mae: 2.48349 |  0:00:55s\n",
      "epoch 272| loss: 2.26584 | val_0_mae: 2.54473 |  0:00:55s\n",
      "epoch 273| loss: 2.26525 | val_0_mae: 2.58723 |  0:00:55s\n",
      "epoch 274| loss: 2.23623 | val_0_mae: 2.39734 |  0:00:55s\n",
      "epoch 275| loss: 2.23299 | val_0_mae: 2.4207  |  0:00:56s\n",
      "epoch 276| loss: 2.12064 | val_0_mae: 2.34444 |  0:00:56s\n",
      "epoch 277| loss: 2.13642 | val_0_mae: 2.32498 |  0:00:56s\n",
      "epoch 278| loss: 2.14213 | val_0_mae: 2.38533 |  0:00:56s\n",
      "epoch 279| loss: 2.11873 | val_0_mae: 2.37218 |  0:00:56s\n",
      "epoch 280| loss: 2.07918 | val_0_mae: 2.26917 |  0:00:57s\n",
      "epoch 281| loss: 2.18157 | val_0_mae: 2.22663 |  0:00:57s\n",
      "epoch 282| loss: 2.20036 | val_0_mae: 2.3292  |  0:00:57s\n",
      "epoch 283| loss: 2.17126 | val_0_mae: 2.38255 |  0:00:57s\n",
      "epoch 284| loss: 2.10786 | val_0_mae: 2.41665 |  0:00:57s\n",
      "epoch 285| loss: 2.13265 | val_0_mae: 2.34008 |  0:00:58s\n",
      "epoch 286| loss: 2.0971  | val_0_mae: 2.52814 |  0:00:58s\n",
      "epoch 287| loss: 2.14269 | val_0_mae: 2.42186 |  0:00:58s\n",
      "epoch 288| loss: 2.20967 | val_0_mae: 2.32282 |  0:00:58s\n",
      "epoch 289| loss: 2.0347  | val_0_mae: 2.38949 |  0:00:58s\n",
      "epoch 290| loss: 2.13572 | val_0_mae: 2.36885 |  0:00:59s\n",
      "epoch 291| loss: 2.13352 | val_0_mae: 2.41826 |  0:00:59s\n",
      "epoch 292| loss: 2.14826 | val_0_mae: 2.49745 |  0:00:59s\n",
      "epoch 293| loss: 2.0917  | val_0_mae: 2.51768 |  0:00:59s\n",
      "epoch 294| loss: 2.21626 | val_0_mae: 2.4666  |  0:00:59s\n",
      "epoch 295| loss: 2.24107 | val_0_mae: 2.51741 |  0:01:00s\n",
      "epoch 296| loss: 2.20372 | val_0_mae: 2.40349 |  0:01:00s\n",
      "epoch 297| loss: 2.09024 | val_0_mae: 2.49304 |  0:01:00s\n",
      "epoch 298| loss: 2.28496 | val_0_mae: 2.52946 |  0:01:00s\n",
      "epoch 299| loss: 2.19847 | val_0_mae: 2.4488  |  0:01:00s\n",
      "epoch 300| loss: 2.13324 | val_0_mae: 2.45679 |  0:01:01s\n",
      "epoch 301| loss: 2.09402 | val_0_mae: 2.48595 |  0:01:01s\n",
      "epoch 302| loss: 2.16203 | val_0_mae: 2.3865  |  0:01:01s\n",
      "epoch 303| loss: 2.12851 | val_0_mae: 2.53863 |  0:01:01s\n",
      "epoch 304| loss: 2.17415 | val_0_mae: 2.48705 |  0:01:02s\n",
      "epoch 305| loss: 2.0578  | val_0_mae: 2.38412 |  0:01:02s\n",
      "epoch 306| loss: 2.14255 | val_0_mae: 2.26852 |  0:01:02s\n",
      "epoch 307| loss: 2.10092 | val_0_mae: 2.24977 |  0:01:02s\n",
      "epoch 308| loss: 2.06198 | val_0_mae: 2.21231 |  0:01:02s\n",
      "epoch 309| loss: 1.9783  | val_0_mae: 2.31859 |  0:01:03s\n",
      "epoch 310| loss: 2.13427 | val_0_mae: 2.33975 |  0:01:03s\n",
      "epoch 311| loss: 2.08242 | val_0_mae: 2.39732 |  0:01:03s\n",
      "epoch 312| loss: 2.08295 | val_0_mae: 2.21754 |  0:01:03s\n",
      "epoch 313| loss: 2.00727 | val_0_mae: 2.38247 |  0:01:03s\n",
      "epoch 314| loss: 2.00673 | val_0_mae: 2.38774 |  0:01:04s\n",
      "epoch 315| loss: 2.0011  | val_0_mae: 2.40896 |  0:01:04s\n",
      "epoch 316| loss: 2.12454 | val_0_mae: 2.38963 |  0:01:04s\n",
      "epoch 317| loss: 2.02201 | val_0_mae: 2.36656 |  0:01:04s\n",
      "epoch 318| loss: 2.08001 | val_0_mae: 2.36519 |  0:01:04s\n",
      "epoch 319| loss: 2.08722 | val_0_mae: 2.3299  |  0:01:05s\n",
      "epoch 320| loss: 2.11599 | val_0_mae: 2.28751 |  0:01:05s\n",
      "epoch 321| loss: 2.07308 | val_0_mae: 2.17045 |  0:01:05s\n",
      "epoch 322| loss: 2.02389 | val_0_mae: 2.2337  |  0:01:05s\n",
      "epoch 323| loss: 2.00556 | val_0_mae: 2.30358 |  0:01:05s\n",
      "epoch 324| loss: 1.92201 | val_0_mae: 2.22934 |  0:01:06s\n",
      "epoch 325| loss: 1.92649 | val_0_mae: 2.19315 |  0:01:06s\n",
      "epoch 326| loss: 1.93863 | val_0_mae: 2.24152 |  0:01:06s\n",
      "epoch 327| loss: 1.97032 | val_0_mae: 2.29497 |  0:01:06s\n",
      "epoch 328| loss: 1.91706 | val_0_mae: 2.42478 |  0:01:06s\n",
      "epoch 329| loss: 2.15097 | val_0_mae: 2.39495 |  0:01:07s\n",
      "epoch 330| loss: 2.10865 | val_0_mae: 2.35277 |  0:01:07s\n",
      "epoch 331| loss: 2.06743 | val_0_mae: 2.29478 |  0:01:07s\n",
      "epoch 332| loss: 1.9762  | val_0_mae: 2.44179 |  0:01:07s\n",
      "epoch 333| loss: 2.03484 | val_0_mae: 2.35239 |  0:01:07s\n",
      "epoch 334| loss: 2.03795 | val_0_mae: 2.24356 |  0:01:08s\n",
      "epoch 335| loss: 1.97637 | val_0_mae: 2.20757 |  0:01:08s\n",
      "epoch 336| loss: 1.98913 | val_0_mae: 2.24962 |  0:01:08s\n",
      "epoch 337| loss: 1.97802 | val_0_mae: 2.29105 |  0:01:08s\n",
      "epoch 338| loss: 2.00185 | val_0_mae: 2.30465 |  0:01:08s\n",
      "epoch 339| loss: 1.90352 | val_0_mae: 2.27578 |  0:01:09s\n",
      "epoch 340| loss: 1.89269 | val_0_mae: 2.22243 |  0:01:09s\n",
      "epoch 341| loss: 1.90885 | val_0_mae: 2.17052 |  0:01:09s\n",
      "epoch 342| loss: 2.04912 | val_0_mae: 2.24898 |  0:01:09s\n",
      "epoch 343| loss: 1.93233 | val_0_mae: 2.27154 |  0:01:10s\n",
      "epoch 344| loss: 1.98417 | val_0_mae: 2.28774 |  0:01:10s\n",
      "epoch 345| loss: 2.04908 | val_0_mae: 2.25938 |  0:01:10s\n",
      "epoch 346| loss: 2.06957 | val_0_mae: 2.2049  |  0:01:10s\n",
      "epoch 347| loss: 2.05038 | val_0_mae: 2.34484 |  0:01:10s\n",
      "epoch 348| loss: 2.1038  | val_0_mae: 2.25447 |  0:01:11s\n",
      "epoch 349| loss: 2.00535 | val_0_mae: 2.39087 |  0:01:11s\n",
      "epoch 350| loss: 2.09528 | val_0_mae: 2.3712  |  0:01:11s\n",
      "epoch 351| loss: 2.03324 | val_0_mae: 2.31082 |  0:01:11s\n",
      "epoch 352| loss: 1.95124 | val_0_mae: 2.47216 |  0:01:11s\n",
      "epoch 353| loss: 1.98409 | val_0_mae: 2.32597 |  0:01:12s\n",
      "epoch 354| loss: 2.08305 | val_0_mae: 2.24947 |  0:01:12s\n",
      "epoch 355| loss: 1.96774 | val_0_mae: 2.26184 |  0:01:12s\n",
      "epoch 356| loss: 1.96149 | val_0_mae: 2.19688 |  0:01:12s\n",
      "epoch 357| loss: 1.87121 | val_0_mae: 2.20944 |  0:01:12s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 358| loss: 1.98048 | val_0_mae: 2.20964 |  0:01:13s\n",
      "epoch 359| loss: 1.94997 | val_0_mae: 2.26698 |  0:01:13s\n",
      "epoch 360| loss: 1.97406 | val_0_mae: 2.24784 |  0:01:13s\n",
      "epoch 361| loss: 2.01014 | val_0_mae: 2.26407 |  0:01:13s\n",
      "epoch 362| loss: 2.1033  | val_0_mae: 2.19519 |  0:01:13s\n",
      "epoch 363| loss: 2.12277 | val_0_mae: 2.42315 |  0:01:14s\n",
      "epoch 364| loss: 2.18934 | val_0_mae: 2.45922 |  0:01:14s\n",
      "epoch 365| loss: 2.06811 | val_0_mae: 2.42718 |  0:01:14s\n",
      "epoch 366| loss: 2.0609  | val_0_mae: 2.39239 |  0:01:14s\n",
      "epoch 367| loss: 1.92086 | val_0_mae: 2.34748 |  0:01:14s\n",
      "epoch 368| loss: 1.98775 | val_0_mae: 2.26451 |  0:01:15s\n",
      "epoch 369| loss: 2.01433 | val_0_mae: 2.22848 |  0:01:15s\n",
      "epoch 370| loss: 2.0305  | val_0_mae: 2.33813 |  0:01:15s\n",
      "epoch 371| loss: 2.07442 | val_0_mae: 2.21809 |  0:01:15s\n",
      "\n",
      "Early stopping occured at epoch 371 with best_epoch = 321 and best_val_0_mae = 2.17045\n",
      "Best weights from best epoch are automatically used!\n",
      "************************************************************\n",
      "Prediction MAE: 2.1704502600735096\n",
      "************************************************************\n",
      "Num Fold: 4\n",
      "Train segments: 3545 Val segments: 886\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 22.49483| val_0_mae: 24.31802|  0:00:00s\n",
      "epoch 1  | loss: 21.35063| val_0_mae: 20.4892 |  0:00:00s\n",
      "epoch 2  | loss: 20.25832| val_0_mae: 18.9276 |  0:00:00s\n",
      "epoch 3  | loss: 18.90364| val_0_mae: 16.41075|  0:00:00s\n",
      "epoch 4  | loss: 17.30262| val_0_mae: 16.5776 |  0:00:01s\n",
      "epoch 5  | loss: 15.51138| val_0_mae: 19.01064|  0:00:01s\n",
      "epoch 6  | loss: 13.93402| val_0_mae: 19.58802|  0:00:01s\n",
      "epoch 7  | loss: 12.30637| val_0_mae: 21.22692|  0:00:01s\n",
      "epoch 8  | loss: 11.33219| val_0_mae: 23.48339|  0:00:01s\n",
      "epoch 9  | loss: 10.94852| val_0_mae: 31.02138|  0:00:02s\n",
      "epoch 10 | loss: 10.77438| val_0_mae: 29.30904|  0:00:02s\n",
      "epoch 11 | loss: 10.47493| val_0_mae: 21.84039|  0:00:02s\n",
      "epoch 12 | loss: 9.98525 | val_0_mae: 16.31052|  0:00:02s\n",
      "epoch 13 | loss: 9.80854 | val_0_mae: 17.18779|  0:00:02s\n",
      "epoch 14 | loss: 9.50024 | val_0_mae: 15.72079|  0:00:03s\n",
      "epoch 15 | loss: 9.36117 | val_0_mae: 21.08736|  0:00:03s\n",
      "epoch 16 | loss: 9.23445 | val_0_mae: 22.30949|  0:00:03s\n",
      "epoch 17 | loss: 9.03391 | val_0_mae: 22.94009|  0:00:03s\n",
      "epoch 18 | loss: 9.00179 | val_0_mae: 17.31437|  0:00:03s\n",
      "epoch 19 | loss: 8.86207 | val_0_mae: 15.30812|  0:00:04s\n",
      "epoch 20 | loss: 8.70887 | val_0_mae: 15.27532|  0:00:04s\n",
      "epoch 21 | loss: 8.67229 | val_0_mae: 15.19469|  0:00:04s\n",
      "epoch 22 | loss: 8.45717 | val_0_mae: 12.85254|  0:00:04s\n",
      "epoch 23 | loss: 8.25613 | val_0_mae: 11.60418|  0:00:04s\n",
      "epoch 24 | loss: 8.14631 | val_0_mae: 10.98482|  0:00:05s\n",
      "epoch 25 | loss: 8.11583 | val_0_mae: 10.7568 |  0:00:05s\n",
      "epoch 26 | loss: 8.03583 | val_0_mae: 11.01914|  0:00:05s\n",
      "epoch 27 | loss: 7.86566 | val_0_mae: 11.08886|  0:00:05s\n",
      "epoch 28 | loss: 7.88325 | val_0_mae: 10.66523|  0:00:05s\n",
      "epoch 29 | loss: 7.69772 | val_0_mae: 10.69743|  0:00:06s\n",
      "epoch 30 | loss: 7.81811 | val_0_mae: 11.77815|  0:00:06s\n",
      "epoch 31 | loss: 7.74768 | val_0_mae: 13.48008|  0:00:06s\n",
      "epoch 32 | loss: 7.45757 | val_0_mae: 15.42555|  0:00:06s\n",
      "epoch 33 | loss: 7.44134 | val_0_mae: 13.90831|  0:00:06s\n",
      "epoch 34 | loss: 7.27317 | val_0_mae: 11.88323|  0:00:07s\n",
      "epoch 35 | loss: 7.34732 | val_0_mae: 10.76118|  0:00:07s\n",
      "epoch 36 | loss: 7.43971 | val_0_mae: 11.42019|  0:00:07s\n",
      "epoch 37 | loss: 7.21152 | val_0_mae: 10.90239|  0:00:07s\n",
      "epoch 38 | loss: 7.20887 | val_0_mae: 10.49257|  0:00:07s\n",
      "epoch 39 | loss: 7.34739 | val_0_mae: 9.60171 |  0:00:08s\n",
      "epoch 40 | loss: 7.34902 | val_0_mae: 9.24425 |  0:00:08s\n",
      "epoch 41 | loss: 7.25669 | val_0_mae: 9.01564 |  0:00:08s\n",
      "epoch 42 | loss: 7.28733 | val_0_mae: 9.1493  |  0:00:08s\n",
      "epoch 43 | loss: 7.18432 | val_0_mae: 9.08183 |  0:00:08s\n",
      "epoch 44 | loss: 7.17999 | val_0_mae: 8.97218 |  0:00:09s\n",
      "epoch 45 | loss: 7.05524 | val_0_mae: 8.80507 |  0:00:09s\n",
      "epoch 46 | loss: 7.01457 | val_0_mae: 8.73789 |  0:00:09s\n",
      "epoch 47 | loss: 7.19439 | val_0_mae: 9.25413 |  0:00:09s\n",
      "epoch 48 | loss: 7.18412 | val_0_mae: 8.45686 |  0:00:09s\n",
      "epoch 49 | loss: 7.14212 | val_0_mae: 8.43691 |  0:00:10s\n",
      "epoch 50 | loss: 6.80296 | val_0_mae: 8.83432 |  0:00:10s\n",
      "epoch 51 | loss: 6.53118 | val_0_mae: 7.98416 |  0:00:10s\n",
      "epoch 52 | loss: 6.52281 | val_0_mae: 7.9425  |  0:00:10s\n",
      "epoch 53 | loss: 6.72539 | val_0_mae: 8.12294 |  0:00:10s\n",
      "epoch 54 | loss: 6.59824 | val_0_mae: 7.56485 |  0:00:11s\n",
      "epoch 55 | loss: 6.37412 | val_0_mae: 7.4459  |  0:00:11s\n",
      "epoch 56 | loss: 6.36869 | val_0_mae: 7.09989 |  0:00:11s\n",
      "epoch 57 | loss: 6.33329 | val_0_mae: 7.4908  |  0:00:11s\n",
      "epoch 58 | loss: 6.34891 | val_0_mae: 7.25554 |  0:00:11s\n",
      "epoch 59 | loss: 6.09654 | val_0_mae: 6.84949 |  0:00:12s\n",
      "epoch 60 | loss: 6.04815 | val_0_mae: 7.01375 |  0:00:12s\n",
      "epoch 61 | loss: 6.03653 | val_0_mae: 7.13983 |  0:00:12s\n",
      "epoch 62 | loss: 6.10022 | val_0_mae: 7.21608 |  0:00:12s\n",
      "epoch 63 | loss: 5.99167 | val_0_mae: 6.98396 |  0:00:13s\n",
      "epoch 64 | loss: 6.14239 | val_0_mae: 6.77498 |  0:00:13s\n",
      "epoch 65 | loss: 5.91451 | val_0_mae: 7.28151 |  0:00:13s\n",
      "epoch 66 | loss: 6.15943 | val_0_mae: 7.15835 |  0:00:13s\n",
      "epoch 67 | loss: 6.13356 | val_0_mae: 6.36437 |  0:00:13s\n",
      "epoch 68 | loss: 6.00094 | val_0_mae: 6.57514 |  0:00:14s\n",
      "epoch 69 | loss: 5.92106 | val_0_mae: 6.47076 |  0:00:14s\n",
      "epoch 70 | loss: 5.90727 | val_0_mae: 6.9148  |  0:00:14s\n",
      "epoch 71 | loss: 5.88436 | val_0_mae: 6.78023 |  0:00:14s\n",
      "epoch 72 | loss: 5.71516 | val_0_mae: 6.46508 |  0:00:14s\n",
      "epoch 73 | loss: 5.67901 | val_0_mae: 6.1798  |  0:00:15s\n",
      "epoch 74 | loss: 5.63    | val_0_mae: 6.62824 |  0:00:15s\n",
      "epoch 75 | loss: 5.78024 | val_0_mae: 6.27044 |  0:00:15s\n",
      "epoch 76 | loss: 5.66236 | val_0_mae: 6.52769 |  0:00:15s\n",
      "epoch 77 | loss: 5.61047 | val_0_mae: 6.60895 |  0:00:15s\n",
      "epoch 78 | loss: 5.72064 | val_0_mae: 6.52256 |  0:00:16s\n",
      "epoch 79 | loss: 5.70368 | val_0_mae: 6.41682 |  0:00:16s\n",
      "epoch 80 | loss: 5.66412 | val_0_mae: 6.45929 |  0:00:16s\n",
      "epoch 81 | loss: 5.82146 | val_0_mae: 6.23371 |  0:00:16s\n",
      "epoch 82 | loss: 5.65339 | val_0_mae: 6.18895 |  0:00:16s\n",
      "epoch 83 | loss: 5.74428 | val_0_mae: 6.66686 |  0:00:17s\n",
      "epoch 84 | loss: 5.6153  | val_0_mae: 6.65358 |  0:00:17s\n",
      "epoch 85 | loss: 5.72341 | val_0_mae: 6.31378 |  0:00:17s\n",
      "epoch 86 | loss: 5.58796 | val_0_mae: 6.05157 |  0:00:17s\n",
      "epoch 87 | loss: 5.59465 | val_0_mae: 6.07838 |  0:00:18s\n",
      "epoch 88 | loss: 5.62285 | val_0_mae: 6.20698 |  0:00:18s\n",
      "epoch 89 | loss: 5.50405 | val_0_mae: 6.33487 |  0:00:18s\n",
      "epoch 90 | loss: 5.41481 | val_0_mae: 6.0793  |  0:00:18s\n",
      "epoch 91 | loss: 5.18332 | val_0_mae: 6.44488 |  0:00:18s\n",
      "epoch 92 | loss: 5.34052 | val_0_mae: 5.9596  |  0:00:19s\n",
      "epoch 93 | loss: 5.19427 | val_0_mae: 5.52865 |  0:00:19s\n",
      "epoch 94 | loss: 5.18792 | val_0_mae: 5.51819 |  0:00:19s\n",
      "epoch 95 | loss: 5.16125 | val_0_mae: 5.9436  |  0:00:19s\n",
      "epoch 96 | loss: 5.04259 | val_0_mae: 5.83798 |  0:00:19s\n",
      "epoch 97 | loss: 5.04879 | val_0_mae: 5.66214 |  0:00:20s\n",
      "epoch 98 | loss: 5.14876 | val_0_mae: 5.81486 |  0:00:20s\n",
      "epoch 99 | loss: 5.32402 | val_0_mae: 6.14383 |  0:00:20s\n",
      "epoch 100| loss: 5.42035 | val_0_mae: 5.91162 |  0:00:20s\n",
      "epoch 101| loss: 5.22571 | val_0_mae: 5.46945 |  0:00:20s\n",
      "epoch 102| loss: 5.09436 | val_0_mae: 5.39043 |  0:00:21s\n",
      "epoch 103| loss: 5.06079 | val_0_mae: 5.38236 |  0:00:21s\n",
      "epoch 104| loss: 4.89247 | val_0_mae: 5.37755 |  0:00:21s\n",
      "epoch 105| loss: 5.027   | val_0_mae: 5.53009 |  0:00:21s\n",
      "epoch 106| loss: 5.04725 | val_0_mae: 5.34707 |  0:00:21s\n",
      "epoch 107| loss: 5.07492 | val_0_mae: 5.40778 |  0:00:22s\n",
      "epoch 108| loss: 5.00188 | val_0_mae: 5.51797 |  0:00:22s\n",
      "epoch 109| loss: 4.93452 | val_0_mae: 5.25033 |  0:00:22s\n",
      "epoch 110| loss: 4.98894 | val_0_mae: 5.72042 |  0:00:22s\n",
      "epoch 111| loss: 4.96496 | val_0_mae: 5.60551 |  0:00:22s\n",
      "epoch 112| loss: 4.98049 | val_0_mae: 5.35455 |  0:00:23s\n",
      "epoch 113| loss: 4.8517  | val_0_mae: 5.40108 |  0:00:23s\n",
      "epoch 114| loss: 4.90433 | val_0_mae: 5.42395 |  0:00:23s\n",
      "epoch 115| loss: 4.88291 | val_0_mae: 5.24366 |  0:00:23s\n",
      "epoch 116| loss: 4.81637 | val_0_mae: 5.36044 |  0:00:24s\n",
      "epoch 117| loss: 4.75117 | val_0_mae: 5.19082 |  0:00:24s\n",
      "epoch 118| loss: 4.81575 | val_0_mae: 5.23108 |  0:00:24s\n",
      "epoch 119| loss: 4.83858 | val_0_mae: 5.3386  |  0:00:24s\n",
      "epoch 120| loss: 4.93129 | val_0_mae: 5.44619 |  0:00:24s\n",
      "epoch 121| loss: 4.66909 | val_0_mae: 5.34521 |  0:00:25s\n",
      "epoch 122| loss: 4.89429 | val_0_mae: 5.45215 |  0:00:25s\n",
      "epoch 123| loss: 4.69302 | val_0_mae: 5.23676 |  0:00:25s\n",
      "epoch 124| loss: 4.75188 | val_0_mae: 5.25052 |  0:00:25s\n",
      "epoch 125| loss: 4.71872 | val_0_mae: 5.34396 |  0:00:25s\n",
      "epoch 126| loss: 4.71775 | val_0_mae: 5.07172 |  0:00:26s\n",
      "epoch 127| loss: 4.65432 | val_0_mae: 5.14106 |  0:00:26s\n",
      "epoch 128| loss: 4.7328  | val_0_mae: 5.29714 |  0:00:26s\n",
      "epoch 129| loss: 4.65396 | val_0_mae: 5.03669 |  0:00:26s\n",
      "epoch 130| loss: 4.50728 | val_0_mae: 5.18453 |  0:00:26s\n",
      "epoch 131| loss: 4.61681 | val_0_mae: 5.11442 |  0:00:27s\n",
      "epoch 132| loss: 4.48842 | val_0_mae: 5.13793 |  0:00:27s\n",
      "epoch 133| loss: 4.46447 | val_0_mae: 4.97989 |  0:00:27s\n",
      "epoch 134| loss: 4.5017  | val_0_mae: 4.97658 |  0:00:27s\n",
      "epoch 135| loss: 4.26425 | val_0_mae: 4.85301 |  0:00:27s\n",
      "epoch 136| loss: 4.40535 | val_0_mae: 4.69675 |  0:00:28s\n",
      "epoch 137| loss: 4.29809 | val_0_mae: 4.74169 |  0:00:28s\n",
      "epoch 138| loss: 4.35041 | val_0_mae: 4.81568 |  0:00:28s\n",
      "epoch 139| loss: 4.43234 | val_0_mae: 4.8575  |  0:00:28s\n",
      "epoch 140| loss: 4.44419 | val_0_mae: 4.67563 |  0:00:28s\n",
      "epoch 141| loss: 4.24144 | val_0_mae: 4.64286 |  0:00:29s\n",
      "epoch 142| loss: 4.33966 | val_0_mae: 4.74889 |  0:00:29s\n",
      "epoch 143| loss: 4.3175  | val_0_mae: 4.86383 |  0:00:29s\n",
      "epoch 144| loss: 4.46741 | val_0_mae: 4.98832 |  0:00:29s\n",
      "epoch 145| loss: 4.43266 | val_0_mae: 5.0666  |  0:00:29s\n",
      "epoch 146| loss: 4.398   | val_0_mae: 4.98011 |  0:00:30s\n",
      "epoch 147| loss: 4.29619 | val_0_mae: 5.22621 |  0:00:30s\n",
      "epoch 148| loss: 4.37586 | val_0_mae: 4.84608 |  0:00:30s\n",
      "epoch 149| loss: 4.38278 | val_0_mae: 4.80465 |  0:00:30s\n",
      "epoch 150| loss: 4.38697 | val_0_mae: 5.19336 |  0:00:30s\n",
      "epoch 151| loss: 4.41693 | val_0_mae: 5.00683 |  0:00:31s\n",
      "epoch 152| loss: 4.26611 | val_0_mae: 4.76073 |  0:00:31s\n",
      "epoch 153| loss: 4.33852 | val_0_mae: 4.77992 |  0:00:31s\n",
      "epoch 154| loss: 4.25413 | val_0_mae: 4.79125 |  0:00:31s\n",
      "epoch 155| loss: 4.30076 | val_0_mae: 4.70863 |  0:00:31s\n",
      "epoch 156| loss: 4.24662 | val_0_mae: 4.65013 |  0:00:32s\n",
      "epoch 157| loss: 4.33503 | val_0_mae: 4.90252 |  0:00:32s\n",
      "epoch 158| loss: 4.40763 | val_0_mae: 5.16976 |  0:00:32s\n",
      "epoch 159| loss: 4.59406 | val_0_mae: 4.932   |  0:00:32s\n",
      "epoch 160| loss: 4.58966 | val_0_mae: 5.0105  |  0:00:32s\n",
      "epoch 161| loss: 4.55016 | val_0_mae: 4.85121 |  0:00:33s\n",
      "epoch 162| loss: 4.52366 | val_0_mae: 4.9195  |  0:00:33s\n",
      "epoch 163| loss: 4.33487 | val_0_mae: 4.80316 |  0:00:33s\n",
      "epoch 164| loss: 4.38006 | val_0_mae: 4.68895 |  0:00:33s\n",
      "epoch 165| loss: 4.24191 | val_0_mae: 4.55702 |  0:00:33s\n",
      "epoch 166| loss: 4.3304  | val_0_mae: 4.61672 |  0:00:34s\n",
      "epoch 167| loss: 4.20547 | val_0_mae: 4.58264 |  0:00:34s\n",
      "epoch 168| loss: 4.245   | val_0_mae: 4.88028 |  0:00:34s\n",
      "epoch 169| loss: 4.1903  | val_0_mae: 4.59521 |  0:00:34s\n",
      "epoch 170| loss: 4.09274 | val_0_mae: 4.78723 |  0:00:34s\n",
      "epoch 171| loss: 4.44904 | val_0_mae: 4.61731 |  0:00:35s\n",
      "epoch 172| loss: 4.2095  | val_0_mae: 4.80126 |  0:00:35s\n",
      "epoch 173| loss: 4.20916 | val_0_mae: 4.79132 |  0:00:35s\n",
      "epoch 174| loss: 4.25593 | val_0_mae: 4.71165 |  0:00:35s\n",
      "epoch 175| loss: 4.15816 | val_0_mae: 4.64985 |  0:00:35s\n",
      "epoch 176| loss: 4.10895 | val_0_mae: 4.50762 |  0:00:36s\n",
      "epoch 177| loss: 4.02915 | val_0_mae: 4.79474 |  0:00:36s\n",
      "epoch 178| loss: 3.90897 | val_0_mae: 4.62641 |  0:00:36s\n",
      "epoch 179| loss: 4.02645 | val_0_mae: 4.54534 |  0:00:36s\n",
      "epoch 180| loss: 3.95888 | val_0_mae: 4.44533 |  0:00:37s\n",
      "epoch 181| loss: 3.8865  | val_0_mae: 4.46863 |  0:00:37s\n",
      "epoch 182| loss: 3.95792 | val_0_mae: 4.44054 |  0:00:37s\n",
      "epoch 183| loss: 3.97969 | val_0_mae: 4.52107 |  0:00:37s\n",
      "epoch 184| loss: 4.09177 | val_0_mae: 4.5047  |  0:00:37s\n",
      "epoch 185| loss: 4.03078 | val_0_mae: 4.67893 |  0:00:38s\n",
      "epoch 186| loss: 4.11255 | val_0_mae: 4.55478 |  0:00:38s\n",
      "epoch 187| loss: 4.02542 | val_0_mae: 4.50809 |  0:00:38s\n",
      "epoch 188| loss: 3.99977 | val_0_mae: 4.59569 |  0:00:38s\n",
      "epoch 189| loss: 3.84674 | val_0_mae: 4.50256 |  0:00:38s\n",
      "epoch 190| loss: 3.88605 | val_0_mae: 4.41742 |  0:00:39s\n",
      "epoch 191| loss: 3.86296 | val_0_mae: 4.38783 |  0:00:39s\n",
      "epoch 192| loss: 3.72112 | val_0_mae: 4.46572 |  0:00:39s\n",
      "epoch 193| loss: 3.74156 | val_0_mae: 4.50285 |  0:00:39s\n",
      "epoch 194| loss: 3.74977 | val_0_mae: 4.3462  |  0:00:39s\n",
      "epoch 195| loss: 3.77668 | val_0_mae: 4.37658 |  0:00:40s\n",
      "epoch 196| loss: 3.74593 | val_0_mae: 4.54409 |  0:00:40s\n",
      "epoch 197| loss: 3.69453 | val_0_mae: 4.23579 |  0:00:40s\n",
      "epoch 198| loss: 3.73293 | val_0_mae: 4.40206 |  0:00:40s\n",
      "epoch 199| loss: 3.69934 | val_0_mae: 4.2913  |  0:00:40s\n",
      "epoch 200| loss: 3.72453 | val_0_mae: 4.40206 |  0:00:41s\n",
      "epoch 201| loss: 3.78085 | val_0_mae: 4.42853 |  0:00:41s\n",
      "epoch 202| loss: 3.63331 | val_0_mae: 4.3406  |  0:00:41s\n",
      "epoch 203| loss: 3.64398 | val_0_mae: 4.25797 |  0:00:41s\n",
      "epoch 204| loss: 3.657   | val_0_mae: 4.41262 |  0:00:41s\n",
      "epoch 205| loss: 3.63919 | val_0_mae: 4.15333 |  0:00:42s\n",
      "epoch 206| loss: 3.61077 | val_0_mae: 4.10859 |  0:00:42s\n",
      "epoch 207| loss: 3.63067 | val_0_mae: 4.07813 |  0:00:42s\n",
      "epoch 208| loss: 3.72768 | val_0_mae: 4.05187 |  0:00:42s\n",
      "epoch 209| loss: 3.75334 | val_0_mae: 4.05492 |  0:00:42s\n",
      "epoch 210| loss: 3.71434 | val_0_mae: 4.16904 |  0:00:43s\n",
      "epoch 211| loss: 3.7737  | val_0_mae: 4.29007 |  0:00:43s\n",
      "epoch 212| loss: 3.68915 | val_0_mae: 4.28639 |  0:00:43s\n",
      "epoch 213| loss: 3.71261 | val_0_mae: 4.28399 |  0:00:43s\n",
      "epoch 214| loss: 3.68829 | val_0_mae: 4.23381 |  0:00:43s\n",
      "epoch 215| loss: 3.53683 | val_0_mae: 4.22779 |  0:00:44s\n",
      "epoch 216| loss: 3.768   | val_0_mae: 4.35954 |  0:00:44s\n",
      "epoch 217| loss: 3.72292 | val_0_mae: 4.09755 |  0:00:44s\n",
      "epoch 218| loss: 3.75805 | val_0_mae: 4.17535 |  0:00:44s\n",
      "epoch 219| loss: 3.77322 | val_0_mae: 4.06345 |  0:00:44s\n",
      "epoch 220| loss: 3.62568 | val_0_mae: 4.06465 |  0:00:45s\n",
      "epoch 221| loss: 3.60702 | val_0_mae: 3.99483 |  0:00:45s\n",
      "epoch 222| loss: 3.67077 | val_0_mae: 3.92036 |  0:00:45s\n",
      "epoch 223| loss: 3.59506 | val_0_mae: 4.10438 |  0:00:45s\n",
      "epoch 224| loss: 3.61478 | val_0_mae: 4.06632 |  0:00:45s\n",
      "epoch 225| loss: 3.49433 | val_0_mae: 4.02611 |  0:00:46s\n",
      "epoch 226| loss: 3.48449 | val_0_mae: 3.98737 |  0:00:46s\n",
      "epoch 227| loss: 3.65879 | val_0_mae: 4.10994 |  0:00:46s\n",
      "epoch 228| loss: 3.56149 | val_0_mae: 4.09208 |  0:00:46s\n",
      "epoch 229| loss: 3.58255 | val_0_mae: 4.04493 |  0:00:46s\n",
      "epoch 230| loss: 3.58629 | val_0_mae: 4.07896 |  0:00:47s\n",
      "epoch 231| loss: 3.53657 | val_0_mae: 4.10805 |  0:00:47s\n",
      "epoch 232| loss: 3.52145 | val_0_mae: 4.23145 |  0:00:47s\n",
      "epoch 233| loss: 3.64485 | val_0_mae: 4.12356 |  0:00:47s\n",
      "epoch 234| loss: 3.58724 | val_0_mae: 4.18958 |  0:00:48s\n",
      "epoch 235| loss: 3.6012  | val_0_mae: 4.10392 |  0:00:48s\n",
      "epoch 236| loss: 3.60359 | val_0_mae: 4.20772 |  0:00:48s\n",
      "epoch 237| loss: 3.59826 | val_0_mae: 4.35046 |  0:00:48s\n",
      "epoch 238| loss: 3.62158 | val_0_mae: 4.17123 |  0:00:48s\n",
      "epoch 239| loss: 3.58335 | val_0_mae: 4.15739 |  0:00:49s\n",
      "epoch 240| loss: 3.44206 | val_0_mae: 4.13285 |  0:00:49s\n",
      "epoch 241| loss: 3.42236 | val_0_mae: 4.08549 |  0:00:49s\n",
      "epoch 242| loss: 3.63268 | val_0_mae: 4.12644 |  0:00:49s\n",
      "epoch 243| loss: 3.55425 | val_0_mae: 3.90581 |  0:00:49s\n",
      "epoch 244| loss: 3.53396 | val_0_mae: 3.97892 |  0:00:50s\n",
      "epoch 245| loss: 3.59836 | val_0_mae: 4.11388 |  0:00:50s\n",
      "epoch 246| loss: 3.56271 | val_0_mae: 4.06687 |  0:00:50s\n",
      "epoch 247| loss: 3.5166  | val_0_mae: 4.03852 |  0:00:50s\n",
      "epoch 248| loss: 3.39261 | val_0_mae: 4.10459 |  0:00:50s\n",
      "epoch 249| loss: 3.42375 | val_0_mae: 4.27565 |  0:00:51s\n",
      "epoch 250| loss: 3.51503 | val_0_mae: 3.99825 |  0:00:51s\n",
      "epoch 251| loss: 3.43068 | val_0_mae: 3.97088 |  0:00:51s\n",
      "epoch 252| loss: 3.44902 | val_0_mae: 3.8758  |  0:00:51s\n",
      "epoch 253| loss: 3.46596 | val_0_mae: 4.07975 |  0:00:51s\n",
      "epoch 254| loss: 3.49469 | val_0_mae: 4.18142 |  0:00:52s\n",
      "epoch 255| loss: 3.48574 | val_0_mae: 4.09446 |  0:00:52s\n",
      "epoch 256| loss: 3.41646 | val_0_mae: 4.04729 |  0:00:52s\n",
      "epoch 257| loss: 3.59324 | val_0_mae: 3.91484 |  0:00:52s\n",
      "epoch 258| loss: 3.43678 | val_0_mae: 3.92311 |  0:00:52s\n",
      "epoch 259| loss: 3.36783 | val_0_mae: 4.23193 |  0:00:53s\n",
      "epoch 260| loss: 3.52291 | val_0_mae: 4.19139 |  0:00:53s\n",
      "epoch 261| loss: 3.46041 | val_0_mae: 4.06673 |  0:00:53s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 262| loss: 3.44542 | val_0_mae: 4.08527 |  0:00:53s\n",
      "epoch 263| loss: 3.51116 | val_0_mae: 4.08286 |  0:00:53s\n",
      "epoch 264| loss: 3.34049 | val_0_mae: 3.8352  |  0:00:54s\n",
      "epoch 265| loss: 3.50042 | val_0_mae: 3.90573 |  0:00:54s\n",
      "epoch 266| loss: 3.60183 | val_0_mae: 3.92441 |  0:00:54s\n",
      "epoch 267| loss: 3.48295 | val_0_mae: 3.93441 |  0:00:54s\n",
      "epoch 268| loss: 3.4562  | val_0_mae: 3.84515 |  0:00:54s\n",
      "epoch 269| loss: 3.48119 | val_0_mae: 3.8124  |  0:00:55s\n",
      "epoch 270| loss: 3.37337 | val_0_mae: 3.88227 |  0:00:55s\n",
      "epoch 271| loss: 3.41693 | val_0_mae: 3.84305 |  0:00:55s\n",
      "epoch 272| loss: 3.39385 | val_0_mae: 3.82717 |  0:00:55s\n",
      "epoch 273| loss: 3.51624 | val_0_mae: 3.90832 |  0:00:55s\n",
      "epoch 274| loss: 3.34951 | val_0_mae: 3.86662 |  0:00:56s\n",
      "epoch 275| loss: 3.3177  | val_0_mae: 3.85511 |  0:00:56s\n",
      "epoch 276| loss: 3.35393 | val_0_mae: 4.00935 |  0:00:56s\n",
      "epoch 277| loss: 3.41844 | val_0_mae: 3.99497 |  0:00:56s\n",
      "epoch 278| loss: 3.3371  | val_0_mae: 3.8556  |  0:00:56s\n",
      "epoch 279| loss: 3.26162 | val_0_mae: 3.87031 |  0:00:57s\n",
      "epoch 280| loss: 3.30863 | val_0_mae: 4.0321  |  0:00:57s\n",
      "epoch 281| loss: 3.47361 | val_0_mae: 4.13316 |  0:00:57s\n",
      "epoch 282| loss: 3.54524 | val_0_mae: 3.97638 |  0:00:57s\n",
      "epoch 283| loss: 3.44067 | val_0_mae: 3.83644 |  0:00:57s\n",
      "epoch 284| loss: 3.43729 | val_0_mae: 3.79236 |  0:00:58s\n",
      "epoch 285| loss: 3.29679 | val_0_mae: 3.9355  |  0:00:58s\n",
      "epoch 286| loss: 3.41855 | val_0_mae: 3.77835 |  0:00:58s\n",
      "epoch 287| loss: 3.28717 | val_0_mae: 3.72414 |  0:00:58s\n",
      "epoch 288| loss: 3.29711 | val_0_mae: 3.92562 |  0:00:58s\n",
      "epoch 289| loss: 3.3636  | val_0_mae: 3.96643 |  0:00:59s\n",
      "epoch 290| loss: 3.376   | val_0_mae: 3.90272 |  0:00:59s\n",
      "epoch 291| loss: 3.30925 | val_0_mae: 3.91197 |  0:00:59s\n",
      "epoch 292| loss: 3.41551 | val_0_mae: 3.90819 |  0:00:59s\n",
      "epoch 293| loss: 3.33929 | val_0_mae: 3.88581 |  0:01:00s\n",
      "epoch 294| loss: 3.25081 | val_0_mae: 3.97245 |  0:01:00s\n",
      "epoch 295| loss: 3.30388 | val_0_mae: 3.96553 |  0:01:00s\n",
      "epoch 296| loss: 3.24206 | val_0_mae: 3.97671 |  0:01:00s\n",
      "epoch 297| loss: 3.37008 | val_0_mae: 3.87135 |  0:01:00s\n",
      "epoch 298| loss: 3.32343 | val_0_mae: 3.98523 |  0:01:01s\n",
      "epoch 299| loss: 3.45563 | val_0_mae: 3.79786 |  0:01:01s\n",
      "epoch 300| loss: 3.35473 | val_0_mae: 3.91558 |  0:01:01s\n",
      "epoch 301| loss: 3.33211 | val_0_mae: 3.95154 |  0:01:01s\n",
      "epoch 302| loss: 3.2607  | val_0_mae: 3.88701 |  0:01:01s\n",
      "epoch 303| loss: 3.36696 | val_0_mae: 3.82282 |  0:01:02s\n",
      "epoch 304| loss: 3.37043 | val_0_mae: 3.96912 |  0:01:02s\n",
      "epoch 305| loss: 3.36312 | val_0_mae: 3.96312 |  0:01:02s\n",
      "epoch 306| loss: 3.33446 | val_0_mae: 3.7994  |  0:01:02s\n",
      "epoch 307| loss: 3.29466 | val_0_mae: 3.68111 |  0:01:02s\n",
      "epoch 308| loss: 3.25376 | val_0_mae: 3.83711 |  0:01:03s\n",
      "epoch 309| loss: 3.19521 | val_0_mae: 3.78173 |  0:01:03s\n",
      "epoch 310| loss: 3.31616 | val_0_mae: 3.71749 |  0:01:03s\n",
      "epoch 311| loss: 3.35278 | val_0_mae: 3.70716 |  0:01:03s\n",
      "epoch 312| loss: 3.25607 | val_0_mae: 3.89572 |  0:01:03s\n",
      "epoch 313| loss: 3.23824 | val_0_mae: 3.95501 |  0:01:04s\n",
      "epoch 314| loss: 3.3428  | val_0_mae: 3.72459 |  0:01:04s\n",
      "epoch 315| loss: 3.19864 | val_0_mae: 3.70923 |  0:01:04s\n",
      "epoch 316| loss: 3.18771 | val_0_mae: 3.75097 |  0:01:04s\n",
      "epoch 317| loss: 3.13067 | val_0_mae: 3.51924 |  0:01:04s\n",
      "epoch 318| loss: 3.14459 | val_0_mae: 3.58245 |  0:01:05s\n",
      "epoch 319| loss: 3.20188 | val_0_mae: 3.58772 |  0:01:05s\n",
      "epoch 320| loss: 3.13106 | val_0_mae: 3.666   |  0:01:05s\n",
      "epoch 321| loss: 3.04316 | val_0_mae: 3.6788  |  0:01:05s\n",
      "epoch 322| loss: 3.1021  | val_0_mae: 3.63095 |  0:01:05s\n",
      "epoch 323| loss: 3.08392 | val_0_mae: 3.61253 |  0:01:06s\n",
      "epoch 324| loss: 3.17942 | val_0_mae: 3.59031 |  0:01:06s\n",
      "epoch 325| loss: 3.16062 | val_0_mae: 3.72831 |  0:01:06s\n",
      "epoch 326| loss: 3.21116 | val_0_mae: 3.51482 |  0:01:06s\n",
      "epoch 327| loss: 3.10318 | val_0_mae: 3.73394 |  0:01:06s\n",
      "epoch 328| loss: 3.14491 | val_0_mae: 3.43218 |  0:01:07s\n",
      "epoch 329| loss: 3.19756 | val_0_mae: 3.64578 |  0:01:07s\n",
      "epoch 330| loss: 3.2605  | val_0_mae: 3.64953 |  0:01:07s\n",
      "epoch 331| loss: 3.22588 | val_0_mae: 3.60546 |  0:01:07s\n",
      "epoch 332| loss: 3.11403 | val_0_mae: 3.55935 |  0:01:08s\n",
      "epoch 333| loss: 2.98185 | val_0_mae: 3.70982 |  0:01:08s\n",
      "epoch 334| loss: 3.12811 | val_0_mae: 3.66438 |  0:01:08s\n",
      "epoch 335| loss: 3.07742 | val_0_mae: 3.62523 |  0:01:08s\n",
      "epoch 336| loss: 3.03097 | val_0_mae: 3.68558 |  0:01:08s\n",
      "epoch 337| loss: 3.07394 | val_0_mae: 3.76015 |  0:01:09s\n",
      "epoch 338| loss: 3.02131 | val_0_mae: 3.77718 |  0:01:09s\n",
      "epoch 339| loss: 3.10901 | val_0_mae: 3.60297 |  0:01:09s\n",
      "epoch 340| loss: 3.1792  | val_0_mae: 3.62761 |  0:01:09s\n",
      "epoch 341| loss: 3.12079 | val_0_mae: 3.60194 |  0:01:09s\n",
      "epoch 342| loss: 3.16243 | val_0_mae: 3.58148 |  0:01:10s\n",
      "epoch 343| loss: 3.11763 | val_0_mae: 3.66401 |  0:01:10s\n",
      "epoch 344| loss: 3.10579 | val_0_mae: 3.70234 |  0:01:10s\n",
      "epoch 345| loss: 3.19084 | val_0_mae: 3.50015 |  0:01:10s\n",
      "epoch 346| loss: 3.09531 | val_0_mae: 3.45893 |  0:01:10s\n",
      "epoch 347| loss: 3.00906 | val_0_mae: 3.43451 |  0:01:11s\n",
      "epoch 348| loss: 2.95727 | val_0_mae: 3.59525 |  0:01:11s\n",
      "epoch 349| loss: 3.05502 | val_0_mae: 3.61523 |  0:01:11s\n",
      "epoch 350| loss: 3.04451 | val_0_mae: 3.6994  |  0:01:11s\n",
      "epoch 351| loss: 3.08775 | val_0_mae: 3.57876 |  0:01:11s\n",
      "epoch 352| loss: 3.02375 | val_0_mae: 3.57872 |  0:01:12s\n",
      "epoch 353| loss: 3.17034 | val_0_mae: 3.64425 |  0:01:12s\n",
      "epoch 354| loss: 3.34815 | val_0_mae: 3.76021 |  0:01:12s\n",
      "epoch 355| loss: 3.37585 | val_0_mae: 3.93712 |  0:01:12s\n",
      "epoch 356| loss: 3.14708 | val_0_mae: 3.84282 |  0:01:12s\n",
      "epoch 357| loss: 3.25226 | val_0_mae: 3.80606 |  0:01:13s\n",
      "epoch 358| loss: 3.10719 | val_0_mae: 3.88429 |  0:01:13s\n",
      "epoch 359| loss: 3.17386 | val_0_mae: 3.78877 |  0:01:13s\n",
      "epoch 360| loss: 3.14016 | val_0_mae: 3.81084 |  0:01:13s\n",
      "epoch 361| loss: 3.21059 | val_0_mae: 3.59681 |  0:01:13s\n",
      "epoch 362| loss: 3.08942 | val_0_mae: 3.65885 |  0:01:14s\n",
      "epoch 363| loss: 3.17436 | val_0_mae: 3.66002 |  0:01:14s\n",
      "epoch 364| loss: 3.12813 | val_0_mae: 3.71842 |  0:01:14s\n",
      "epoch 365| loss: 3.07851 | val_0_mae: 3.69123 |  0:01:14s\n",
      "epoch 366| loss: 3.19106 | val_0_mae: 3.84355 |  0:01:14s\n",
      "epoch 367| loss: 3.04658 | val_0_mae: 3.75411 |  0:01:15s\n",
      "epoch 368| loss: 2.99711 | val_0_mae: 3.59611 |  0:01:15s\n",
      "epoch 369| loss: 2.96689 | val_0_mae: 3.60929 |  0:01:15s\n",
      "epoch 370| loss: 3.00086 | val_0_mae: 3.50024 |  0:01:15s\n",
      "epoch 371| loss: 3.04517 | val_0_mae: 3.48553 |  0:01:15s\n",
      "epoch 372| loss: 2.90769 | val_0_mae: 3.53445 |  0:01:16s\n",
      "epoch 373| loss: 2.96338 | val_0_mae: 3.80648 |  0:01:16s\n",
      "epoch 374| loss: 3.09107 | val_0_mae: 3.84792 |  0:01:16s\n",
      "epoch 375| loss: 3.16515 | val_0_mae: 3.76111 |  0:01:16s\n",
      "epoch 376| loss: 3.0532  | val_0_mae: 3.74848 |  0:01:16s\n",
      "epoch 377| loss: 3.09278 | val_0_mae: 3.59613 |  0:01:17s\n",
      "epoch 378| loss: 3.00239 | val_0_mae: 3.60649 |  0:01:17s\n",
      "\n",
      "Early stopping occured at epoch 378 with best_epoch = 328 and best_val_0_mae = 3.43218\n",
      "Best weights from best epoch are automatically used!\n",
      "************************************************************\n",
      "Prediction MAE: 3.432181267866291\n",
      "************************************************************\n",
      "Num Fold: 5\n",
      "Train segments: 3545 Val segments: 886\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 22.74441| val_0_mae: 18.06432|  0:00:00s\n",
      "epoch 1  | loss: 21.61027| val_0_mae: 13.55994|  0:00:00s\n",
      "epoch 2  | loss: 20.43556| val_0_mae: 15.1157 |  0:00:00s\n",
      "epoch 3  | loss: 19.31552| val_0_mae: 14.64007|  0:00:00s\n",
      "epoch 4  | loss: 17.81086| val_0_mae: 17.11335|  0:00:01s\n",
      "epoch 5  | loss: 16.56226| val_0_mae: 23.77323|  0:00:01s\n",
      "epoch 6  | loss: 15.29078| val_0_mae: 16.68592|  0:00:01s\n",
      "epoch 7  | loss: 13.99269| val_0_mae: 14.52948|  0:00:01s\n",
      "epoch 8  | loss: 12.79675| val_0_mae: 20.75341|  0:00:01s\n",
      "epoch 9  | loss: 11.83177| val_0_mae: 18.60938|  0:00:02s\n",
      "epoch 10 | loss: 11.19517| val_0_mae: 21.71663|  0:00:02s\n",
      "epoch 11 | loss: 10.94872| val_0_mae: 21.61437|  0:00:02s\n",
      "epoch 12 | loss: 10.61114| val_0_mae: 14.6485 |  0:00:02s\n",
      "epoch 13 | loss: 10.6335 | val_0_mae: 14.9169 |  0:00:02s\n",
      "epoch 14 | loss: 10.15249| val_0_mae: 12.63983|  0:00:03s\n",
      "epoch 15 | loss: 9.82511 | val_0_mae: 12.88459|  0:00:03s\n",
      "epoch 16 | loss: 10.00492| val_0_mae: 13.50003|  0:00:03s\n",
      "epoch 17 | loss: 9.86173 | val_0_mae: 16.11784|  0:00:03s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18 | loss: 9.70833 | val_0_mae: 16.113  |  0:00:03s\n",
      "epoch 19 | loss: 9.69189 | val_0_mae: 12.77069|  0:00:04s\n",
      "epoch 20 | loss: 9.40808 | val_0_mae: 12.92609|  0:00:04s\n",
      "epoch 21 | loss: 9.26006 | val_0_mae: 12.93619|  0:00:04s\n",
      "epoch 22 | loss: 8.91305 | val_0_mae: 14.05018|  0:00:04s\n",
      "epoch 23 | loss: 8.65776 | val_0_mae: 14.94566|  0:00:04s\n",
      "epoch 24 | loss: 8.45294 | val_0_mae: 15.07042|  0:00:05s\n",
      "epoch 25 | loss: 8.4317  | val_0_mae: 11.99316|  0:00:05s\n",
      "epoch 26 | loss: 8.28163 | val_0_mae: 11.53717|  0:00:05s\n",
      "epoch 27 | loss: 8.06708 | val_0_mae: 11.16522|  0:00:05s\n",
      "epoch 28 | loss: 8.17058 | val_0_mae: 11.46524|  0:00:05s\n",
      "epoch 29 | loss: 7.87876 | val_0_mae: 11.77731|  0:00:06s\n",
      "epoch 30 | loss: 7.81562 | val_0_mae: 10.79226|  0:00:06s\n",
      "epoch 31 | loss: 7.63065 | val_0_mae: 11.24876|  0:00:06s\n",
      "epoch 32 | loss: 7.6971  | val_0_mae: 11.08721|  0:00:06s\n",
      "epoch 33 | loss: 7.55773 | val_0_mae: 10.73396|  0:00:06s\n",
      "epoch 34 | loss: 7.49315 | val_0_mae: 10.04249|  0:00:07s\n",
      "epoch 35 | loss: 7.32568 | val_0_mae: 9.67699 |  0:00:07s\n",
      "epoch 36 | loss: 7.51174 | val_0_mae: 9.34464 |  0:00:07s\n",
      "epoch 37 | loss: 7.43228 | val_0_mae: 8.62978 |  0:00:07s\n",
      "epoch 38 | loss: 7.47071 | val_0_mae: 8.59517 |  0:00:07s\n",
      "epoch 39 | loss: 7.22291 | val_0_mae: 8.62078 |  0:00:08s\n",
      "epoch 40 | loss: 7.37532 | val_0_mae: 8.63092 |  0:00:08s\n",
      "epoch 41 | loss: 7.20116 | val_0_mae: 8.77765 |  0:00:08s\n",
      "epoch 42 | loss: 7.11792 | val_0_mae: 9.26964 |  0:00:08s\n",
      "epoch 43 | loss: 7.20239 | val_0_mae: 9.4465  |  0:00:08s\n",
      "epoch 44 | loss: 7.19622 | val_0_mae: 9.51787 |  0:00:09s\n",
      "epoch 45 | loss: 7.10159 | val_0_mae: 9.16333 |  0:00:09s\n",
      "epoch 46 | loss: 6.95162 | val_0_mae: 9.18569 |  0:00:09s\n",
      "epoch 47 | loss: 6.99185 | val_0_mae: 9.21685 |  0:00:09s\n",
      "epoch 48 | loss: 6.85642 | val_0_mae: 9.3429  |  0:00:09s\n",
      "epoch 49 | loss: 6.77181 | val_0_mae: 8.86152 |  0:00:10s\n",
      "epoch 50 | loss: 6.66374 | val_0_mae: 8.76038 |  0:00:10s\n",
      "epoch 51 | loss: 6.68762 | val_0_mae: 8.33831 |  0:00:10s\n",
      "epoch 52 | loss: 6.6291  | val_0_mae: 7.84427 |  0:00:10s\n",
      "epoch 53 | loss: 6.51722 | val_0_mae: 8.02344 |  0:00:10s\n",
      "epoch 54 | loss: 6.34812 | val_0_mae: 7.74181 |  0:00:11s\n",
      "epoch 55 | loss: 6.29583 | val_0_mae: 7.23259 |  0:00:11s\n",
      "epoch 56 | loss: 6.33943 | val_0_mae: 7.79195 |  0:00:11s\n",
      "epoch 57 | loss: 6.3483  | val_0_mae: 7.47323 |  0:00:11s\n",
      "epoch 58 | loss: 6.32009 | val_0_mae: 7.22191 |  0:00:12s\n",
      "epoch 59 | loss: 6.29687 | val_0_mae: 7.19167 |  0:00:12s\n",
      "epoch 60 | loss: 6.29027 | val_0_mae: 7.26678 |  0:00:12s\n",
      "epoch 61 | loss: 6.16463 | val_0_mae: 7.06368 |  0:00:12s\n",
      "epoch 62 | loss: 6.16413 | val_0_mae: 6.79459 |  0:00:12s\n",
      "epoch 63 | loss: 5.99587 | val_0_mae: 7.50225 |  0:00:13s\n",
      "epoch 64 | loss: 6.08151 | val_0_mae: 7.56968 |  0:00:13s\n",
      "epoch 65 | loss: 6.03089 | val_0_mae: 7.10062 |  0:00:13s\n",
      "epoch 66 | loss: 5.90935 | val_0_mae: 6.85958 |  0:00:13s\n",
      "epoch 67 | loss: 5.7678  | val_0_mae: 6.22382 |  0:00:13s\n",
      "epoch 68 | loss: 5.73026 | val_0_mae: 6.05212 |  0:00:14s\n",
      "epoch 69 | loss: 5.73082 | val_0_mae: 6.05873 |  0:00:14s\n",
      "epoch 70 | loss: 5.65315 | val_0_mae: 5.86906 |  0:00:14s\n",
      "epoch 71 | loss: 5.72627 | val_0_mae: 5.74659 |  0:00:14s\n",
      "epoch 72 | loss: 5.56206 | val_0_mae: 6.00902 |  0:00:14s\n",
      "epoch 73 | loss: 5.37819 | val_0_mae: 6.34111 |  0:00:15s\n",
      "epoch 74 | loss: 5.4644  | val_0_mae: 6.02585 |  0:00:15s\n",
      "epoch 75 | loss: 5.31105 | val_0_mae: 5.64398 |  0:00:15s\n",
      "epoch 76 | loss: 5.25213 | val_0_mae: 5.46777 |  0:00:15s\n",
      "epoch 77 | loss: 5.26105 | val_0_mae: 5.30057 |  0:00:15s\n",
      "epoch 78 | loss: 5.21573 | val_0_mae: 5.35241 |  0:00:16s\n",
      "epoch 79 | loss: 5.15531 | val_0_mae: 5.36441 |  0:00:16s\n",
      "epoch 80 | loss: 4.99255 | val_0_mae: 5.50571 |  0:00:16s\n",
      "epoch 81 | loss: 4.91289 | val_0_mae: 5.08842 |  0:00:16s\n",
      "epoch 82 | loss: 4.99919 | val_0_mae: 4.91136 |  0:00:16s\n",
      "epoch 83 | loss: 4.93639 | val_0_mae: 5.11555 |  0:00:17s\n",
      "epoch 84 | loss: 4.98742 | val_0_mae: 5.11996 |  0:00:17s\n",
      "epoch 85 | loss: 4.98878 | val_0_mae: 5.0193  |  0:00:17s\n",
      "epoch 86 | loss: 4.92824 | val_0_mae: 4.97827 |  0:00:17s\n",
      "epoch 87 | loss: 4.75435 | val_0_mae: 4.86011 |  0:00:17s\n",
      "epoch 88 | loss: 4.73686 | val_0_mae: 5.00354 |  0:00:18s\n",
      "epoch 89 | loss: 4.69074 | val_0_mae: 4.85827 |  0:00:18s\n",
      "epoch 90 | loss: 4.62925 | val_0_mae: 4.73253 |  0:00:18s\n",
      "epoch 91 | loss: 4.58988 | val_0_mae: 4.66402 |  0:00:18s\n",
      "epoch 92 | loss: 4.62042 | val_0_mae: 4.54437 |  0:00:18s\n",
      "epoch 93 | loss: 4.50223 | val_0_mae: 4.64281 |  0:00:19s\n",
      "epoch 94 | loss: 4.43209 | val_0_mae: 4.37514 |  0:00:19s\n",
      "epoch 95 | loss: 4.4754  | val_0_mae: 4.47219 |  0:00:19s\n",
      "epoch 96 | loss: 4.393   | val_0_mae: 4.72562 |  0:00:19s\n",
      "epoch 97 | loss: 4.41425 | val_0_mae: 4.47684 |  0:00:19s\n",
      "epoch 98 | loss: 4.30472 | val_0_mae: 4.55432 |  0:00:20s\n",
      "epoch 99 | loss: 4.51392 | val_0_mae: 4.45365 |  0:00:20s\n",
      "epoch 100| loss: 4.41113 | val_0_mae: 4.48407 |  0:00:20s\n",
      "epoch 101| loss: 4.28999 | val_0_mae: 4.20355 |  0:00:20s\n",
      "epoch 102| loss: 4.17172 | val_0_mae: 4.43617 |  0:00:20s\n",
      "epoch 103| loss: 4.26246 | val_0_mae: 4.33725 |  0:00:21s\n",
      "epoch 104| loss: 4.24612 | val_0_mae: 4.36382 |  0:00:21s\n",
      "epoch 105| loss: 4.259   | val_0_mae: 4.3312  |  0:00:21s\n",
      "epoch 106| loss: 4.39163 | val_0_mae: 4.21629 |  0:00:21s\n",
      "epoch 107| loss: 4.24303 | val_0_mae: 4.15068 |  0:00:21s\n",
      "epoch 108| loss: 4.23729 | val_0_mae: 4.13267 |  0:00:22s\n",
      "epoch 109| loss: 4.07693 | val_0_mae: 4.34206 |  0:00:22s\n",
      "epoch 110| loss: 4.18663 | val_0_mae: 4.34788 |  0:00:22s\n",
      "epoch 111| loss: 4.13875 | val_0_mae: 4.12294 |  0:00:22s\n",
      "epoch 112| loss: 4.17306 | val_0_mae: 4.08886 |  0:00:22s\n",
      "epoch 113| loss: 4.04144 | val_0_mae: 4.18275 |  0:00:23s\n",
      "epoch 114| loss: 4.10585 | val_0_mae: 4.14556 |  0:00:23s\n",
      "epoch 115| loss: 4.13082 | val_0_mae: 4.50668 |  0:00:23s\n",
      "epoch 116| loss: 4.12383 | val_0_mae: 4.20809 |  0:00:23s\n",
      "epoch 117| loss: 4.22501 | val_0_mae: 3.98309 |  0:00:23s\n",
      "epoch 118| loss: 4.04566 | val_0_mae: 3.88269 |  0:00:24s\n",
      "epoch 119| loss: 3.90827 | val_0_mae: 4.04654 |  0:00:24s\n",
      "epoch 120| loss: 3.99129 | val_0_mae: 4.10928 |  0:00:24s\n",
      "epoch 121| loss: 3.92864 | val_0_mae: 3.95963 |  0:00:24s\n",
      "epoch 122| loss: 3.83407 | val_0_mae: 3.99347 |  0:00:24s\n",
      "epoch 123| loss: 4.03179 | val_0_mae: 3.88635 |  0:00:25s\n",
      "epoch 124| loss: 3.91225 | val_0_mae: 3.93469 |  0:00:25s\n",
      "epoch 125| loss: 3.86482 | val_0_mae: 3.91263 |  0:00:25s\n",
      "epoch 126| loss: 3.74161 | val_0_mae: 3.84732 |  0:00:25s\n",
      "epoch 127| loss: 3.73663 | val_0_mae: 3.8089  |  0:00:25s\n",
      "epoch 128| loss: 3.74559 | val_0_mae: 3.94458 |  0:00:26s\n",
      "epoch 129| loss: 3.78702 | val_0_mae: 3.87117 |  0:00:26s\n",
      "epoch 130| loss: 3.77271 | val_0_mae: 3.7243  |  0:00:26s\n",
      "epoch 131| loss: 3.51803 | val_0_mae: 3.81479 |  0:00:26s\n",
      "epoch 132| loss: 3.69418 | val_0_mae: 3.65479 |  0:00:26s\n",
      "epoch 133| loss: 3.63994 | val_0_mae: 3.69697 |  0:00:27s\n",
      "epoch 134| loss: 3.61503 | val_0_mae: 3.72846 |  0:00:27s\n",
      "epoch 135| loss: 3.61114 | val_0_mae: 3.69175 |  0:00:27s\n",
      "epoch 136| loss: 3.55035 | val_0_mae: 3.69551 |  0:00:27s\n",
      "epoch 137| loss: 3.66166 | val_0_mae: 3.74782 |  0:00:27s\n",
      "epoch 138| loss: 3.66225 | val_0_mae: 3.6668  |  0:00:28s\n",
      "epoch 139| loss: 3.5178  | val_0_mae: 3.83282 |  0:00:28s\n",
      "epoch 140| loss: 3.58781 | val_0_mae: 3.65347 |  0:00:28s\n",
      "epoch 141| loss: 3.53481 | val_0_mae: 3.96624 |  0:00:28s\n",
      "epoch 142| loss: 3.6102  | val_0_mae: 3.7325  |  0:00:29s\n",
      "epoch 143| loss: 3.63003 | val_0_mae: 3.68515 |  0:00:29s\n",
      "epoch 144| loss: 3.53266 | val_0_mae: 3.5129  |  0:00:29s\n",
      "epoch 145| loss: 3.57057 | val_0_mae: 3.49153 |  0:00:29s\n",
      "epoch 146| loss: 3.38216 | val_0_mae: 3.58158 |  0:00:29s\n",
      "epoch 147| loss: 3.42331 | val_0_mae: 3.56372 |  0:00:30s\n",
      "epoch 148| loss: 3.42112 | val_0_mae: 3.43379 |  0:00:30s\n",
      "epoch 149| loss: 3.28273 | val_0_mae: 3.61409 |  0:00:30s\n",
      "epoch 150| loss: 3.35994 | val_0_mae: 3.49495 |  0:00:30s\n",
      "epoch 151| loss: 3.47738 | val_0_mae: 3.43897 |  0:00:30s\n",
      "epoch 152| loss: 3.38543 | val_0_mae: 3.40905 |  0:00:31s\n",
      "epoch 153| loss: 3.30513 | val_0_mae: 3.56681 |  0:00:31s\n",
      "epoch 154| loss: 3.35034 | val_0_mae: 3.39306 |  0:00:31s\n",
      "epoch 155| loss: 3.40971 | val_0_mae: 3.43915 |  0:00:31s\n",
      "epoch 156| loss: 3.44665 | val_0_mae: 3.4903  |  0:00:31s\n",
      "epoch 157| loss: 3.32142 | val_0_mae: 3.38277 |  0:00:32s\n",
      "epoch 158| loss: 3.28288 | val_0_mae: 3.50823 |  0:00:32s\n",
      "epoch 159| loss: 3.32781 | val_0_mae: 3.36189 |  0:00:32s\n",
      "epoch 160| loss: 3.31954 | val_0_mae: 3.43704 |  0:00:32s\n",
      "epoch 161| loss: 3.41332 | val_0_mae: 3.33408 |  0:00:32s\n",
      "epoch 162| loss: 3.29522 | val_0_mae: 3.30635 |  0:00:33s\n",
      "epoch 163| loss: 3.33143 | val_0_mae: 3.25209 |  0:00:33s\n",
      "epoch 164| loss: 3.23    | val_0_mae: 3.33584 |  0:00:33s\n",
      "epoch 165| loss: 3.29106 | val_0_mae: 3.16558 |  0:00:33s\n",
      "epoch 166| loss: 3.26006 | val_0_mae: 3.39987 |  0:00:33s\n",
      "epoch 167| loss: 3.2007  | val_0_mae: 3.27109 |  0:00:34s\n",
      "epoch 168| loss: 3.26496 | val_0_mae: 3.3322  |  0:00:34s\n",
      "epoch 169| loss: 3.22481 | val_0_mae: 3.33578 |  0:00:34s\n",
      "epoch 170| loss: 3.29491 | val_0_mae: 3.565   |  0:00:34s\n",
      "epoch 171| loss: 3.31102 | val_0_mae: 3.2454  |  0:00:34s\n",
      "epoch 172| loss: 3.19193 | val_0_mae: 3.21289 |  0:00:35s\n",
      "epoch 173| loss: 3.09103 | val_0_mae: 3.34223 |  0:00:35s\n",
      "epoch 174| loss: 3.1877  | val_0_mae: 3.21948 |  0:00:35s\n",
      "epoch 175| loss: 3.11129 | val_0_mae: 3.53129 |  0:00:35s\n",
      "epoch 176| loss: 3.10499 | val_0_mae: 3.34534 |  0:00:35s\n",
      "epoch 177| loss: 3.25066 | val_0_mae: 3.29118 |  0:00:36s\n",
      "epoch 178| loss: 3.05332 | val_0_mae: 3.31646 |  0:00:36s\n",
      "epoch 179| loss: 3.10093 | val_0_mae: 3.29346 |  0:00:36s\n",
      "epoch 180| loss: 3.07717 | val_0_mae: 3.44081 |  0:00:36s\n",
      "epoch 181| loss: 3.14152 | val_0_mae: 3.49216 |  0:00:37s\n",
      "epoch 182| loss: 3.11931 | val_0_mae: 3.24196 |  0:00:37s\n",
      "epoch 183| loss: 3.18259 | val_0_mae: 3.23426 |  0:00:37s\n",
      "epoch 184| loss: 3.08135 | val_0_mae: 3.28595 |  0:00:37s\n",
      "epoch 185| loss: 3.0395  | val_0_mae: 3.23026 |  0:00:37s\n",
      "epoch 186| loss: 3.04538 | val_0_mae: 3.41271 |  0:00:38s\n",
      "epoch 187| loss: 3.07571 | val_0_mae: 3.24924 |  0:00:38s\n",
      "epoch 188| loss: 2.87601 | val_0_mae: 3.14517 |  0:00:38s\n",
      "epoch 189| loss: 2.98567 | val_0_mae: 3.24751 |  0:00:38s\n",
      "epoch 190| loss: 3.04901 | val_0_mae: 3.20134 |  0:00:38s\n",
      "epoch 191| loss: 3.06844 | val_0_mae: 3.30016 |  0:00:39s\n",
      "epoch 192| loss: 2.91865 | val_0_mae: 3.29135 |  0:00:39s\n",
      "epoch 193| loss: 2.97252 | val_0_mae: 3.30518 |  0:00:39s\n",
      "epoch 194| loss: 2.94019 | val_0_mae: 3.31206 |  0:00:39s\n",
      "epoch 195| loss: 2.96766 | val_0_mae: 2.99357 |  0:00:39s\n",
      "epoch 196| loss: 2.96097 | val_0_mae: 3.4699  |  0:00:40s\n",
      "epoch 197| loss: 3.01702 | val_0_mae: 2.98034 |  0:00:40s\n",
      "epoch 198| loss: 2.85961 | val_0_mae: 3.0194  |  0:00:40s\n",
      "epoch 199| loss: 2.91642 | val_0_mae: 3.09911 |  0:00:40s\n",
      "epoch 200| loss: 2.68755 | val_0_mae: 3.02277 |  0:00:41s\n",
      "epoch 201| loss: 2.9735  | val_0_mae: 3.13153 |  0:00:41s\n",
      "epoch 202| loss: 2.88979 | val_0_mae: 3.26893 |  0:00:41s\n",
      "epoch 203| loss: 2.91919 | val_0_mae: 3.12785 |  0:00:41s\n",
      "epoch 204| loss: 2.73676 | val_0_mae: 3.05063 |  0:00:41s\n",
      "epoch 205| loss: 2.8487  | val_0_mae: 2.97508 |  0:00:42s\n",
      "epoch 206| loss: 2.80637 | val_0_mae: 2.89113 |  0:00:42s\n",
      "epoch 207| loss: 2.7797  | val_0_mae: 3.01445 |  0:00:42s\n",
      "epoch 208| loss: 2.83556 | val_0_mae: 2.97625 |  0:00:42s\n",
      "epoch 209| loss: 2.86224 | val_0_mae: 2.98601 |  0:00:42s\n",
      "epoch 210| loss: 2.7938  | val_0_mae: 3.02971 |  0:00:43s\n",
      "epoch 211| loss: 2.79425 | val_0_mae: 2.97398 |  0:00:43s\n",
      "epoch 212| loss: 2.71758 | val_0_mae: 2.92716 |  0:00:43s\n",
      "epoch 213| loss: 2.75887 | val_0_mae: 2.88983 |  0:00:43s\n",
      "epoch 214| loss: 2.70617 | val_0_mae: 2.88748 |  0:00:44s\n",
      "epoch 215| loss: 2.81911 | val_0_mae: 2.95011 |  0:00:44s\n",
      "epoch 216| loss: 2.7525  | val_0_mae: 2.79234 |  0:00:44s\n",
      "epoch 217| loss: 2.76451 | val_0_mae: 2.88925 |  0:00:44s\n",
      "epoch 218| loss: 2.73487 | val_0_mae: 2.87109 |  0:00:44s\n",
      "epoch 219| loss: 2.66994 | val_0_mae: 2.85158 |  0:00:45s\n",
      "epoch 220| loss: 2.81114 | val_0_mae: 2.82766 |  0:00:45s\n",
      "epoch 221| loss: 2.7451  | val_0_mae: 2.9857  |  0:00:45s\n",
      "epoch 222| loss: 2.70068 | val_0_mae: 2.88573 |  0:00:45s\n",
      "epoch 223| loss: 2.71893 | val_0_mae: 2.87748 |  0:00:45s\n",
      "epoch 224| loss: 2.74839 | val_0_mae: 2.9721  |  0:00:46s\n",
      "epoch 225| loss: 2.72936 | val_0_mae: 2.97876 |  0:00:46s\n",
      "epoch 226| loss: 2.80323 | val_0_mae: 3.0024  |  0:00:46s\n",
      "epoch 227| loss: 2.69878 | val_0_mae: 2.96808 |  0:00:46s\n",
      "epoch 228| loss: 2.73739 | val_0_mae: 2.99135 |  0:00:47s\n",
      "epoch 229| loss: 2.73846 | val_0_mae: 2.90562 |  0:00:47s\n",
      "epoch 230| loss: 2.81115 | val_0_mae: 3.06441 |  0:00:47s\n",
      "epoch 231| loss: 2.67208 | val_0_mae: 2.94314 |  0:00:47s\n",
      "epoch 232| loss: 2.76848 | val_0_mae: 2.90395 |  0:00:47s\n",
      "epoch 233| loss: 2.65793 | val_0_mae: 2.84266 |  0:00:48s\n",
      "epoch 234| loss: 2.65816 | val_0_mae: 3.02372 |  0:00:48s\n",
      "epoch 235| loss: 2.60629 | val_0_mae: 2.76941 |  0:00:48s\n",
      "epoch 236| loss: 2.63893 | val_0_mae: 2.82742 |  0:00:48s\n",
      "epoch 237| loss: 2.71757 | val_0_mae: 2.78103 |  0:00:49s\n",
      "epoch 238| loss: 2.72589 | val_0_mae: 2.73799 |  0:00:49s\n",
      "epoch 239| loss: 2.69032 | val_0_mae: 2.91897 |  0:00:49s\n",
      "epoch 240| loss: 2.6857  | val_0_mae: 2.72048 |  0:00:49s\n",
      "epoch 241| loss: 2.58613 | val_0_mae: 2.82034 |  0:00:49s\n",
      "epoch 242| loss: 2.65021 | val_0_mae: 2.79558 |  0:00:50s\n",
      "epoch 243| loss: 2.6416  | val_0_mae: 2.81817 |  0:00:50s\n",
      "epoch 244| loss: 2.68576 | val_0_mae: 2.72596 |  0:00:50s\n",
      "epoch 245| loss: 2.71528 | val_0_mae: 2.72522 |  0:00:50s\n",
      "epoch 246| loss: 2.59985 | val_0_mae: 3.16172 |  0:00:50s\n",
      "epoch 247| loss: 2.63434 | val_0_mae: 2.72771 |  0:00:51s\n",
      "epoch 248| loss: 2.68132 | val_0_mae: 2.81162 |  0:00:51s\n",
      "epoch 249| loss: 2.59016 | val_0_mae: 2.82745 |  0:00:51s\n",
      "epoch 250| loss: 2.57883 | val_0_mae: 2.83222 |  0:00:51s\n",
      "epoch 251| loss: 2.49866 | val_0_mae: 2.87173 |  0:00:51s\n",
      "epoch 252| loss: 2.58718 | val_0_mae: 2.81027 |  0:00:52s\n",
      "epoch 253| loss: 2.54591 | val_0_mae: 2.66929 |  0:00:52s\n",
      "epoch 254| loss: 2.60984 | val_0_mae: 2.59649 |  0:00:52s\n",
      "epoch 255| loss: 2.60572 | val_0_mae: 2.94416 |  0:00:52s\n",
      "epoch 256| loss: 2.63684 | val_0_mae: 2.78707 |  0:00:52s\n",
      "epoch 257| loss: 2.5462  | val_0_mae: 2.63874 |  0:00:53s\n",
      "epoch 258| loss: 2.5084  | val_0_mae: 2.7558  |  0:00:53s\n",
      "epoch 259| loss: 2.54522 | val_0_mae: 2.7176  |  0:00:53s\n",
      "epoch 260| loss: 2.46238 | val_0_mae: 2.80333 |  0:00:53s\n",
      "epoch 261| loss: 2.63834 | val_0_mae: 2.66648 |  0:00:54s\n",
      "epoch 262| loss: 2.51448 | val_0_mae: 2.70792 |  0:00:54s\n",
      "epoch 263| loss: 2.56189 | val_0_mae: 2.68699 |  0:00:54s\n",
      "epoch 264| loss: 2.44129 | val_0_mae: 2.64302 |  0:00:54s\n",
      "epoch 265| loss: 2.46068 | val_0_mae: 2.834   |  0:00:54s\n",
      "epoch 266| loss: 2.43391 | val_0_mae: 2.71223 |  0:00:55s\n",
      "epoch 267| loss: 2.42299 | val_0_mae: 2.75814 |  0:00:55s\n",
      "epoch 268| loss: 2.53432 | val_0_mae: 2.66081 |  0:00:55s\n",
      "epoch 269| loss: 2.49258 | val_0_mae: 2.59343 |  0:00:55s\n",
      "epoch 270| loss: 2.50844 | val_0_mae: 2.66734 |  0:00:55s\n",
      "epoch 271| loss: 2.64872 | val_0_mae: 2.71827 |  0:00:56s\n",
      "epoch 272| loss: 2.44202 | val_0_mae: 2.71669 |  0:00:56s\n",
      "epoch 273| loss: 2.43346 | val_0_mae: 2.66068 |  0:00:56s\n",
      "epoch 274| loss: 2.51856 | val_0_mae: 2.61143 |  0:00:56s\n",
      "epoch 275| loss: 2.38703 | val_0_mae: 2.66385 |  0:00:56s\n",
      "epoch 276| loss: 2.49727 | val_0_mae: 2.7979  |  0:00:57s\n",
      "epoch 277| loss: 2.63864 | val_0_mae: 3.09    |  0:00:57s\n",
      "epoch 278| loss: 2.78928 | val_0_mae: 2.99655 |  0:00:57s\n",
      "epoch 279| loss: 2.70272 | val_0_mae: 2.73481 |  0:00:57s\n",
      "epoch 280| loss: 2.84268 | val_0_mae: 2.76262 |  0:00:58s\n",
      "epoch 281| loss: 2.67783 | val_0_mae: 2.80101 |  0:00:58s\n",
      "epoch 282| loss: 2.66938 | val_0_mae: 2.87027 |  0:00:58s\n",
      "epoch 283| loss: 2.87352 | val_0_mae: 2.77488 |  0:00:58s\n",
      "epoch 284| loss: 2.61998 | val_0_mae: 2.87313 |  0:00:58s\n",
      "epoch 285| loss: 2.56113 | val_0_mae: 2.67173 |  0:00:59s\n",
      "epoch 286| loss: 2.57532 | val_0_mae: 2.69984 |  0:00:59s\n",
      "epoch 287| loss: 2.61049 | val_0_mae: 2.71333 |  0:00:59s\n",
      "epoch 288| loss: 2.54824 | val_0_mae: 2.84069 |  0:00:59s\n",
      "epoch 289| loss: 2.50092 | val_0_mae: 2.81175 |  0:00:59s\n",
      "epoch 290| loss: 2.5553  | val_0_mae: 2.63806 |  0:01:00s\n",
      "epoch 291| loss: 2.49531 | val_0_mae: 2.69531 |  0:01:00s\n",
      "epoch 292| loss: 2.3825  | val_0_mae: 2.72162 |  0:01:00s\n",
      "epoch 293| loss: 2.49318 | val_0_mae: 2.66114 |  0:01:00s\n",
      "epoch 294| loss: 2.45822 | val_0_mae: 2.61814 |  0:01:00s\n",
      "epoch 295| loss: 2.43995 | val_0_mae: 2.71191 |  0:01:01s\n",
      "epoch 296| loss: 2.44116 | val_0_mae: 2.74529 |  0:01:01s\n",
      "epoch 297| loss: 2.62519 | val_0_mae: 2.72071 |  0:01:01s\n",
      "epoch 298| loss: 2.54127 | val_0_mae: 2.77066 |  0:01:01s\n",
      "epoch 299| loss: 2.50071 | val_0_mae: 2.74257 |  0:01:01s\n",
      "epoch 300| loss: 2.48908 | val_0_mae: 2.72285 |  0:01:02s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 301| loss: 2.38602 | val_0_mae: 2.71245 |  0:01:02s\n",
      "epoch 302| loss: 2.48446 | val_0_mae: 2.6503  |  0:01:02s\n",
      "epoch 303| loss: 2.46352 | val_0_mae: 2.73737 |  0:01:02s\n",
      "epoch 304| loss: 2.45057 | val_0_mae: 2.80323 |  0:01:02s\n",
      "epoch 305| loss: 2.4901  | val_0_mae: 2.7241  |  0:01:03s\n",
      "epoch 306| loss: 2.36038 | val_0_mae: 2.67748 |  0:01:03s\n",
      "epoch 307| loss: 2.36804 | val_0_mae: 2.65879 |  0:01:03s\n",
      "epoch 308| loss: 2.42602 | val_0_mae: 2.50107 |  0:01:03s\n",
      "epoch 309| loss: 2.46105 | val_0_mae: 2.50373 |  0:01:03s\n",
      "epoch 310| loss: 2.49714 | val_0_mae: 2.61921 |  0:01:04s\n",
      "epoch 311| loss: 2.38887 | val_0_mae: 2.6743  |  0:01:04s\n",
      "epoch 312| loss: 2.39986 | val_0_mae: 2.46542 |  0:01:04s\n",
      "epoch 313| loss: 2.29762 | val_0_mae: 2.47637 |  0:01:04s\n",
      "epoch 314| loss: 2.42905 | val_0_mae: 2.52347 |  0:01:04s\n",
      "epoch 315| loss: 2.36564 | val_0_mae: 2.49261 |  0:01:05s\n",
      "epoch 316| loss: 2.52432 | val_0_mae: 2.59441 |  0:01:05s\n",
      "epoch 317| loss: 2.54252 | val_0_mae: 2.59303 |  0:01:05s\n",
      "epoch 318| loss: 2.39064 | val_0_mae: 2.52651 |  0:01:05s\n",
      "epoch 319| loss: 2.5598  | val_0_mae: 2.63732 |  0:01:05s\n",
      "epoch 320| loss: 2.4934  | val_0_mae: 2.58648 |  0:01:06s\n",
      "epoch 321| loss: 2.46774 | val_0_mae: 2.51606 |  0:01:06s\n",
      "epoch 322| loss: 2.46595 | val_0_mae: 2.5888  |  0:01:06s\n",
      "epoch 323| loss: 2.38521 | val_0_mae: 2.72473 |  0:01:06s\n",
      "epoch 324| loss: 2.39107 | val_0_mae: 2.7402  |  0:01:06s\n",
      "epoch 325| loss: 2.4482  | val_0_mae: 2.72822 |  0:01:07s\n",
      "epoch 326| loss: 2.58253 | val_0_mae: 2.79893 |  0:01:07s\n",
      "epoch 327| loss: 2.51738 | val_0_mae: 2.79686 |  0:01:07s\n",
      "epoch 328| loss: 2.54643 | val_0_mae: 2.75753 |  0:01:07s\n",
      "epoch 329| loss: 2.39019 | val_0_mae: 2.70271 |  0:01:08s\n",
      "epoch 330| loss: 2.29549 | val_0_mae: 2.54655 |  0:01:08s\n",
      "epoch 331| loss: 2.39408 | val_0_mae: 2.72529 |  0:01:08s\n",
      "epoch 332| loss: 2.3403  | val_0_mae: 2.77025 |  0:01:08s\n",
      "epoch 333| loss: 2.54068 | val_0_mae: 2.69123 |  0:01:08s\n",
      "epoch 334| loss: 2.4338  | val_0_mae: 2.68488 |  0:01:09s\n",
      "epoch 335| loss: 2.41765 | val_0_mae: 2.57528 |  0:01:09s\n",
      "epoch 336| loss: 2.36817 | val_0_mae: 2.65886 |  0:01:09s\n",
      "epoch 337| loss: 2.4552  | val_0_mae: 2.62023 |  0:01:09s\n",
      "epoch 338| loss: 2.35191 | val_0_mae: 2.53982 |  0:01:09s\n",
      "epoch 339| loss: 2.37762 | val_0_mae: 2.58356 |  0:01:10s\n",
      "epoch 340| loss: 2.3431  | val_0_mae: 2.56468 |  0:01:10s\n",
      "epoch 341| loss: 2.37845 | val_0_mae: 2.55473 |  0:01:10s\n",
      "epoch 342| loss: 2.37256 | val_0_mae: 2.62108 |  0:01:10s\n",
      "epoch 343| loss: 2.32936 | val_0_mae: 2.59319 |  0:01:10s\n",
      "epoch 344| loss: 2.36621 | val_0_mae: 2.51729 |  0:01:11s\n",
      "epoch 345| loss: 2.28506 | val_0_mae: 2.49208 |  0:01:11s\n",
      "epoch 346| loss: 2.39512 | val_0_mae: 2.51856 |  0:01:11s\n",
      "epoch 347| loss: 2.40992 | val_0_mae: 2.52219 |  0:01:11s\n",
      "epoch 348| loss: 2.36362 | val_0_mae: 2.5394  |  0:01:11s\n",
      "epoch 349| loss: 2.34647 | val_0_mae: 2.48414 |  0:01:12s\n",
      "epoch 350| loss: 2.27389 | val_0_mae: 2.51703 |  0:01:12s\n",
      "epoch 351| loss: 2.48697 | val_0_mae: 2.36421 |  0:01:12s\n",
      "epoch 352| loss: 2.27046 | val_0_mae: 2.50974 |  0:01:12s\n",
      "epoch 353| loss: 2.20866 | val_0_mae: 2.46773 |  0:01:12s\n",
      "epoch 354| loss: 2.36273 | val_0_mae: 2.51683 |  0:01:13s\n",
      "epoch 355| loss: 2.2661  | val_0_mae: 2.54931 |  0:01:13s\n",
      "epoch 356| loss: 2.29649 | val_0_mae: 2.47872 |  0:01:13s\n",
      "epoch 357| loss: 2.35494 | val_0_mae: 2.54462 |  0:01:13s\n",
      "epoch 358| loss: 2.40751 | val_0_mae: 2.55047 |  0:01:13s\n",
      "epoch 359| loss: 2.24274 | val_0_mae: 2.51392 |  0:01:14s\n",
      "epoch 360| loss: 2.1275  | val_0_mae: 2.46869 |  0:01:14s\n",
      "epoch 361| loss: 2.2717  | val_0_mae: 2.45743 |  0:01:14s\n",
      "epoch 362| loss: 2.34558 | val_0_mae: 2.48467 |  0:01:14s\n",
      "epoch 363| loss: 2.25886 | val_0_mae: 2.36815 |  0:01:14s\n",
      "epoch 364| loss: 2.29725 | val_0_mae: 2.45772 |  0:01:15s\n",
      "epoch 365| loss: 2.21865 | val_0_mae: 2.34472 |  0:01:15s\n",
      "epoch 366| loss: 2.22816 | val_0_mae: 2.48874 |  0:01:15s\n",
      "epoch 367| loss: 2.35723 | val_0_mae: 2.48971 |  0:01:15s\n",
      "epoch 368| loss: 2.26459 | val_0_mae: 2.6868  |  0:01:15s\n",
      "epoch 369| loss: 2.32896 | val_0_mae: 2.60851 |  0:01:16s\n",
      "epoch 370| loss: 2.41407 | val_0_mae: 2.53011 |  0:01:16s\n",
      "epoch 371| loss: 2.29999 | val_0_mae: 2.57914 |  0:01:16s\n",
      "epoch 372| loss: 2.34974 | val_0_mae: 2.58753 |  0:01:16s\n",
      "epoch 373| loss: 2.32686 | val_0_mae: 2.48286 |  0:01:17s\n",
      "epoch 374| loss: 2.26407 | val_0_mae: 2.35265 |  0:01:17s\n",
      "epoch 375| loss: 2.25445 | val_0_mae: 2.47778 |  0:01:17s\n",
      "epoch 376| loss: 2.20961 | val_0_mae: 2.44449 |  0:01:17s\n",
      "epoch 377| loss: 2.41849 | val_0_mae: 2.52656 |  0:01:17s\n",
      "epoch 378| loss: 2.28469 | val_0_mae: 2.44804 |  0:01:18s\n",
      "epoch 379| loss: 2.22569 | val_0_mae: 2.47456 |  0:01:18s\n",
      "epoch 380| loss: 2.2383  | val_0_mae: 2.51325 |  0:01:18s\n",
      "epoch 381| loss: 2.2156  | val_0_mae: 2.37437 |  0:01:18s\n",
      "epoch 382| loss: 2.16455 | val_0_mae: 2.40852 |  0:01:18s\n",
      "epoch 383| loss: 2.14569 | val_0_mae: 2.40664 |  0:01:19s\n",
      "epoch 384| loss: 2.26128 | val_0_mae: 2.49297 |  0:01:19s\n",
      "epoch 385| loss: 2.17839 | val_0_mae: 2.34401 |  0:01:19s\n",
      "epoch 386| loss: 2.09126 | val_0_mae: 2.40134 |  0:01:19s\n",
      "epoch 387| loss: 2.19245 | val_0_mae: 2.23346 |  0:01:19s\n",
      "epoch 388| loss: 2.13897 | val_0_mae: 2.33002 |  0:01:20s\n",
      "epoch 389| loss: 2.0997  | val_0_mae: 2.41286 |  0:01:20s\n",
      "epoch 390| loss: 2.12101 | val_0_mae: 2.23891 |  0:01:20s\n",
      "epoch 391| loss: 2.13687 | val_0_mae: 2.34148 |  0:01:20s\n",
      "epoch 392| loss: 2.1771  | val_0_mae: 2.33158 |  0:01:20s\n",
      "epoch 393| loss: 2.14051 | val_0_mae: 2.37001 |  0:01:21s\n",
      "epoch 394| loss: 2.03493 | val_0_mae: 2.28355 |  0:01:21s\n",
      "epoch 395| loss: 2.10441 | val_0_mae: 2.34739 |  0:01:21s\n",
      "epoch 396| loss: 2.15401 | val_0_mae: 2.44037 |  0:01:21s\n",
      "epoch 397| loss: 2.0925  | val_0_mae: 2.32352 |  0:01:22s\n",
      "epoch 398| loss: 2.05704 | val_0_mae: 2.31067 |  0:01:22s\n",
      "epoch 399| loss: 2.03418 | val_0_mae: 2.33775 |  0:01:22s\n",
      "epoch 400| loss: 1.99751 | val_0_mae: 2.30627 |  0:01:22s\n",
      "epoch 401| loss: 2.09608 | val_0_mae: 2.27976 |  0:01:22s\n",
      "epoch 402| loss: 2.03695 | val_0_mae: 2.26937 |  0:01:23s\n",
      "epoch 403| loss: 2.09492 | val_0_mae: 2.37578 |  0:01:23s\n",
      "epoch 404| loss: 2.1426  | val_0_mae: 2.37944 |  0:01:23s\n",
      "epoch 405| loss: 2.12616 | val_0_mae: 2.34112 |  0:01:23s\n",
      "epoch 406| loss: 2.21541 | val_0_mae: 2.33161 |  0:01:23s\n",
      "epoch 407| loss: 2.14109 | val_0_mae: 2.32471 |  0:01:24s\n",
      "epoch 408| loss: 2.0938  | val_0_mae: 2.28864 |  0:01:24s\n",
      "epoch 409| loss: 2.12698 | val_0_mae: 2.27308 |  0:01:24s\n",
      "epoch 410| loss: 2.06555 | val_0_mae: 2.26537 |  0:01:24s\n",
      "epoch 411| loss: 2.04675 | val_0_mae: 2.25449 |  0:01:24s\n",
      "epoch 412| loss: 2.08596 | val_0_mae: 2.39137 |  0:01:25s\n",
      "epoch 413| loss: 2.12448 | val_0_mae: 2.39417 |  0:01:25s\n",
      "epoch 414| loss: 2.19657 | val_0_mae: 2.51949 |  0:01:25s\n",
      "epoch 415| loss: 2.1617  | val_0_mae: 2.46432 |  0:01:25s\n",
      "epoch 416| loss: 2.24105 | val_0_mae: 2.54874 |  0:01:25s\n",
      "epoch 417| loss: 2.21093 | val_0_mae: 2.38862 |  0:01:26s\n",
      "epoch 418| loss: 2.09939 | val_0_mae: 2.49317 |  0:01:26s\n",
      "epoch 419| loss: 2.1384  | val_0_mae: 2.65472 |  0:01:26s\n",
      "epoch 420| loss: 2.14421 | val_0_mae: 2.41902 |  0:01:26s\n",
      "epoch 421| loss: 2.07121 | val_0_mae: 2.50703 |  0:01:26s\n",
      "epoch 422| loss: 2.06427 | val_0_mae: 2.40128 |  0:01:27s\n",
      "epoch 423| loss: 2.03262 | val_0_mae: 2.31665 |  0:01:27s\n",
      "epoch 424| loss: 2.1756  | val_0_mae: 2.33364 |  0:01:27s\n",
      "epoch 425| loss: 2.13169 | val_0_mae: 2.60642 |  0:01:27s\n",
      "epoch 426| loss: 2.0897  | val_0_mae: 2.35803 |  0:01:27s\n",
      "epoch 427| loss: 2.08399 | val_0_mae: 2.32422 |  0:01:28s\n",
      "epoch 428| loss: 2.1401  | val_0_mae: 2.32481 |  0:01:28s\n",
      "epoch 429| loss: 2.07295 | val_0_mae: 2.30747 |  0:01:28s\n",
      "epoch 430| loss: 2.18028 | val_0_mae: 2.34164 |  0:01:28s\n",
      "epoch 431| loss: 2.10639 | val_0_mae: 2.37413 |  0:01:28s\n",
      "epoch 432| loss: 1.99515 | val_0_mae: 2.32648 |  0:01:29s\n",
      "epoch 433| loss: 2.11932 | val_0_mae: 2.41416 |  0:01:29s\n",
      "epoch 434| loss: 2.01994 | val_0_mae: 2.37389 |  0:01:29s\n",
      "epoch 435| loss: 2.07723 | val_0_mae: 2.37782 |  0:01:29s\n",
      "epoch 436| loss: 2.01811 | val_0_mae: 2.35105 |  0:01:30s\n",
      "epoch 437| loss: 1.96163 | val_0_mae: 2.29494 |  0:01:30s\n",
      "\n",
      "Early stopping occured at epoch 437 with best_epoch = 387 and best_val_0_mae = 2.23346\n",
      "Best weights from best epoch are automatically used!\n",
      "************************************************************\n",
      "Prediction MAE: 2.2334625643478883\n",
      "************************************************************\n"
     ]
    }
   ],
   "source": [
    "#############################################################\n",
    "# 7. Training\n",
    "\n",
    "list_segments_train = list(unique_segments_id_train)\n",
    "\n",
    "kf = StratifiedKFold(n_splits = 5, shuffle=True, random_state=12)\n",
    "list_history, list_models = [], []\n",
    "\n",
    "for num_fold, (train_index, val_index) in enumerate(kf.split(list_segments_train,\n",
    "                                                             np.zeros(len(list_segments_train)))):\n",
    "    segments_train_fold = np.asarray(list_segments_train)[train_index]\n",
    "    segments_val_fold = np.asarray(list_segments_train)[val_index]\n",
    "\n",
    "    print(f'Num Fold: {num_fold + 1}')\n",
    "    print(f'Train segments: {len(train_index)} Val segments: {len(val_index)}')\n",
    "    \n",
    "    X_train = df_X_train[features][df_X_train['segment_id'].isin(list(segments_train_fold))]\n",
    "    y_train = df_X_train['time_to_eruption'][df_X_train['segment_id'].isin(list(segments_train_fold))]\n",
    "    X_val = df_X_train[features][df_X_train['segment_id'].isin(list(segments_val_fold))]\n",
    "    y_val = df_X_train['time_to_eruption'][df_X_train['segment_id'].isin(list(segments_val_fold))]\n",
    "    \n",
    "    #model = buildLGBModel(X_train, y_train, X_val, y_val, features, verbose=10, early_stopping_rounds=200)\n",
    "    \n",
    "    model_tabnet = TabNetRegressor()\n",
    "    model_tabnet.fit(\n",
    "      X_train.values, \n",
    "      np.expand_dims(y_train.values, -1),\n",
    "      eval_set=[(X_val.values, np.expand_dims(y_val.values, -1))],\n",
    "      patience=50,\n",
    "      max_epochs=500,\n",
    "      eval_metric=[TabnetMAE],\n",
    "      loss_fn=torch.nn.L1Loss()\n",
    "    )\n",
    "    \n",
    "    #list_models.append(model)\n",
    "\n",
    "    y_pred_val = model_tabnet.predict(X_val.values)\n",
    "    mae = np.abs(y_val - y_pred_val.squeeze())\n",
    "\n",
    "    #pickle.dump(model, open(f'./models/model_tabular_STFT_{num_fold}.pickle', 'wb'))\n",
    "    torch.save(model_tabnet, f'./models/model_tabular_STFT_{num_fold}')\n",
    "    \n",
    "    print('***'*20)\n",
    "    print(f'Prediction MAE: {mae.mean()}')\n",
    "    print('***'*20)\n",
    "\n",
    "#############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "251f3ed641a84b8b863e2f66d03138a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************************************************************\n",
      "2233462.564347889\n",
      "************************************************************\n"
     ]
    }
   ],
   "source": [
    "#############################################################\n",
    "# 8. Cross Val Score\n",
    "\n",
    "list_segments_train = list(unique_segments_id_train)\n",
    "batch_size = 8\n",
    "\n",
    "kf = StratifiedKFold(n_splits = 5, shuffle=True, random_state=12)\n",
    "df_val_all = pd.DataFrame()\n",
    "\n",
    "for num_fold, (train_index, val_index) in tqdm(enumerate(kf.split(list_segments_train,\n",
    "                                                             np.zeros(len(list_segments_train)))), \n",
    "                                               total=5, position=0):\n",
    "    \n",
    "    \n",
    "    segments_train_fold = np.asarray(list_segments_train)[train_index]\n",
    "    segments_val_fold = np.asarray(list_segments_train)[val_index]\n",
    "\n",
    "    model = torch.load(f'./models/model_tabular_STFT_{num_fold}')\n",
    "\n",
    "    y_pred_val = model.predict(df_X_train[features][df_X_train['segment_id'].isin(list(segments_val_fold))].values).squeeze()\n",
    "    y_true_val = df_X_train['time_to_eruption'][df_X_train['segment_id'].isin(list(segments_val_fold))]\n",
    "\n",
    "    df_tmp = pd.DataFrame({\n",
    "            'pred' :  np.abs(y_pred_val)*(10**6),\n",
    "            'y_true' : y_true_val*(10**6)\n",
    "    })\n",
    "\n",
    "    df_val_all = pd.concat([df_val_all, df_tmp], axis=0)\n",
    "\n",
    "print('***'*20)\n",
    "print(np.mean(np.abs(df_tmp['y_true'] - df_tmp['pred'])))\n",
    "print('***'*20)\n",
    "\n",
    "\n",
    "#############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c137d752f4d94dbbb08d3a9dd904ced4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=4520.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>segment_id</th>\n",
       "      <th>time_to_eruption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4.520000e+03</td>\n",
       "      <td>4.520000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.066993e+09</td>\n",
       "      <td>2.510334e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.162904e+08</td>\n",
       "      <td>1.293076e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>8.602880e+05</td>\n",
       "      <td>3.723431e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.458995e+08</td>\n",
       "      <td>1.533057e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.060695e+09</td>\n",
       "      <td>2.466841e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.599284e+09</td>\n",
       "      <td>3.670453e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.147116e+09</td>\n",
       "      <td>4.835446e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         segment_id  time_to_eruption\n",
       "count  4.520000e+03      4.520000e+03\n",
       "mean   1.066993e+09      2.510334e+07\n",
       "std    6.162904e+08      1.293076e+07\n",
       "min    8.602880e+05      3.723431e+04\n",
       "25%    5.458995e+08      1.533057e+07\n",
       "50%    1.060695e+09      2.466841e+07\n",
       "75%    1.599284e+09      3.670453e+07\n",
       "max    2.147116e+09      4.835446e+07"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#############################################################\n",
    "# 9. Inference\n",
    "\n",
    "df_X_test = buildDataset(dict_segments_sequences_paths_test)\n",
    "# del X_val_sequences, y_val_target, list_cv_pred, y_pred_cv, y_cv_target, df_cv, X_cv_sequences, y_cv_target\n",
    "gc.collect()\n",
    "\n",
    "list_models = [torch.load(f'./models/model_tabular_STFT_{num_fold}') for num_fold in range(5)]\n",
    "y_test_pred = np.mean([model.predict(df_X_test[features].values).squeeze()], axis=0)\n",
    "list_test_segments = df_X_test['segment_id']\n",
    "\n",
    "df_submission = pd.DataFrame({\n",
    "    'segment_id' : list_test_segments,\n",
    "    'time_to_eruption' : np.abs(y_test_pred*(10**6))#np.clip(y_test_pred*(10**6), 6_000, np.inf)\n",
    "})\n",
    "\n",
    "df_submission.to_csv('./FinalSubmissions/' + 'submission_tabular_stft.csv', index=False)\n",
    "df_submission.describe()\n",
    "\n",
    "#############################################################"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
